<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Elliot Shannon">

<title>Gibbs’ Sampler: Dynamic Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="dynamic_files/libs/clipboard/clipboard.min.js"></script>
<script src="dynamic_files/libs/quarto-html/quarto.js"></script>
<script src="dynamic_files/libs/quarto-html/popper.min.js"></script>
<script src="dynamic_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="dynamic_files/libs/quarto-html/anchor.min.js"></script>
<link href="dynamic_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="dynamic_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="dynamic_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="dynamic_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="dynamic_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Gibbs’ Sampler: Dynamic Linear Regression</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Elliot Shannon <a href="mailto:shann125@msu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Michigan State University
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<section id="setting" class="level2">
<h2 class="anchored" data-anchor-id="setting">Setting</h2>
<p>The setting of interest involves data generated from a dynamic linear model. Here, dynamic refers to the evolution of regression coefficients (<span class="math inline">\(\boldsymbol{\beta}\)</span>’s) over time. Rather than standard multiple linear regression, we have different regression coefficients for each time step, where coefficients at time <span class="math inline">\(t\)</span> are centered on the coefficient values at time <span class="math inline">\(t-1\)</span>. Moreover, the covariates (<span class="math inline">\(\textbf{X}\)</span>), may also change over time, hence we have a different design matrix for each time step. The proposed model is described in detail below.</p>
</section>
<section id="model" class="level2">
<h2 class="anchored" data-anchor-id="model">Model</h2>
<p>For time points <span class="math inline">\(t = 1, \ldots, T\)</span>, let</p>
<ul>
<li><p><span class="math inline">\(\textbf{Y}_t = \begin{pmatrix} y_{1,t} \\ \vdots \\ y_{N,t}  \end{pmatrix} \in \mathbb{R}^N\)</span> be the vector of responses.</p></li>
<li><p><span class="math inline">\(\textbf{X}_t = \begin{pmatrix} 1 &amp; x_{1, 1, t} &amp; \ldots &amp; x_{1, P - 1, t} \\ &amp; &amp; \vdots \\  1 &amp; x_{N, 1, t} &amp; \ldots &amp; x_{N, P - 1, t} \end{pmatrix} \in \mathbb{R}^{N \times P}\)</span> be the design matrix of covariates.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}_t = \begin{pmatrix} \beta_{1,t} \\ \vdots \\ \beta_{P,t}  \end{pmatrix} \in \mathbb{R}^P\)</span> be the vector of regression coefficients.</p></li>
<li><p><span class="math inline">\( \boldsymbol{\varepsilon} _t = \begin{pmatrix} \varepsilon_{1,t} \\ \vdots \\ \varepsilon_{N,t}  \end{pmatrix} \in \mathbb{R}^N\)</span> be the vector of residual terms.</p></li>
</ul>
<p>The proposed model is then</p>
<p><span class="math display">\[\begin{equation} \label{eq:mod}
\begin{aligned}
\textbf{Y}_t &amp;= \textbf{X}_t \boldsymbol{\beta}_t +  \boldsymbol{\varepsilon} _t, \quad  \boldsymbol{\varepsilon} _t \sim MVN(\textbf{0}, \sigma^2 \textbf{I}_N), \quad t = 1, \ldots, T\\
\boldsymbol{\beta}_t &amp;= \boldsymbol{\beta}_{t - 1} +  \boldsymbol{\eta} _t, \quad \boldsymbol{\beta}_0 \sim MVN( \boldsymbol{\mu} _\beta,  \boldsymbol{\Sigma} _\beta), \\
\boldsymbol{\eta} _t &amp;\sim MVN(0,  \boldsymbol{\Sigma} _\eta), \quad  \boldsymbol{\Sigma} _\eta \sim IW(\textbf{H}, \nu), \quad \sigma^2 \sim IG(a, b)
\end{aligned}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\textbf{0}\)</span> is a vector of <span class="math inline">\(0\)</span>’s.</p>
<p>Further, <span class="math inline">\(MVN( \boldsymbol{\mu} ,  \boldsymbol{\Sigma} )\)</span> is the multivariate normal distribution with mean vector <span class="math inline">\( \boldsymbol{\mu} \in \mathbb{R}^N\)</span>, covariance matrix <span class="math inline">\( \boldsymbol{\Sigma} \in \mathbb{R}^{N \times N}\)</span>, and pdf</p>
<p><span class="math display">\[\begin{equation}\label{eq:mvn}
p(\textbf{x}\mid  \boldsymbol{\mu} ,  \boldsymbol{\Sigma} ) = (2 \pi)^{-N/2} | \boldsymbol{\Sigma} |^{-1/2} \exp\left(\frac{-1}{2} (\textbf{x}-  \boldsymbol{\mu} )^\top  \boldsymbol{\Sigma} ^{-1} (\textbf{x}-  \boldsymbol{\mu} )\right)
\end{equation}\]</span></p>
<p><span class="math inline">\(IW(\textbf{H}, \nu)\)</span> is the Inverse Wishart distribution with (positive definite) scale matrix <span class="math inline">\(\textbf{H}\in \mathbb{R}^{N \times N}\)</span>, degrees of freedom <span class="math inline">\(\nu &gt; N - 1\)</span>, and pdf</p>
<p><span class="math display">\[\begin{equation}\label{eq:iw}
p( \boldsymbol{\Sigma} \mid \textbf{H}, \nu) = \frac{|\textbf{H}|^{\nu / 2}}{2^{\nu N / 2}  \Gamma_N \left( \frac{\nu}{2} \right)}  | \boldsymbol{\Sigma} |^{-(\nu + N + 1) / 2} \exp\left(-\frac{1}{2} \text{tr}\left( \textbf{H} \boldsymbol{\Sigma} ^{-1} \right) \right)
\end{equation}\]</span></p>
<p>and <span class="math inline">\(IG(a, b)\)</span> is the Inverse Gamma distribution with shape parameter <span class="math inline">\(a &gt; 0\)</span>, scale parameter <span class="math inline">\(b &gt; 0\)</span>, and pdf</p>
<p><span class="math display">\[\begin{equation}\label{eq:ig}
p(\sigma^2 \mid a, b) = \frac{b^a}{\Gamma (a)} (\sigma^2)^{-a - 1} \exp\left( \frac{-b}{\sigma^2} \right).
\end{equation}\]</span></p>
<p>Given this completed model specification, we would like to conduct inference on the model parameters given data <span class="math inline">\(\textbf{Y}_t\)</span> and <span class="math inline">\(\textbf{X}_t\)</span>, <span class="math inline">\(t = 1, \ldots, T\)</span>. These parameters include <span class="math inline">\(\boldsymbol{\beta}_0, \boldsymbol{\beta}_1, \ldots, \boldsymbol{\beta}_T,  \boldsymbol{\Sigma} _\eta, \sigma^2\)</span>. We assume that prior parameters <span class="math inline">\( \boldsymbol{\mu} _\beta,  \boldsymbol{\Sigma} _\beta, \textbf{H}, \nu, a, b\)</span> are given (specified by the user).</p>
</section>
<section id="posterior" class="level2">
<h2 class="anchored" data-anchor-id="posterior">Posterior</h2>
<p>We know that the posterior distribution in Bayesian inference is proportional to the likelihood (data distribution) times the prior. Here, our likelihood is the distribution of the data <span class="math inline">\(\textbf{Y}_t, t = 1, \ldots, T\)</span>. Since the distribution of the residuals is <span class="math inline">\(MVN\)</span>, we will have a <span class="math inline">\(MVN\)</span> likelihood, written as</p>
<p><span class="math display">\[\begin{equation}\label{eq:likelihood}
\prod_{t = 1}^T MVN(\textbf{Y}_t \mid \textbf{X}_t \boldsymbol{\beta}_t, \sigma^2 \textbf{I}_N)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\textbf{I}_N\)</span> is an <span class="math inline">\(N \times N\)</span> identity matrix (diagonal matrix with diagonal elements equal to <span class="math inline">\(1\)</span>).</p>
<p>We will also have priors (some of which are induced) for each parameter for which we seek inference. Specifically, we have prior distributions of the form</p>
<p><span class="math display">\[\begin{equation}\label{eq:priors}
\prod_{t = 1}^T MVN(\boldsymbol{\beta}_t \mid \boldsymbol{\beta}_{t - 1},  \boldsymbol{\Sigma} _\eta) \times MVN(\boldsymbol{\beta}_0 \mid  \boldsymbol{\mu} _\beta,  \boldsymbol{\Sigma} _\beta) \times IG(\sigma^2 \mid a, b) \times IW( \boldsymbol{\Sigma} _\eta \mid \textbf{H}, \nu)
\end{equation}\]</span></p>
<p>Given (<span class="math inline">\(\ref{eq:likelihood}\)</span>) and (<span class="math inline">\(\ref{eq:priors}\)</span>), their product will be proportional to the posterior distribution, and is given as</p>
<p><span class="math display">\[\begin{equation}\label{eq:posterior}
\begin{aligned}
\prod_{t = 1}^T MVN(\textbf{Y}_t \mid \textbf{X}_t \boldsymbol{\beta}_t, \sigma^2 \textbf{I}_N) &amp;\times \prod_{t = 1}^T MVN(\boldsymbol{\beta}_t \mid \boldsymbol{\beta}_{t - 1},  \boldsymbol{\Sigma} _\eta) \times MVN(\boldsymbol{\beta}_0 \mid  \boldsymbol{\mu} _\beta,  \boldsymbol{\Sigma} _\beta) \\ &amp;\times IG(\sigma^2 \mid a, b) \times IW( \boldsymbol{\Sigma} _\eta \mid \textbf{H}, \nu)
\end{aligned}
\end{equation}\]</span></p>
<p>Importantly, (<span class="math inline">\(\ref{eq:posterior}\)</span>) is only to our desired posterior. Why is this okay? We are essentially ignoring the complex integral (normalizing constant) which typically appears in the denominator of Bayes theorem, which represents the marginal distribution of our complete data <span class="math inline">\(\textbf{Y}\)</span>. This normalizing constant is necessary to ensure that the posterior we derive is actually a proper probability distribution (integrates to 1). It is important, but not necessary for our purposes of deriving full conditionals for Gibbs sampling. Moving forward, we only work with this proportional posterior (<span class="math inline">\(\ref{eq:posterior}\)</span>).</p>
</section>
<section id="conditional-intuition" class="level2">
<h2 class="anchored" data-anchor-id="conditional-intuition">Conditional Intuition</h2>
<p>Recall that in the current model (<span class="math inline">\(\ref{eq:mod}\)</span>), we are interested in learning about parameters <span class="math inline">\(\boldsymbol{\beta}_0, \boldsymbol{\beta}_1, \ldots, \boldsymbol{\beta}_T,  \boldsymbol{\Sigma} _\eta, \sigma^2\)</span>. These parameters each appear in our posterior distribution given in (<span class="math inline">\(\ref{eq:posterior}\)</span>); some appear in several terms, others appear in fewer. The beauty of Gibbs sampling is that for each parameter of interest, we can derive its , meaning we don’t need to work with the entirety of (<span class="math inline">\(\ref{eq:posterior}\)</span>), but rather just the specific terms in which the parameter of interest is found. This simplifies our lives greatly. Moreover, if we have been clever enough to use conjugate priors for each parameter, we can expect that our full conditional distributions will take nice forms. So nice in fact, that we can skip many tedious steps in our derivation to simply identify the defining features (parameters) of each distribution. The general steps are outlined below.</p>
<section id="general-steps-for-deriving-full-conditional-distributions" class="level3">
<h3 class="anchored" data-anchor-id="general-steps-for-deriving-full-conditional-distributions">General steps for deriving full conditional distributions</h3>
<ol type="1">
<li>Identify each term in the posterior distribution in which the parameter of interest is found.</li>
<li>Isolate these terms and write them as a product of pdfs.</li>
<li>Combine like terms and ignore terms that do not involve the parameter of interest.</li>
<li>Recognize the simplified expression as a pdf of the parameter of interest and identify the distributional parameters. This is the full conditional distribution for the parameter of interest.</li>
<li>Move to the next parameter of interest and go back to step 1.</li>
</ol>
</section>
<section id="a-note-on-conjugacy" class="level3">
<h3 class="anchored" data-anchor-id="a-note-on-conjugacy">A note on conjugacy</h3>
<p>In Bayesian inference, conjugacy refers to the pairing of prior and likelihood distributions to achieve a specific posterior form. When a prior is conjugate, the resulting posterior distribution will have the same distributional form. This is immensely helpful when deriving full conditional distributions, especially in step 4 of the general steps given above. Some important examples of conjugacy are given below:</p>
<ul>
<li>Normal Likelihood <span class="math inline">\(\times\)</span> Normal Prior <span class="math inline">\(\rightarrow\)</span> Normal Posterior</li>
<li>Normal Likelihood <span class="math inline">\(\times\)</span> IG Prior <span class="math inline">\(\rightarrow\)</span> IG Posterior</li>
<li>Normal Likelihood <span class="math inline">\(\times\)</span> IW Prior <span class="math inline">\(\rightarrow\)</span> IW Posterior</li>
</ul>
</section>
</section>
<section id="incompleting-the-square" class="level2">
<h2 class="anchored" data-anchor-id="incompleting-the-square">Incompleting the Square</h2>
<p>In the case of Normal-Normal conjugacy (normal prior with normal likelihood), we expect the posterior distribution to also follow a normal distribution. The same is true with multivariate normal distributions, which we work with here. A handy trick for identifying this posterior distribution is coined “”, which comes from James Clark’s book ‘Models for Ecological Data’. See Section 4.2 of his book for more details.</p>
<p>Following (<span class="math inline">\(\ref{eq:mvn}\)</span>), we know that the kernel of the <span class="math inline">\(MVN\)</span> distribution is of the form</p>
<p><span class="math display">\[\begin{equation*}
p(\textbf{x}\mid  \boldsymbol{\mu} ,  \boldsymbol{\Sigma} ) \propto \exp\left(\frac{-1}{2} (\textbf{x}-  \boldsymbol{\mu} )^\top  \boldsymbol{\Sigma} ^{-1} (\textbf{x}-  \boldsymbol{\mu} )\right)
\end{equation*}\]</span></p>
<p>where <span class="math inline">\(\propto\)</span> mean “proportional to”. This structure gives us some insight into the placement of the parameters in the pdf. To see this further, we can focus on the terms inside the exponential, ignoring the <span class="math inline">\(-\frac{1}{2}\)</span> coefficient. Expanding this term gives us:</p>
<p><span class="math display">\[\begin{align}\label{eq:expand_mvn}
(\textbf{x}-  \boldsymbol{\mu} )^\top  \boldsymbol{\Sigma} ^{-1} (\textbf{x}-  \boldsymbol{\mu} ) &amp;= \textbf{x}^\top  \boldsymbol{\Sigma} ^{-1} \textbf{x}- \textbf{x}^\top  \boldsymbol{\Sigma} ^{-1}  \boldsymbol{\mu} -  \boldsymbol{\mu} ^\top  \boldsymbol{\Sigma} ^{-1} \textbf{x}+  \boldsymbol{\mu} ^\top  \boldsymbol{\Sigma} ^{-1}  \boldsymbol{\mu}
\end{align}\]</span></p>
<p>Now comes the trick. Writing the mean as a function of the covariance matrix, we can define</p>
<p><span class="math display">\[\begin{align*}
\boldsymbol{\mu} &amp;= \textbf{V}\textbf{v}\\
\boldsymbol{\Sigma} &amp;= \textbf{V}
\end{align*}\]</span></p>
<p>This allows us to rewrite (<span class="math inline">\(\ref{eq:expand_mvn}\)</span>) as</p>
<p><span class="math display">\[\begin{align*}
\textbf{x}^\top \textbf{V}^{-1} \textbf{x}&amp;- \textbf{x}^\top \textbf{V}^{-1} \textbf{V}\textbf{v}- \textbf{v}^\top \textbf{V}^\top \textbf{V}^{-1} \textbf{x}+ \textbf{v}^\top \textbf{V}^\top \textbf{V}^{-1} \textbf{V}\textbf{v}\\
&amp;= \textbf{x}^\top \textbf{V}^{-1} \textbf{x}- \textbf{x}^\top \textbf{v}- \textbf{v}^\top \textbf{x}+ \textbf{v}^\top \textbf{V}\textbf{v}\\
&amp;= \textbf{x}^\top \textbf{V}^{-1} \textbf{x}- \textbf{x}^\top \textbf{v}\cdots
\end{align*}\]</span></p>
<p>This is super helpful, because when we are mashing together normal priors and likelihoods, we can combine like terms and look for <span class="math inline">\(\textbf{V}^{-1}\)</span> and <span class="math inline">\(\textbf{v}\)</span> to get the mean and variance of the full conditional <span class="math inline">\(MVN\)</span>. They will always be in the same place! <span class="math inline">\(\textbf{V}^{-1}\)</span> will be sandwiched between the variable of interest (i.e.&nbsp;the <span class="math inline">\(\textbf{x}^\top \textbf{V}^{-1} \textbf{x}\)</span> term), and <span class="math inline">\(\textbf{v}\)</span> will be attached to the negative transpose of the variable of interest (i.e.&nbsp;<span class="math inline">\(- \textbf{x}^\top \textbf{v}\)</span>) (in this example, <span class="math inline">\(\textbf{x}\)</span> is the variable of interest). Once we identify <span class="math inline">\(\textbf{V}^{-1}\)</span> and <span class="math inline">\(\textbf{v}\)</span>, we can sample from the full conditional distribution as <span class="math inline">\(MVN(\textbf{V}\textbf{v}, \textbf{V})\)</span>.</p>
</section>
<section id="working-it-out" class="level2">
<h2 class="anchored" data-anchor-id="working-it-out">Working it out</h2>
<p>We will now go through each of the parameters in model (<span class="math inline">\(\ref{eq:mod}\)</span>) and derive their full conditional distributions. Moving forward, we will use different colors to help keep track of different prior and likelihood terms as we work through the derivations. This will help us see where each component of the full conditional distribution is coming from.</p>
</section>
<section id="update-boldsymbolbeta_0" class="level2">
<h2 class="anchored" data-anchor-id="update-boldsymbolbeta_0">Update <span class="math inline">\(\boldsymbol{\beta}_0\)</span></h2>
<p>Looking at (<span class="math inline">\(\ref{eq:posterior}\)</span>), we see that <span class="math inline">\(\boldsymbol{\beta}_0\)</span> appears in two terms, namely it’s , and as the mean value of . The product of these distributions looks like</p>
<p><span class="math display">\[\begin{equation*}
\textcolor{OrangeRed}{MVN(\boldsymbol{\beta}_0 \mid  \boldsymbol{\mu} _\beta,  \boldsymbol{\Sigma} _\beta)} \times \textcolor{RoyalBlue}{MVN(\boldsymbol{\beta}_1 \mid \boldsymbol{\beta}_0,  \boldsymbol{\Sigma} _\eta)}
\end{equation*}\]</span></p>
<p>Since both distributions are normal, we know their product will also be normal, with mean <span class="math inline">\(\textbf{V}\textbf{v}\)</span> and Covariance matrix <span class="math inline">\(\textbf{V}\)</span>. Based on what we know about incompleting the square, we will find <span class="math inline">\(\textbf{V}\)</span> and <span class="math inline">\(\textbf{v}\)</span> in the following terms of the product</p>
<p><span class="math display">\[\begin{equation*}
\boldsymbol{\beta}_0^\top \textbf{V}^{-1} \boldsymbol{\beta}_0 - \boldsymbol{\beta}_0^\top \textbf{v}\cdots.
\end{equation*}\]</span></p>
<p>So, all we have to do is multiply two multivariate normal pdfs (see equation <span class="math inline">\(\ref{eq:mvn}\)</span>), combine like terms in <span class="math inline">\(\boldsymbol{\beta}_0\)</span>, and identify <span class="math inline">\(\textbf{V}^{-1}\)</span> and <span class="math inline">\(\textbf{v}\)</span> from where they appear above. Since we are incompleting the square, we don’t actually need to multiply the complete pdfs, just the exponential parts where <span class="math inline">\(\textbf{V}\)</span> and <span class="math inline">\(\textbf{v}\)</span> will appear. Ignoring the other components of the pdfs, we have</p>
<p><span class="math display">\[\begin{align*}
&amp;\textcolor{OrangeRed}{MVN(\boldsymbol{\beta}_0 \mid  \boldsymbol{\mu} _\beta,  \boldsymbol{\Sigma} _\beta)} \times \textcolor{RoyalBlue}{MVN(\boldsymbol{\beta}_1 \mid \boldsymbol{\beta}_0,  \boldsymbol{\Sigma} _\eta)} \\
&amp;\propto \textcolor{OrangeRed}{\exp \left((\boldsymbol{\beta}_0 -  \boldsymbol{\mu} _\beta)^\top  \boldsymbol{\Sigma} _\beta^{-1}(\boldsymbol{\beta}_0 -  \boldsymbol{\mu} _\beta)\right)} \times \textcolor{RoyalBlue}{\exp \left((\boldsymbol{\beta}_1 - \boldsymbol{\beta}_0)^\top  \boldsymbol{\Sigma} _\eta^{-1}(\boldsymbol{\beta}_1 - \boldsymbol{\beta}_0)\right)} \\
&amp;= \exp \left(\textcolor{OrangeRed}{(\boldsymbol{\beta}_0 -  \boldsymbol{\mu} _\beta)^\top  \boldsymbol{\Sigma} _\beta^{-1}(\boldsymbol{\beta}_0 -  \boldsymbol{\mu} _\beta)} + \textcolor{RoyalBlue}{(\boldsymbol{\beta}_1 - \boldsymbol{\beta}_0)^\top  \boldsymbol{\Sigma} _\eta^{-1}(\boldsymbol{\beta}_1 - \boldsymbol{\beta}_0)} \right) \\
&amp;= \exp \left( \textcolor{OrangeRed}{\boldsymbol{\beta}_0^\top  \boldsymbol{\Sigma} _\beta^{-1} \boldsymbol{\beta}_0 - \boldsymbol{\beta}_0^\top  \boldsymbol{\Sigma} _\beta^{-1}  \boldsymbol{\mu} _\beta -  \boldsymbol{\mu} _\beta^\top  \boldsymbol{\Sigma} _\beta^{-1} \boldsymbol{\beta}_0 +  \boldsymbol{\mu} _\beta^\top  \boldsymbol{\Sigma} _\beta^{-1}  \boldsymbol{\mu} _\beta} \right. \\
&amp;\quad \left. + \textcolor{RoyalBlue}{\boldsymbol{\beta}_1^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_1 - \boldsymbol{\beta}_1^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_0 - \boldsymbol{\beta}_0^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_1 + \boldsymbol{\beta}_0^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_0} \right)
\end{align*}\]</span></p>
<p>Now we just need to pay attention to the terms of the form <span class="math inline">\(\boldsymbol{\beta}_0^\top \textbf{V}^{-1} \boldsymbol{\beta}_0\)</span> and <span class="math inline">\(- \boldsymbol{\beta}_0^\top \textbf{v}\)</span> to identify <span class="math inline">\(\textbf{V}^{-1}\)</span> and <span class="math inline">\(\textbf{v}\)</span>. Combining like terms gives us</p>
<p><span class="math display">\[\begin{equation*}
\propto \exp \left( \boldsymbol{\beta}_0^\top (\textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\beta^{-1}} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1}}) \boldsymbol{\beta}_0^\top - \boldsymbol{\beta}_0^\top (\textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\beta^{-1}  \boldsymbol{\mu} _\beta} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_1}) \cdots \right)
\end{equation*}\]</span></p>
<p>So we have that</p>
<p><span class="math display">\[\begin{align*}
&amp;\textbf{V}^{-1} = (\textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\beta^{-1}} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1}}) \\
&amp;\textbf{v}= (\textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\beta^{-1}  \boldsymbol{\mu} _\beta} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_1})
\end{align*}\]</span></p>
<p>and we can sample <span class="math inline">\(\boldsymbol{\beta}_0\)</span> from it’s full conditional distribution as <span class="math inline">\(MVN(\textbf{V}\textbf{v}, \textbf{V})\)</span>.</p>
</section>
<section id="update-boldsymbolbeta_t-quad-t-1-ldots-t-1" class="level2">
<h2 class="anchored" data-anchor-id="update-boldsymbolbeta_t-quad-t-1-ldots-t-1">Update <span class="math inline">\(\boldsymbol{\beta}_t \quad t = 1, \ldots (T-1)\)</span></h2>
<p>Looking at (<span class="math inline">\(\ref{eq:posterior}\)</span>), we see that <span class="math inline">\(\boldsymbol{\beta}_t\)</span> appears in 3 terms, namely it’s , the , and in the . The product of these distributions looks like</p>
<p><span class="math display">\[\begin{equation*}
\textcolor{Emerald}{MVN(\textbf{Y}_t \mid \textbf{X}_t \boldsymbol{\beta}_t, \sigma^2 \textbf{I}_N)} \times \textcolor{OrangeRed}{MVN(\boldsymbol{\beta}_t \mid \boldsymbol{\beta}_{t - 1},  \boldsymbol{\Sigma} _\eta)} \times \textcolor{RoyalBlue}{MVN(\boldsymbol{\beta}_{t + 1} \mid \boldsymbol{\beta}_t,  \boldsymbol{\Sigma} _\eta)}
\end{equation*}\]</span></p>
<p>Again, we will expand this product, only paying attention to the terms in the exponent so we can incomplete the square. We have</p>
<p><span class="math display">\[\begin{align*}
&amp;\textcolor{Emerald}{MVN(\textbf{Y}_t \mid \textbf{X}_t \boldsymbol{\beta}_t, \sigma^2 \textbf{I}_N)} \times \textcolor{OrangeRed}{MVN(\boldsymbol{\beta}_t \mid \boldsymbol{\beta}_{t - 1},  \boldsymbol{\Sigma} _\eta)} \times \textcolor{RoyalBlue}{MVN(\boldsymbol{\beta}_{t + 1} \mid \boldsymbol{\beta}_t,  \boldsymbol{\Sigma} _\eta)} \\
&amp;\propto \textcolor{Emerald}{\exp \left((\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)^\top (\sigma^2 \textbf{I}_N)^{-1}(\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)\right)} \times \textcolor{OrangeRed}{\exp \left((\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1}(\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})\right)} \\
&amp;\quad \times \textcolor{RoyalBlue}{\exp \left((\boldsymbol{\beta}_{t+1} - \boldsymbol{\beta}_t)^\top  \boldsymbol{\Sigma} _\eta^{-1}(\boldsymbol{\beta}_{t+1} - \boldsymbol{\beta}_t)\right)} \\
&amp;= \exp \left(\textcolor{Emerald}{(\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)^\top (\sigma^2 \textbf{I}_N)^{-1}(\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)} + \textcolor{OrangeRed}{(\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1}(\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})} \right. \\
&amp;\quad \left. + \textcolor{RoyalBlue}{(\boldsymbol{\beta}_{t+1} - \boldsymbol{\beta}_t)^\top  \boldsymbol{\Sigma} _\eta^{-1}(\boldsymbol{\beta}_{t+1} - \boldsymbol{\beta}_t)} \right) \\
&amp;= \exp \left( \textcolor{Emerald}{\textbf{Y}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{Y}_t - \textbf{Y}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{X}_t \boldsymbol{\beta}_t - \boldsymbol{\beta}_t^\top \textbf{X}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{Y}_t + \boldsymbol{\beta}_t^\top \textbf{X}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{X}_t \boldsymbol{\beta}_t} \right. \\
&amp;\quad \left. + \textcolor{OrangeRed}{\boldsymbol{\beta}_t^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_t - \boldsymbol{\beta}_t^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t-1} - \boldsymbol{\beta}_{t-1}^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_t + \boldsymbol{\beta}_{t-1}^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t-1}} \right. \\
&amp;\quad \left. + \textcolor{RoyalBlue}{\boldsymbol{\beta}_{t+1}^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t+1} - \boldsymbol{\beta}_{t+1}^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_t - \boldsymbol{\beta}_t^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t+1} + \boldsymbol{\beta}_t^\top  \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_t} \right)
\end{align*}\]</span></p>
<p>Now we just need to pay attention to the terms of the form <span class="math inline">\(\boldsymbol{\beta}_t^\top \textbf{V}^{-1} \boldsymbol{\beta}_t\)</span> and <span class="math inline">\(- \boldsymbol{\beta}_t^\top \textbf{v}\)</span> to identify <span class="math inline">\(\textbf{V}^{-1}\)</span> and <span class="math inline">\(\textbf{v}\)</span>. Combining like terms gives us</p>
<p><span class="math display">\[\begin{equation*}
\propto \exp \left( \boldsymbol{\beta}_t^\top (\textcolor{Emerald}{\textbf{X}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{X}_t} + \textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\eta^{-1}} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1}}) \boldsymbol{\beta}_t^\top - \boldsymbol{\beta}_0^\top (\textcolor{Emerald}{\textbf{X}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{Y}_t} + \textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t-1}} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t+1}}) \cdots \right)
\end{equation*}\]</span></p>
<p>So we have that</p>
<p><span class="math display">\[\begin{align*}
\begin{gathered}
\textbf{V}^{-1} = (\textcolor{Emerald}{\textbf{X}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{X}_t} + \textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\eta^{-1}} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1}}) \\
\textbf{v}= (\textcolor{Emerald}{\textbf{X}_t^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{Y}_t} + \textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t-1}} + \textcolor{RoyalBlue}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{t+1}})
\end{gathered}
\end{align*}\]</span></p>
<p>and we can sample <span class="math inline">\(\boldsymbol{\beta}_t\)</span> from it’s full conditional distribution as <span class="math inline">\(MVN(\textbf{V}\textbf{v}, \textbf{V})\)</span>.</p>
</section>
<section id="update-boldsymbolbeta_t" class="level2">
<h2 class="anchored" data-anchor-id="update-boldsymbolbeta_t">Update <span class="math inline">\(\boldsymbol{\beta}_T\)</span></h2>
<p>To update <span class="math inline">\(\boldsymbol{\beta}_T\)</span>, we follow the same steps as for <span class="math inline">\(\boldsymbol{\beta}_t\)</span>, <span class="math inline">\(t = 1, \ldots, (T-1)\)</span>, except the terms are no longer used, since there is no <span class="math inline">\(T + 1\)</span> time point. We will then have</p>
<p><span class="math display">\[\begin{align*}
\begin{gathered}
\textbf{V}^{-1} = (\textcolor{Emerald}{\textbf{X}_T^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{X}_T} + \textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\eta^{-1}}) \\
\textbf{v}= (\textcolor{Emerald}{\textbf{X}_T^\top (\sigma^2 \textbf{I}_N)^{-1} \textbf{Y}_T} + \textcolor{OrangeRed}{ \boldsymbol{\Sigma} _\eta^{-1} \boldsymbol{\beta}_{T-1}})
\end{gathered}
\end{align*}\]</span></p>
<p>and we can sample <span class="math inline">\(\boldsymbol{\beta}_T\)</span> from it’s full conditional distribution as <span class="math inline">\(MVN(\textbf{V}\textbf{v}, \textbf{V})\)</span>.</p>
</section>
<section id="update-sigma2" class="level2">
<h2 class="anchored" data-anchor-id="update-sigma2">Update <span class="math inline">\(\sigma^2\)</span></h2>
<p>Up until now, we have used normal likelihoods and priors to determine the normally distributed full conditional distributions for parameters of interest via completing the square. To update <span class="math inline">\(\sigma^2\)</span>, we will have to use a different form of conjugacy; the <span class="math inline">\(IG\)</span>-<span class="math inline">\(MVN\)</span> conjugacy. Here, the <span class="math inline">\(IG\)</span> prior on <span class="math inline">\(\sigma^2\)</span> times the <span class="math inline">\(MVN\)</span> likelihood for <span class="math inline">\(\textbf{Y}\)</span> yields another <span class="math inline">\(IG\)</span> full conditional distribution for <span class="math inline">\(\sigma^2\)</span>. It is our job then to determine what these new <span class="math inline">\(IG\)</span> parameters will be.</p>
<p>Looking at (<span class="math inline">\(\ref{eq:posterior}\)</span>), we see that <span class="math inline">\(\sigma^2\)</span> appears in <span class="math inline">\(T+1\)</span> many terms, namely it’s , and the . The product of these distributions looks like</p>
<p><span class="math display">\[\begin{equation*}
\textcolor{Emerald}{ \prod_{t=1}^T MVN(\textbf{Y}_t \mid \textbf{X}_t \boldsymbol{\beta}_t, \sigma^2 \textbf{I}_N)} \times \textcolor{DeepPink}{IG(\sigma^2 \mid a, b)}
\end{equation*}\]</span></p>
<p>From our knowledge of conjugate distributions, we know that the product of the <span class="math inline">\(IG\)</span> distribution with <span class="math inline">\(MVN\)</span> distributions should also be <span class="math inline">\(IG\)</span>. Recall the <span class="math inline">\(IG\)</span> pdf defined in (<span class="math inline">\(\ref{eq:ig}\)</span>). We will multiply these pdfs together, rearrange terms, and hopefully recover another <span class="math inline">\(IG\)</span> distribution with different parameter values. We have the following</p>
<p><span class="math display">\[\begin{align*}
&amp;\textcolor{Emerald}{ \prod_{t=1}^T MVN(\textbf{Y}_t \mid \textbf{X}_t \boldsymbol{\beta}_t, \sigma^2 \textbf{I}_N)} \times \textcolor{DeepPink}{IG(\sigma^2 \mid a, b)} \\
&amp;= \textcolor{Emerald}{\prod_{t=1}^T (2\pi)^{-N/2} |\sigma^2 \textbf{I}_N|^{-1/2} \exp \left( \frac{-1}{2\sigma^2} (\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)^\top (\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t) \right)} \times \textcolor{DeepPink}{\frac{b^a}{\Gamma (a)} (\sigma^2)^{-a - 1} \exp \left( \frac{-b}{\sigma^2} \right)} \\
&amp;\propto (\sigma^2)^{\textcolor{Emerald}{\frac{-NT}{2}} \textcolor{DeepPink}{-a -1}} \exp \left( - \frac{\textcolor{Emerald}{\frac{1}{2} \sum_{t = 1}^T (\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)^\top (\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)} \textcolor{DeepPink}{+ b}}{\sigma^2} \right)
\end{align*}\]</span></p>
<p>Here in the second step, we write the statement as <span class="math inline">\(\propto\)</span> because we are only interested in the components of the product that will become part of the <span class="math inline">\(IG\)</span> pdf. We also combined like terms, and we can now recognize the expression as an <span class="math inline">\(IG\)</span> distribution for <span class="math inline">\(\sigma^2\)</span>, with the following parameters</p>
<p><span class="math display">\[\begin{align*}
\tilde{a} &amp;= \textcolor{DeepPink}{a} + \textcolor{Emerald}{\frac{NT}{2}} \\
\tilde{b} &amp;= \textcolor{DeepPink}{b} + \textcolor{Emerald}{\frac{1}{2} \sum_{t = 1}^T (\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)^\top (\textbf{Y}_t - \textbf{X}_t \boldsymbol{\beta}_t)}
\end{align*}\]</span></p>
<p>and we can sample from <span class="math inline">\(\sigma^2\)</span>’s full conditional distribution as <span class="math inline">\(IG(\tilde{a}, \tilde{b})\)</span>.</p>
</section>
<section id="update-boldsymbolsigma-_eta" class="level2">
<h2 class="anchored" data-anchor-id="update-boldsymbolsigma-_eta">Update <span class="math inline">\( \boldsymbol{\Sigma} _\eta\)</span></h2>
<p>In this final step, we derive the full conditional distribution for <span class="math inline">\( \boldsymbol{\Sigma} _\eta\)</span>. One important thing to realize here is that <span class="math inline">\( \boldsymbol{\Sigma} _\eta\)</span> is a , not a scalar or vector as we have worked with before. A conjugate prior for a matrix-valued parameter to the multivariate normal is the Inverse-Wishart <span class="math inline">\(IW\)</span> prior (<span class="math inline">\(\ref{eq:iw}\)</span>). Here we use this prior, which will yield a full conditional distribution for <span class="math inline">\( \boldsymbol{\Sigma} _\eta\)</span> that is also distributed as <span class="math inline">\(IW\)</span>.</p>
<p>Looking at (<span class="math inline">\(\ref{eq:posterior}\)</span>), we have <span class="math inline">\( \boldsymbol{\Sigma} _\eta\)</span> appearing in <span class="math inline">\(T+1\)</span> many terms, namely it’s , and the . The product of these distributions looks like</p>
<p><span class="math display">\[\begin{equation*}
\textcolor{OrangeRed}{ \prod_{t=1}^T MVN(\boldsymbol{\beta}_t \mid \boldsymbol{\beta}_{t-1},  \boldsymbol{\Sigma} _\eta)} \times \textcolor{RoyalPurple}{IW( \boldsymbol{\Sigma} _\eta \mid \textbf{H}, \nu)}
\end{equation*}\]</span></p>
<p>Our goal now is to simplify the product of these pdfs, and get it in the form of a new <span class="math inline">\(IW\)</span> distribution where we can identify new parameters for the full conditional distribution. The product of these pdfs will be</p>
<p><span class="math display">\[\begin{align*}
&amp;\textcolor{OrangeRed}{ \prod_{t=1}^T MVN(\boldsymbol{\beta}_t \mid \boldsymbol{\beta}_{t-1},  \boldsymbol{\Sigma} _\eta)} \times \textcolor{RoyalPurple}{IW( \boldsymbol{\Sigma} _\eta \mid \textbf{H}, \nu)} \\
&amp;= \textcolor{OrangeRed}{\prod_{t=1}^T (2\pi)^{-P/2} | \boldsymbol{\Sigma} _\eta|^{-1/2} \exp \left( \frac{-1}{2} (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1} (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1}) \right)} \\
&amp;\quad \times \textcolor{RoyalPurple}{\frac{|\textbf{H}|^{\nu / 2}}{2^{\nu N / 2}  \Gamma_N \left( \frac{\nu}{2} \right)}  | \boldsymbol{\Sigma} _\eta|^{-(\nu + N + 1) / 2} \exp\left(-\frac{1}{2} \text{tr}\left( \textbf{H} \boldsymbol{\Sigma} _\eta^{-1} \right) \right)} \\
&amp;\propto | \boldsymbol{\Sigma} _\eta|^{-(\textcolor{OrangeRed}{T} + \textcolor{RoyalPurple}{\nu+P+1})/2} \exp \left( \frac{-1}{2} \left[ \underbrace{\textcolor{OrangeRed}{\sum_{t = 1}^T (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1} (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})}}_A + \textcolor{RoyalPurple}{\text{tr} ( \textbf{H} \boldsymbol{\Sigma} _\eta^{-1} )} \right] \right)
\end{align*}\]</span></p>
<p>We will now use a trick to massage the expression into the form of the <span class="math inline">\(IW\)</span> distribution. Since <span class="math inline">\(A\)</span> is evaluated as a scalar (sum of quadratic forms), we can take the of it without changing the expression (the trace of a scalar is the scalar itself). So we can write</p>
<p><span class="math display">\[\begin{align*}
\quad A &amp;= \textcolor{OrangeRed}{\sum_{t = 1}^T (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1} (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})} \\
\quad &amp;= \text{tr} \left( \textcolor{OrangeRed}{\sum_{t = 1}^T (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1} (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})} \right)
\end{align*}\]</span></p>
<p>We also know that the trace of a sum is equal to the sum of a trace, so we can move the trace operator inside the sum.</p>
<p><span class="math display">\[\begin{align*}
\quad &amp;=  \textcolor{OrangeRed}{\sum_{t = 1}^T} \text{tr} \left( \textcolor{OrangeRed}{(\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1} (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})} \right)
\end{align*}\]</span></p>
<p>Another useful identity of the trace operator is the following</p>
<p><span class="math display">\[\begin{equation*}
\text{tr} (\textbf{A}\textbf{B}\textbf{C}) = \text{tr} (\textbf{B}\textbf{C}\textbf{A}) = \text{tr} (\textbf{C}\textbf{A}\textbf{B})
\end{equation*}\]</span></p>
<p>Here, we can change the order of the product of matrices in a trace by moving the first matrix to the end of the product. Applying that above yields</p>
<p><span class="math display">\[\begin{align*}
\quad &amp;=  \textcolor{OrangeRed}{\sum_{t = 1}^T} \text{tr} \left( \textcolor{OrangeRed}{(\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1}) (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1}} \right)
\end{align*}\]</span></p>
<p>This is the form we want for <span class="math inline">\(A\)</span>, and plugging it back in gives</p>
<p><span class="math display">\[\begin{align*}
&amp;| \boldsymbol{\Sigma} _\eta|^{-(\textcolor{OrangeRed}{T} + \textcolor{RoyalPurple}{\nu+P+1})/2} \exp \left( \frac{-1}{2} \left[ \textcolor{OrangeRed}{\sum_{t = 1}^T} \text{tr} \left( \textcolor{OrangeRed}{(\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1}) (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top  \boldsymbol{\Sigma} _\eta^{-1}} \right)  + \textcolor{RoyalPurple}{\text{tr} ( \textbf{H} \boldsymbol{\Sigma} _\eta^{-1} )} \right] \right) \\
= &amp;| \boldsymbol{\Sigma} _\eta|^{-(\textcolor{OrangeRed}{T} + \textcolor{RoyalPurple}{\nu+P+1})/2} \exp \left( \frac{-1}{2} \text{tr} \left[ \left( \textcolor{OrangeRed}{\sum_{t = 1}^T (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1}) (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top} + \textcolor{RoyalPurple}{\textbf{H}} \right)  \boldsymbol{\Sigma} _\eta^{-1} \right] \right)
\end{align*}\]</span></p>
<p>which is in the same form as (<span class="math inline">\(\ref{eq:iw}\)</span>), with parameter values</p>
<p><span class="math display">\[\begin{align*}
\tilde{\nu} &amp;= \textcolor{RoyalPurple}{\nu} + \textcolor{OrangeRed}{T} \\
\tilde{\textbf{H}} &amp;= \textcolor{RoyalPurple}{\textbf{H}} + \textcolor{OrangeRed}{\sum_{t = 1}^T (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1}) (\boldsymbol{\beta}_t - \boldsymbol{\beta}_{t-1})^\top}
\end{align*}\]</span></p>
<p>and we can update <span class="math inline">\( \boldsymbol{\Sigma} _\eta\)</span> from its full conditional distribution as <span class="math inline">\(IW(\tilde{\textbf{H}}, \tilde{\nu})\)</span>.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>