<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-03-21 Fri 09:37 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>STT Prelim Study Guide</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Elliot Shannon" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<meta http-equiv='X-UA-Compatible' content='IE=edge'><meta content='width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no' name='viewport'><style>
  /* General styling */
  html {
    touch-action: manipulation;
    -webkit-text-size-adjust: 100%;
  }
  
  body {
    padding: 0;
    margin: 0 auto;
    background: #f9f9f9;
    color: #17202A;
    font-weight: normal;
    font-size: 15px;
    font-family: 'Ubuntu', 'Roboto', 'Arial', sans-serif;
    max-width: 800px; /* Limit the maximum width */
    line-height: 1.8;
  }
  
  h2, h3, h4, h5, h6 {
    font-family: 'Ubuntu', Verdana, sans-serif;
    color: #428bca;
    padding: 0;
    margin: 20px 0 10px 0;
    font-size: 1.1em;
  }
  
  h2 {
    margin: 30px 0 10px 0;
    font-size: 1.2em;
  }
  
  a {
    color: #5bc0de;
    text-decoration: none;
  }
  
  p {
    margin: 6px 0;
    text-align: justify;
  }
  
  ul, ol {
    margin: 10px 0;
    text-align: justify;
    padding-left: 20px;
  }
  
  ul > li > code {
    color: #586b82;
  }
  
  pre {
    white-space: pre-wrap;
  }
 
  /* Custom styling for TODO and DONE items */
  .todo {
    color: #d9534f; /* Color for TODO items */
  }
  
  .done {
    color: #5cb85c; /* Color for DONE items */
  }

  .MathJax {
    font-family: 'Computer Modern', serif;
  }

</style>
<style type="text/css">
@media print {
@page :left {
margin-right: 2cm;  /* Larger margin on right for notes */
margin-left: 8cm;   /* Smaller margin on left */
}
@page :right {
margin-left: 2cm;   /* Larger margin on left for notes */
margin-right: 8cm;  /* Smaller margin on right */
}
}
</style>
<style type="text/css">
@media print {
html, body {
zoom: 113%; /* Increase scale by 13% (adjust as needed) */
}
}
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">STT Prelim Study Guide</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org612575a">1. Linear Algebra</a>
<ul>
<li><a href="#orgf1872b1">1.1. Basic Elements of Linear Algebra</a></li>
<li><a href="#orgbdb14a6">1.2. Basic Concepts in Matrix Algebra</a></li>
<li><a href="#org4c5ae2a">1.3. Matrix Cookbook</a></li>
</ul>
</li>
<li><a href="#orga4a208a">2. STT 867 <code>[100%]</code></a>
<ul>
<li><a href="#orgf2647cd">2.1. <span class="done DONE">DONE</span> Least Squares, Gauss-Markov Theorem and extensions <code>[8/8]</code></a>
<ul>
<li><a href="#org47c5507"><span class="done DONE">DONE</span> Mulitple linear regression model</a></li>
<li><a href="#org7a8eecf"><span class="done DONE">DONE</span> Error-in-variables linear regression</a></li>
<li><a href="#org3e084be"><span class="done DONE">DONE</span> Ordinary least squares</a></li>
<li><a href="#org277a867"><span class="done DONE">DONE</span> Properties of \(\hat{\beta}\)</a></li>
<li><a href="#org7ba37d1"><span class="done DONE">DONE</span> Guass-Markov Theorem</a></li>
<li><a href="#org4d63e3f"><span class="done DONE">DONE</span> Method of Lagrange Multplier</a></li>
<li><a href="#org91bec9c"><span class="done DONE">DONE</span> Generalization of Gauss-Markov</a></li>
<li><a href="#orgf86a720"><span class="done DONE">DONE</span> Estimation of \(\sigma^2\)</a></li>
</ul>
</li>
<li><a href="#orgdf17076">2.2. <span class="done DONE">DONE</span> Hypothesis testing and confidence regions <code>[5/5]</code></a>
<ul>
<li><a href="#orgac25a63"><span class="done DONE">DONE</span> Testing \(H_0 : A\beta = m\) vs \(H_1 : A\beta \neq m\)</a></li>
<li><a href="#org63c93db"><span class="done DONE">DONE</span> Singular value decomposition</a></li>
<li><a href="#org148e75a"><span class="done DONE">DONE</span> Power of \(H_0 : A\beta = m\) vs \(H_1 : A\beta \neq m\)</a></li>
<li><a href="#orge6c197a"><span class="done DONE">DONE</span> Likelihood ratio test</a></li>
<li><a href="#org60ea873"><span class="done DONE">DONE</span> Confidence region for \(A\beta \in \mathbb{R}^r\) with coverage level \(1 - \alpha\)</a></li>
</ul>
</li>
<li><a href="#org2f7f464">2.3. <span class="done DONE">DONE</span> Simultaneous confidence intervals <code>[2/2]</code></a>
<ul>
<li><a href="#orgba751e7"><span class="done DONE">DONE</span> Lemma A</a></li>
<li><a href="#org878d746"><span class="done DONE">DONE</span> Scheffes Simultaneous C.I. for \(l'\beta\)</a></li>
</ul>
</li>
<li><a href="#org8cfae55">2.4. <span class="done DONE">DONE</span> Maximum Likelihood Estimation</a></li>
<li><a href="#orge023450">2.5. <span class="done DONE">DONE</span> Less-than-full-rank linear models <code>[3/3]</code></a>
<ul>
<li><a href="#orgd5739e0"><span class="done DONE">DONE</span> One-way ANOVA example</a></li>
<li><a href="#org9e00304"><span class="done DONE">DONE</span> Generalized inverse of a matrix</a></li>
<li><a href="#orgc87d7ea"><span class="done DONE">DONE</span> Properties under less-than-full-rank model</a></li>
</ul>
</li>
<li><a href="#orgce7392d">2.6. <span class="done DONE">DONE</span> Estimable/Testable linear functions <code>[10/10]</code></a>
<ul>
<li><a href="#org379321b"><span class="done DONE">DONE</span> Estimability</a></li>
<li><a href="#orge2c6b59"><span class="done DONE">DONE</span> Identifiability</a></li>
<li><a href="#org196fbc3"><span class="done DONE">DONE</span> Estimable linear functions \(a'\beta\)</a></li>
<li><a href="#orga0ae14e"><span class="done DONE">DONE</span> Gauss-Markov theorem for \(a'\beta\)</a></li>
<li><a href="#org36531a4"><span class="done DONE">DONE</span> Testable hypothesis</a></li>
<li><a href="#orgcd321c8"><span class="done DONE">DONE</span> Confidence region for \(A\beta\)</a></li>
<li><a href="#org7a66d30"><span class="done DONE">DONE</span> Two-way ANOVA model</a></li>
<li><a href="#org72e7005"><span class="done DONE">DONE</span> Simultaneous confidence interval for estimable linear functions</a></li>
<li><a href="#org8755721"><span class="done DONE">DONE</span> Bonferroni's intervals</a></li>
<li><a href="#org8b1ed6e"><span class="done DONE">DONE</span> Sidaks Intervals</a></li>
</ul>
</li>
<li><a href="#org24ef16e">2.7. <span class="done DONE">DONE</span> Distributional properties of quadratic forms <code>[10/10]</code></a>
<ul>
<li><a href="#org6fb0d0d"><span class="done DONE">DONE</span> Lemma 1</a></li>
<li><a href="#org8a9c1a0"><span class="done DONE">DONE</span> Spectral Decomposition</a></li>
<li><a href="#org2cf60f9"><span class="done DONE">DONE</span> Theorem 1</a></li>
<li><a href="#orgbe0e7b1"><span class="done DONE">DONE</span> Moment generating function</a></li>
<li><a href="#orgc0ecc4c"><span class="done DONE">DONE</span> Corollary \(A \in \mathbb{R}^{n \times n}\)</a></li>
<li><a href="#org378d453"><span class="done DONE">DONE</span> Theorem 2 (Craig's Theorem)</a></li>
<li><a href="#orgf2c144a"><span class="done DONE">DONE</span> Theorem 3.9 Khuri</a></li>
<li><a href="#orge0a293c"><span class="done DONE">DONE</span> Theorem 3</a></li>
<li><a href="#org1da298f"><span class="done DONE">DONE</span> Partitioning the sum of squares <code>[1/1]</code></a></li>
<li><a href="#org555fcd7"><span class="done DONE">DONE</span> Cochran's theorem</a></li>
</ul>
</li>
<li><a href="#org39cb298">2.8. <span class="done DONE">DONE</span> Model selection and prediction <code>[10/10]</code></a>
<ul>
<li><a href="#orga5f1cca"><span class="done DONE">DONE</span> Expected prediction error</a></li>
<li><a href="#org0ddca7f"><span class="done DONE">DONE</span> Prediction <code>[2/2]</code></a></li>
<li><a href="#org08abe2c"><span class="done DONE">DONE</span> Bias-variance tradeoff</a></li>
<li><a href="#orgc437a23"><span class="done DONE">DONE</span> Goodness of Fit <code>[2/2]</code></a></li>
<li><a href="#orgbc2a9cd"><span class="done DONE">DONE</span> Predicition error <code>[2/2]</code></a></li>
<li><a href="#orgc3d4da0"><span class="done DONE">DONE</span> Degrees of freedom of given prediction method</a></li>
<li><a href="#org08d5926"><span class="done DONE">DONE</span> Cross validation</a></li>
<li><a href="#org2f4555a"><span class="done DONE">DONE</span> Information Criterion <code>[6/6]</code></a></li>
<li><a href="#orgab5e80e"><span class="done DONE">DONE</span> Comparison of model selection criteria for linear regression model</a></li>
<li><a href="#org0512a10"><span class="done DONE">DONE</span> Subset selection</a></li>
</ul>
</li>
<li><a href="#org0b724ca">2.9. <span class="done DONE">DONE</span> Shrinkage methods <code>[3/3]</code></a>
<ul>
<li><a href="#org93619e0"><span class="done DONE">DONE</span> James-Stein estimator</a></li>
<li><a href="#org40ea263"><span class="done DONE">DONE</span> Ridge Regression</a></li>
<li><a href="#orgdae9087"><span class="done DONE">DONE</span> The Lasso</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga1f6fd0">3. STT 868 <code>[100%]</code></a>
<ul>
<li><a href="#org1ef9211">3.1. <span class="done DONE">DONE</span> Model Identifiability <code>[10/10]</code></a>
<ul>
<li><a href="#orgc7bc65f"><span class="done DONE">DONE</span> One-way ANOVA model</a></li>
<li><a href="#orgd7cef2d"><span class="done DONE">DONE</span> Variance componenets models</a></li>
<li><a href="#org4030897"><span class="done DONE">DONE</span> Properties of random effects</a></li>
<li><a href="#org1f19cf4">Deciding between fixed and random effects</a></li>
<li><a href="#org39d1666"><span class="done DONE">DONE</span> Random intercept model</a></li>
<li><a href="#org17776a3"><span class="done DONE">DONE</span> Linear mixed model</a></li>
<li><a href="#org96e7cbb"><span class="done DONE">DONE</span> Identifiability definition</a></li>
<li><a href="#org9a142c2"><span class="done DONE">DONE</span> Identifiability theorem for LMM</a></li>
<li><a href="#orga18d8dc"><span class="done DONE">DONE</span> Kronecker Product</a></li>
<li><a href="#orgb7823ba"><span class="done DONE">DONE</span> Vectorization</a></li>
<li><a href="#orgd7719be"><span class="done DONE">DONE</span> Schur Complement Condition</a></li>
</ul>
</li>
<li><a href="#org8849735">3.2. <span class="done DONE">DONE</span> MLE, ANOVA estimation, MINQUE, RMLE <code>[7/7]</code></a>
<ul>
<li><a href="#org8ce39a3"><span class="done DONE">DONE</span> Log-likelihood of LMM</a></li>
<li><a href="#org07f9e7e"><span class="done DONE">DONE</span> MLE \(\hat{\beta}\) <code>[2/2]</code></a></li>
<li><a href="#org65bacb0"><span class="done DONE">DONE</span> MLE \(\hat{\sigma}^2\)</a></li>
<li><a href="#org1f93338"><span class="done DONE">DONE</span> Derivatives of log-likelihood function</a></li>
<li><a href="#orgdc903c3"><span class="done DONE">DONE</span> Balanced random coefficient model <code>[3/3]</code></a></li>
<li><a href="#org5e0bec0"><span class="done DONE">DONE</span> Existence of MLE</a></li>
<li><a href="#org342af40"><span class="done DONE">DONE</span> LMM with random intercept <code>[3/3]</code></a></li>
</ul>
</li>
<li><a href="#org471caef">3.3. <span class="done DONE">DONE</span> Computation and optimization <code>[9/9]</code></a>
<ul>
<li><a href="#orgf557648"><span class="done DONE">DONE</span> Gradient methods <code>[4/4]</code></a></li>
<li><a href="#org4a5e476"><span class="done DONE">DONE</span> Convergence issues</a></li>
<li><a href="#org82a3571"><span class="done DONE">DONE</span> Rate of Convergence</a></li>
<li><a href="#org2d573e6"><span class="done DONE">DONE</span> Expectation-Maximization algorithm</a></li>
<li><a href="#orgbad8a88"><span class="done DONE">DONE</span> Fisher Scoring Algorithm</a></li>
<li><a href="#orgf8e9de0"><span class="done DONE">DONE</span> RMLE in LMM</a></li>
<li><a href="#org213787e"><span class="done DONE">DONE</span> MINQUE in LMM</a></li>
<li><a href="#org80eb2a4"><span class="done DONE">DONE</span> ANOVA Estimation</a></li>
<li><a href="#orged81b08"><span class="done DONE">DONE</span> A general method of moments</a></li>
</ul>
</li>
<li><a href="#org1564b2b">3.4. <span class="done DONE">DONE</span> Hypothesis testing and confidence intervals <code>[6/6]</code></a>
<ul>
<li><a href="#orgeb942b2"><span class="done DONE">DONE</span> F test</a></li>
<li><a href="#org2c21e3a"><span class="done DONE">DONE</span> Likelihood ratio test</a></li>
<li><a href="#org9f74e33"><span class="done DONE">DONE</span> C.I. for \(\sigma^2\) in LMM</a></li>
<li><a href="#org17659e2"><span class="done DONE">DONE</span> Confidence region for \(D \in \mathbb{R}^{k \times k}\)</a></li>
<li><a href="#orgb357343"><span class="done DONE">DONE</span> C.I. for functions of \(\sigma^2\) and \(D\)</a></li>
<li><a href="#org28f9792"><span class="done DONE">DONE</span> Approximate C.I. for variance components <code>[2/2]</code></a></li>
</ul>
</li>
<li><a href="#org5a77854">3.5. <span class="done DONE">DONE</span> Generalized linear models <code>[6/6]</code></a>
<ul>
<li><a href="#org37a9069"><span class="done DONE">DONE</span> GLM Setup</a></li>
<li><a href="#org03a1d8a"><span class="done DONE">DONE</span> Exponential family distribution <code>[4/4]</code></a></li>
<li><a href="#org6ef6bbb"><span class="done DONE">DONE</span> Link Functions <code>[4/4]</code></a></li>
<li><a href="#org14d32e7"><span class="done DONE">DONE</span> log-likelihood for GLM</a></li>
<li><a href="#orga045866"><span class="done DONE">DONE</span> Fisher scoring algorithm</a></li>
<li><a href="#org721c0c4"><span class="done DONE">DONE</span> Inference in GLM <code>[4/4]</code></a></li>
</ul>
</li>
<li><a href="#org1d2272d">3.6. <span class="done DONE">DONE</span> Quasi-likelihood estimation <code>[3/3]</code></a>
<ul>
<li><a href="#orga36a180"><span class="done DONE">DONE</span> Review of MLE</a></li>
<li><a href="#org3cafa64"><span class="done DONE">DONE</span> Construction of Quasi-likelihood function</a></li>
<li><a href="#org4bb05a5"><span class="done DONE">DONE</span> Maximum quasi-likelihood estimation</a></li>
</ul>
</li>
<li><a href="#orgab57e5a">3.7. <span class="done DONE">DONE</span> Generalized linear mixed models <code>[10/10]</code></a>
<ul>
<li><a href="#org02679b9"><span class="done DONE">DONE</span> General setup</a></li>
<li><a href="#org1450002"><span class="done DONE">DONE</span> Mean</a></li>
<li><a href="#orgfef6b7d"><span class="done DONE">DONE</span> Variance</a></li>
<li><a href="#org5d2fc49"><span class="done DONE">DONE</span> Covariance</a></li>
<li><a href="#org1b4c153"><span class="done DONE">DONE</span> Likelihood function</a></li>
<li><a href="#orgfe69f55"><span class="done DONE">DONE</span> log-likelihood function</a></li>
<li><a href="#org0565ec1"><span class="done DONE">DONE</span> Gauss-hermite quadrecture</a></li>
<li><a href="#org66e106f"><span class="done DONE">DONE</span> EM algorithm for GLMM</a></li>
<li><a href="#orgd16aa19"><span class="done DONE">DONE</span> Markov Chain Monte Carlo algorithm</a></li>
<li><a href="#org4df1829"><span class="done DONE">DONE</span> Metropolis-Hastings algorithm</a></li>
</ul>
</li>
<li><a href="#org204d288">3.8. <span class="done DONE">DONE</span> Generalized estimation equations <code>[4/4]</code></a>
<ul>
<li><a href="#orgf00109a"><span class="done DONE">DONE</span> Estimating functions</a></li>
<li><a href="#org2c0e16f"><span class="done DONE">DONE</span> Class of linear estimating functions</a></li>
<li><a href="#org9997c88"><span class="done DONE">DONE</span> Optimal linear estimating equation</a></li>
<li><a href="#org9fbf39e"><span class="done DONE">DONE</span> Generalized estimating equation</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org4e43c95">4. STT 872 <code>[100%]</code></a>
<ul>
<li><a href="#org9ccd2fe">4.1. <span class="done DONE">DONE</span> Preparations <code>[9/9]</code></a>
<ul>
<li><a href="#org44773d1"><span class="done DONE">DONE</span> Measure Theory <code>[4/4]</code></a></li>
<li><a href="#orgd3fcf36"><span class="done DONE">DONE</span> Integration <code>[8/8]</code></a></li>
<li><a href="#org226f807"><span class="done DONE">DONE</span> Probability Spaces <code>[11/11]</code></a></li>
<li><a href="#org5829b89"><span class="done DONE">DONE</span> Group families <code>[5/5]</code></a></li>
<li><a href="#orgc70351a"><span class="done DONE">DONE</span> Exponential families <code>[5/5]</code></a></li>
<li><a href="#org338a73f"><span class="done DONE">DONE</span> Moment and cumulant generating functions <code>[7/7]</code></a></li>
<li><a href="#orgf7b21bc">Models, Estimators, and Risk Functions</a></li>
<li><a href="#org5c02c23"><span class="done DONE">DONE</span> Sufficient Statistics <code>[22/22]</code></a></li>
<li><a href="#org6ed6886"><span class="done DONE">DONE</span> Convexity <code>[10/10]</code></a></li>
<li><a href="#orgb739b08"><span class="done DONE">DONE</span> Large sample theory <code>[18/18]</code></a></li>
</ul>
</li>
<li><a href="#orgedbe639">4.2. <span class="done DONE">DONE</span> Unbiasedness <code>[5/5]</code></a>
<ul>
<li><a href="#org1174495"><span class="done DONE">DONE</span> Minimum Variance Unbiased Estimator <code>[9/9]</code></a></li>
<li><a href="#org75d4812"><span class="done DONE">DONE</span> Continuous distributions and UMVU <code>[4/4]</code></a></li>
<li><a href="#org80b18cf"><span class="done DONE">DONE</span> UMVU for discrete distributions <code>[8/8]</code></a></li>
<li><a href="#org2e80111"><span class="done DONE">DONE</span> Information inequality <code>[12/12]</code></a></li>
<li><a href="#org5929d2c"><span class="done DONE">DONE</span> Multiparameter information inequality <code>[5/5]</code></a></li>
</ul>
</li>
<li><a href="#org31d7093">4.3. <span class="done DONE">DONE</span> Equivariance <code>[1/1]</code></a>
<ul>
<li><a href="#orgb559a38"><span class="done DONE">DONE</span> First Examples <code>[26/26]</code></a></li>
</ul>
</li>
<li><a href="#org54614d3">4.4. <span class="done DONE">DONE</span> Average risk optimality <code>[6/6]</code></a>
<ul>
<li><a href="#org772f333"><span class="done DONE">DONE</span> Introduction <code>[5/5]</code></a></li>
<li><a href="#org1e6f266"><span class="done DONE">DONE</span> First examples <code>[7/7]</code></a></li>
<li><a href="#org08d7e75"><span class="done DONE">DONE</span> Single Prior Bayes <code>[3/3]</code></a></li>
<li><a href="#org87855e1"><span class="done DONE">DONE</span> Hierarchical Bayes <code>[5/5]</code></a></li>
<li><a href="#orgbce9b0a"><span class="done DONE">DONE</span> Empirical Bayes <code>[5/5]</code></a></li>
<li><a href="#orgd619015"><span class="done DONE">DONE</span> Shrinkage Estimators <code>[4/4]</code></a></li>
</ul>
</li>
<li><a href="#org876e59a">4.5. <span class="done DONE">DONE</span> Minimaxity and admissibility <code>[3/3]</code></a>
<ul>
<li><a href="#org9ee4c4a"><span class="done DONE">DONE</span> Admissibility <code>[5/5]</code></a></li>
<li><a href="#orgb628bf3"><span class="done DONE">DONE</span> Minimax Estimation <code>[12/12]</code></a></li>
<li><a href="#org42d3e76"><span class="done DONE">DONE</span> Admissibility and minimaxity in exponential families <code>[13/13]</code></a></li>
</ul>
</li>
<li><a href="#org8f7095c">4.6. <span class="done DONE">DONE</span> Uniformly most powerful tests <code>[6/6]</code></a>
<ul>
<li><a href="#org7da21f9"><span class="done DONE">DONE</span> Stating the problem <code>[1/1]</code></a></li>
<li><a href="#org6962660"><span class="done DONE">DONE</span> Neyman-Pearson Fundamental Lemma <code>[4/4]</code></a></li>
<li><a href="#orgc1c4f7c"><span class="done DONE">DONE</span> Distributions with monotone likelihood ratio <code>[8/8]</code></a></li>
<li><a href="#org2410426"><span class="done DONE">DONE</span> Confidence bounds <code>[6/6]</code></a></li>
<li><a href="#org3f06019"><span class="done DONE">DONE</span> A generalization of the fundamental lemma <code>[3/3]</code></a></li>
<li><a href="#org3d6cd9c"><span class="done DONE">DONE</span> Two-sided hypotheses <code>[2/2]</code></a></li>
</ul>
</li>
<li><a href="#org07d2609">4.7. <span class="done DONE">DONE</span> Unbiased tests <code>[5/5]</code></a></li>
</ul>
</li>
</ul>
</div>
</div>
<!-- Scroll to top button -->
<button onclick="topFunction()" id="scrollBtn" title="Go to top">&#9650;</button>

<style>
  #scrollBtn {
    display: none;
    position: fixed;
    bottom: 20px;
    right: 20px;
    z-index: 99;
    border: none;
    outline: none;
    background-color: #95A5A6;
    color: white;
    cursor: pointer;
    padding: 15px;
    border-radius: 50%;
    box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
    transition: background-color 0.3s, box-shadow 0.3s;
  }

  #scrollBtn:hover {
    background-color: #546E7A;
    box-shadow: 0px 0px 15px rgba(0, 0, 0, 0.2);
  }
</style>

<script>
  // Get the button
  var mybutton = document.getElementById("scrollBtn");

  // When the user scrolls down 20px from the top of the document, show the button
  window.onscroll = function() {scrollFunction()};

  function scrollFunction() {
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
      mybutton.style.display = "block";
    } else {
      mybutton.style.display = "none";
    }
  }

  // When the user clicks on the button, scroll to the top of the document
  function topFunction() {
    document.body.scrollTop = 0; // For Safari
    document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
  }
</script>

<div id="outline-container-org612575a" class="outline-2">
<h2 id="org612575a"><span class="section-number-2">1</span> Linear Algebra</h2>
<div class="outline-text-2" id="text-1">
</div>

<div id="outline-container-orgf1872b1" class="outline-3">
<h3 id="orgf1872b1"><span class="section-number-3">1.1</span> Basic Elements of Linear Algebra</h3>
<div class="outline-text-3" id="text-1-1">
<p>
<span class="underline">Chapter 2 in Khuri</span>
</p>

<p>
A <b>vector space</b> over \(\mathcal{R}\) is a set \(V\) of elements, which can be added or multiplied by scalars, in such a way that the sum of two elements of \(V\) is an element of \(V\), and the product of an element of \(V\) by a scalar is an element of \(V\). It also includes the zero element and negatives. 
</p>

<p>
For example, the set of all \(n\) -tuples is a vector space. 
</p>

<p>
Another example of a vector space is the set of all polynomials. 
</p>

<p>
A <b>vector subspace</b> is basically a subset of a vector space that is itself a vector space. So for example, the set of all polynomials of degree \(k\) or less is a vector subspace of the set of all polynomials. 
</p>

<p>
The intersection of two subspaces is also a subspace. This is not necessarily true for union. 
</p>

<p>
The elements of a vector space \(V\) can be represented as linear combinations of a set of elements of \(V\) that form a basis of \(V\). 
</p>

<p>
<b>Linearly dependent</b> means there is a linear combination of the elements that equal zero, where the coefficients in the linear combination are not all zero. The <b>linear span</b> of \(n\) elements in a vector space is the collection of all linear combinations of those elements. The linear span forms a vector subspace. 
</p>

<p>
The <b>basis</b> of a vector space \(V\) is formed by \(n\) many linearly independent elements in \(V\) whose linear span is equal to \(V\). This number \(n\) is called the <b>dimension</b> of \(V\). 
</p>

<p>
A function that maps one vector space to another vector space over \(\mathcal{R}\) is called a <b>linear transformation</b>. 
</p>

<div style="margin-bottom: 500px;"></div>
</div>
</div>


<div id="outline-container-orgbdb14a6" class="outline-3">
<h3 id="orgbdb14a6"><span class="section-number-3">1.2</span> Basic Concepts in Matrix Algebra</h3>
<div class="outline-text-3" id="text-1-2">
<p>
<span class="underline">Chapter 3 in Khuri</span>
</p>

<p>
For two matrices to be equal means that all of their elements are equal. 
</p>

<p>
When we take the <b>transpose</b> of a matrix, the rows become columns and the columns become rows. 
</p>

<p>
The <b>trace</b> of a matrix is the sum of its diagonal elements. We have \(tr(A) = tr(A^\prime)\).
</p>

<p>
Also \(tr(ABC) = tr(BCA) = tr(CAB)\)
</p>

<p>
\(tr(A - B) = tr(A) = tr(B)\)
</p>

<p>
For symmetrix matrix \(B\), \(tr(B) = \sum \text{eigenvalues}(B)\)
</p>

<p>
The <b>rank</b> of a matrix is the number of linearly independent rows (or columns). 
</p>

<p>
The <b>inverse</b> of a nonsingular matrix of order \(n \times n\), denoted by \(A^{-1}\), is an \(n \times n\) matrix that satisfies the condition \(AA^{-1} = A^{-1}A = I_n\). Such a matrix is unique. 
</p>

<p>
Properties of invserses include:
</p>

<ol class="org-ol">
<li>\((AB)^{-1} = B^{-1}A^{-1}\)</li>
<li>\((A^{\prime})^{-1} = (A^{-1})^{\prime}\)</li>
<li>\((A \otimes B)^{-1} = A^{-1} \otimes B^{-1}\)</li>
</ol>

<p>
A <b>generalized inverse</b> of an \(m \times n\) matrix \(A\) is any \(n \times m\) matrix \(B\) such that \(ABA = A\). We denote such a matrix by \(A^{-}\). 
</p>

<p>
A square matrix, \(A\), is <b>idempotent</b> if \(A^2 = A\).
</p>

<p>
For idempotent matrix \(A\), \(\text{rank}(A) = tr(A)\).
</p>

<p>
A square matrix of order \(n \times n\) is <b>orthogonal</b> if \(A^{\prime}A = I_n\).
</p>

<p>
To show a matrix \(D \in \mathbb{R}^{k \times k}\) is positive definite, show for any quadratic form \(d^{\prime}Dd\) with \(d \neq 0, d^{\prime}Dd > 0\).
</p>

<p>
<b>Woodbury Formula</b>: 
</p>

\begin{equation*}
A \in \mathbb{R}^{n \times n}, B \in \mathbb{R}^{n \times r}, C \in \mathbb{R}^{r \times r}, D \in \mathbb{R}^{r \times n} \\

(A + BDC)^{-1} = A^{-1} - A^{-1} B (D^{-1} + CA^{-1}B)^{-1} C A^{-1}
\end{equation*}

<div style="margin-bottom: 500px;"></div>
</div>
</div>


<div id="outline-container-org4c5ae2a" class="outline-3">
<h3 id="org4c5ae2a"><span class="section-number-3">1.3</span> Matrix Cookbook</h3>
<div class="outline-text-3" id="text-1-3">
<p>
<a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">Matrix Cookbook</a>
</p>

<p>
For any square matrix \(X\), we have 
</p>

\begin{equation*}
\frac{\partial \log |X|}{\partial X} = (X^{\prime})^{-1}
\end{equation*}

<p>
For any square matrix \(X\) and vectors \(a, b\), we have
</p>

\begin{equation*}
\frac{\partial (a^{\prime} X^{-1} b)}{\partial X} = -(X^{\prime})^{-1} a b^{\prime} (X^{\prime})^{-1}
\end{equation*}

<div style="margin-bottom: 500px;"></div>
</div>
</div>
</div>


<div id="outline-container-orga4a208a" class="outline-2">
<h2 id="orga4a208a"><span class="section-number-2">2</span> STT 867 <code>[100%]</code></h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orgf2647cd" class="outline-3">
<h3 id="orgf2647cd"><span class="section-number-3">2.1</span> <span class="done DONE">DONE</span> Least Squares, Gauss-Markov Theorem and extensions <code>[8/8]</code></h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-org47c5507" class="outline-4">
<h4 id="org47c5507"><span class="done DONE">DONE</span> Mulitple linear regression model</h4>
<div class="outline-text-4" id="text-org47c5507">
\begin{equation*}
Y_i = X_i ^\prime \beta + \varepsilon_i
\end{equation*}

<p>
<b>Linear</b> means linear with respect to the coefficients \(\beta\)
</p>

<p>
<b>Fixed design</b> is when \(X \in \mathbb{R}^{n \times p}\) is assumed to be fixed or non-random
</p>

<p>
<b>Response variable</b> is assumed to be continuous
</p>

<p>
<b>Simple linear regression</b> \(y_i = \beta_0 + x_i\beta_1 + \varepsilon_i\)
</p>

<p>
<b>Multivariate linear regression</b> is when we have multiple responses for each set of covariates
</p>
</div>
</div>

<div id="outline-container-org7a8eecf" class="outline-4">
<h4 id="org7a8eecf"><span class="done DONE">DONE</span> Error-in-variables linear regression</h4>
<div class="outline-text-4" id="text-org7a8eecf">
\begin{equation*}
Y = \tilde{X}\beta + \varepsilon \\
X = \tilde{X} + \tilde{\varepsilon}
\end{equation*}

<p>
We observe \(X\), not \(\tilde{X}\)
</p>
</div>
</div>

<div id="outline-container-org3e084be" class="outline-4">
<h4 id="org3e084be"><span class="done DONE">DONE</span> Ordinary least squares</h4>
<div class="outline-text-4" id="text-org3e084be">
<p>
Sum of squares (<b>Residuals</b>) \(|| Y - X\beta ||_2^2\)
</p>

<p>
The \(L_2\) norm of a vector \(a\) is \(||a||_2 = \sqrt{\sum_{i = 1}^{k} a_i^2}\)
</p>

<p>
Ordinary least squares (OLS) \(\hat{\beta} = \underset{\beta \in \mathbb{R}^p}{\mathrm{argmin}} ||Y - X\beta ||_2^2\)
</p>

<p>
Compute gradient, set equal to zero, check Hessian matrix is positive definite \(\Rightarrow \hat{\beta} = (X^\prime X)^{-1} X^\prime Y\)
</p>

<p>
\(\hat{\beta}\) exists and is unique
</p>
</div>
</div>

<div id="outline-container-org277a867" class="outline-4">
<h4 id="org277a867"><span class="done DONE">DONE</span> Properties of \(\hat{\beta}\)</h4>
<div class="outline-text-4" id="text-org277a867">
<p>
Assuming \(\mathbb{E}(\varepsilon) = 0\) and \(\text{Cov}(\varepsilon) = \sigma^2 I_{n \times n}\), then \(E(Y) = X\beta\) and \(\text{Var}(Y) = \sigma^2 I_n\) and 
</p>

<ol class="org-ol">
<li>\(\hat{\beta}\) is unbiased for \(\beta\)</li>
<li>\(\text{Var}(\hat{\beta}) = \sigma^2 (X^{\prime}X)^{-1}\)</li>
<li>\(c^\prime \hat{\beta}\) is unbiased for \(c^\prime \beta\)</li>
</ol>

<p>
If we also assume normallity of \(\varepsilon\), then we get
</p>

\begin{equation*}
\hat{\beta} \sim N(\beta, \sigma^2 (X^{\prime}X)^{-1})
\end{equation*}
</div>
</div>


<div id="outline-container-org7ba37d1" class="outline-4">
<h4 id="org7ba37d1"><span class="done DONE">DONE</span> Guass-Markov Theorem</h4>
<div class="outline-text-4" id="text-org7ba37d1">
<p>
Among all the unbiased estimates of a linear function of the parameters which are expressible as linear combinations of the observations (elements of the response vector \(Y\)), the one produced by the least-squares procedure has the minimum variance.
</p>


<p>
This tells us that \(c^\prime \hat{\beta}\) is the best linear unbiased estimator (BLUE) for \(c^\prime \beta\), assuming \(E(\varepsilon) = 0\) and \(\text{Var}(\varepsilon) = \sigma^2 I_n\). 
</p>

<p>
Here \(c^{\prime}\hat{\beta} = c^{\prime}(X^{\prime}X)^{-1} x^{\prime}Y\)
</p>

<p>
BLUE is unique if \(\sigma^2 > 0\) 
</p>
</div>
</div>

<div id="outline-container-org4d63e3f" class="outline-4">
<h4 id="org4d63e3f"><span class="done DONE">DONE</span> Method of <a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">Lagrange Multplier</a></h4>
<div class="outline-text-4" id="text-org4d63e3f">
<p>
Use this to turn constrained optimization problem into unconstrained problem.
</p>

<p>
We want to optimize a real valued function \(f(x_1, x_2, \ldots, x_n)\), where \(x_1, x_2, \ldots x_n\) are subject to \(m (< n)\) equality constraints of the form
</p>

\begin{equation*}
g_1(x_1, x_2, \ldots, x_n) = 0, \\
g_2(x_1, x_2, \ldots, x_n) = 0, \\
\vdots \\
g_m(x_1, x_2, \ldots, x_n) = 0, \\
\end{equation*}

<p>
where \(g_1, g_2, \ldots, g_m\) are differentiable functions. 
</p>

<p>
The determination of the stationary points in this constrained optimization problem is done by first considering the function
</p>

\begin{equation*}
F(\mathbf{x}) = f(\mathbf{x}) + \sum_{j - 1}^{m} \lambda_j g_j(\mathbf{x})
\end{equation*}

<p>
where \(\mathbf{x} = (x_1, x_2, \ldots, x_n)^\prime\) and \(\lambda_1, \lambda_2, \ldots, \lambda_m\) are scalars called <i>Lagrange multipliers</i>. By differentiating with respect to \(x_1, x_2, \ldots, x_n\) and equating the partial derivatives to zero, we obtain
</p>

\begin{equation*}
\frac{\partial F}{\partial x_i} = \frac{\partial f}{\partial x_i} + \sum_{j = 1}^m \frac{\partial g_j}{\partial x_i} = 0 \\
i = 1, 2, \ldots, n
\end{equation*}

<p>
Together with 
</p>

\begin{equation*}
g_1(x_1, x_2, \ldots, x_n) = 0, \\
g_2(x_1, x_2, \ldots, x_n) = 0, \\
\vdots \\
g_m(x_1, x_2, \ldots, x_n) = 0, \\
\end{equation*}

<p>
we have \(m + n\) equations for m + n unknowns (namely the \(x\)'s and \(\lambda\)'s). The solutions for \(x_1, x_2, \ldots, x_n\) determine the locations of the stationary points. 
</p>
</div>
</div>

<div id="outline-container-org91bec9c" class="outline-4">
<h4 id="org91bec9c"><span class="done DONE">DONE</span> Generalization of Gauss-Markov</h4>
<div class="outline-text-4" id="text-org91bec9c">
<p>
This basically extends GM theorem to the case of \(C \beta\), where \(C \in \mathbb{R}^{q \times p}\) and \(\beta \in \mathbb{R}^p\)
</p>

<p>
\(C \hat{\beta}\) is the unique BLUE for \(C \beta\)
</p>
</div>
</div>

<div id="outline-container-orgf86a720" class="outline-4">
<h4 id="orgf86a720"><span class="done DONE">DONE</span> Estimation of \(\sigma^2\)</h4>
<div class="outline-text-4" id="text-orgf86a720">
<p>
Use sample variance to estimate \(\sigma^2\) based on the residuals
</p>

<p>
Sample variance \(\frac{1}{n}\sum_{i = 1}^{n} \varepsilon_i^2\) is unbiased for \(\sigma^2\)
</p>

<p>
\(\text{MSE} = \frac{1}{n - p} \text{SSE}\) is unbiased for \(\sigma^2\)
</p>

<p>
\(\text{SSE} = ||Y - X\hat{\beta}||_2^2\) "residual sum of squares"
</p>
</div>
</div>
</div>

<div id="outline-container-orgdf17076" class="outline-3">
<h3 id="orgdf17076"><span class="section-number-3">2.2</span> <span class="done DONE">DONE</span> Hypothesis testing and confidence regions <code>[5/5]</code></h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-orgac25a63" class="outline-4">
<h4 id="orgac25a63"><span class="done DONE">DONE</span> Testing \(H_0 : A\beta = m\) vs \(H_1 : A\beta \neq m\)</h4>
<div class="outline-text-4" id="text-orgac25a63">
<p>
Assume \(A\) is of rank \(r\) and \(\varepsilon \sim N(0, \sigma^2 I_n)\).
</p>

<p>
Under \(H_0\),
</p>

\begin{equation*}
A\hat{\beta} \sim N(m, \sigma^2 A(X^{\prime}X)^{-1}A^{\prime}),
\end{equation*}

<p>
Weighted \(L_2\) distance between \(A\hat{\beta}\) and \(m\) is
</p>

\begin{equation*}
||(\sigma^2 A(X^\prime X)^{-1} A^\prime)^{-1/2} (A\hat{\beta} - m)||_2^2 \sim \chi^2_r
\end{equation*}

<p>
Or written differently,
</p>

\begin{equation*}
\frac{1}{\sigma^2}(A\hat{\beta} - m)^{\prime}(A(X^{\prime}X)^{-1}A^{\prime})^{-1}(A\hat{\beta} - m) \sim \chi^2_r
\end{equation*}


<p>
We don't know \(\sigma^2\), so replace with MSE. 
</p>

<p>
Using SVD, we find out
</p>

\begin{equation*}
\frac{(n-p)\text{MSE}}{\sigma^2} \sim \chi^2_{n - p}
\end{equation*}

<p>
We then know ratio of two independent \(\chi^2\) is \(F\) distributed. And because \(\hat{\beta} \perp \!\!\! \perp \text{MSE}\), we have
</p>

\begin{equation*}
F_{r, n-p} = \frac{\chi^2_r / r}{\chi^2_{n-p} / (n-p)} = \frac{(A\hat{\beta} - m)^\prime (A(X^\prime X)^{-1} A^\prime \text{MSE})^{-1}(A\hat{\beta} - m)}{r}
\end{equation*}

<p>
Reject when \(> F_{r, n-p}(1 - \alpha)\). (A large value of the test statsitic \(F\) leads to a rejection of \(H_0\)).
</p>
</div>
</div>

<div id="outline-container-org63c93db" class="outline-4">
<h4 id="org63c93db"><span class="done DONE">DONE</span> Singular value decomposition</h4>
<div class="outline-text-4" id="text-org63c93db">
<p>
For any given matrix \(Z \in \mathbb{R}^{m \times n}\) with rank \(r\), \(r \leq \text{min}(m, n)\), there exists
</p>

\begin{equation*}
Z = U\Sigma V^\prime \\
Z \in \mathbb{R}^{m \times n}, U \in \mathbb{R}^{m \times r}, \Sigma \in \mathbb{R}^{r \times r}, V^\prime \in \mathbb{R}^{r \times n}
\end{equation*}

<p>
where \(U^\prime U = V^\prime V = I_{r \times r}\)
</p>

<p>
\(\Sigma\) is diagonal matrix of singular values. 
</p>

<p>
Since \(U^\prime U = I_{r \times r}\), there exists \(\tilde{U} \in \mathbb{R}^{m \times (m - r)}\) such that \(\tilde{U}^\prime \tilde{U} = I_{(m - r) \times (m - r)}\) and \(U^\prime \tilde{U} = 0\). That is to say, the columns of \(U\) and \(\tilde{U}\) form a orthonormal basis for \(\mathbb{R}^n\). 
</p>
</div>
</div>

<div id="outline-container-org148e75a" class="outline-4">
<h4 id="org148e75a"><span class="done DONE">DONE</span> Power of \(H_0 : A\beta = m\) vs \(H_1 : A\beta \neq m\)</h4>
<div class="outline-text-4" id="text-org148e75a">
<p>
Remember
</p>

\begin{equation*}
\text{Power} = 1 - \text{Type-II Error}
\end{equation*}

<p>
In other words, power is the probability of rejecting when the alternative is true. This is a good thing, we want high power. 
</p>

<p>
So under the alternative, 
</p>

\begin{equation*}
\frac{(A\hat{\beta} - m)^\prime (A(X^\prime X)^{-1} A^\prime \text{MSE})^{-1}(A\hat{\beta} - m)}{r} \sim F_{r, n-p} (\lambda)
\end{equation*}

<p>
which is non-central \(F\) distribution with 
</p>

\begin{equation*}
\lambda = (m_1 - m)^\prime (\sigma^2 A (X^\prime X)^{-1} A^\prime)^{-1} (m_1 - m) \\
A\beta = m_1 \neq m
\end{equation*}

<p>
Then
</p>

\begin{equation*}
\begin{split}
\text{Power} & = 1 - \text{Type-II Error} \\
& = P(F > F_{r, n-p} (1 - \alpha) | \text{H}_1) \\
& = P(F_{r, n-p} (\lambda) > F_{r, n-p} (1 - \alpha))
\end{split}
\end{equation*}
</div>
</div>

<div id="outline-container-orge6c197a" class="outline-4">
<h4 id="orge6c197a"><span class="done DONE">DONE</span> Likelihood ratio test</h4>
<div class="outline-text-4" id="text-orge6c197a">
<p>
Likelihood ratio test statistic is
</p>

\begin{equation*}
T =  \frac{\underset{A \beta \ = m}{\mathrm{max}} \underset{\sigma^2}{\mathrm{max}} L(Y, X ; \beta, \sigma^2)}{\underset{\beta}{\mathrm{max}} \underset{\sigma^2}{\mathrm{max}} L(Y, X ; \beta, \sigma^2)}
\end{equation*}

<p>
The likelihood ratio test statistic and the \(F\) test statistic only differ by a constant.
</p>
</div>
</div>

<div id="outline-container-org60ea873" class="outline-4">
<h4 id="org60ea873"><span class="done DONE">DONE</span> Confidence region for \(A\beta \in \mathbb{R}^r\) with coverage level \(1 - \alpha\)</h4>
<div class="outline-text-4" id="text-org60ea873">
<p>
A <i>pivot</i> is a function of the data and the target quantity. 
</p>

<p>
Idea is to get the distribution of the pivot, then solve inequality with \((1 - \alpha)\) level quantile of distribution to get the quantity of interest. 
</p>

<p>
In \(r = 1\), we get an interval.
</p>

<p>
For \(r > 1\), we get an ellipsoid.
</p>

<p>
A \((1 - \alpha)100\%\) confidence region on \(A\beta\) is given by
</p>

\begin{equation*}
(A\hat{\beta} - A\beta)^{\prime} (A(X^{\prime}X)^{-1}A^{\prime})^{-1} (A\hat{\beta} - A\beta) \leq r \text{MSE} F_{\alpha, r, n-p}.
\end{equation*}

<p>
If instead we want a confidence interval for \(a^{\prime}\beta\), where \(a^{\prime}\) is a known vector of \(p\) elements, it would be more convenient to use the \(t\) -distribution to derive a \((1 - \alpha)100\%\) confidence interval on \(a^{\prime}\beta\) of the form
</p>

\begin{equation*}
a^{\prime}\hat{\beta} \pm t_{\frac{\alpha}{2}, n-p} (a^{\prime}(X^{\prime}X)^{-1} a \text{MSE})^{1/2}.
\end{equation*}

<p>
This is because
</p>

\begin{equation*}
\frac{a^{\prime}\hat{\beta} - a^{\prime}\beta}{(a^{\prime}(X^{\prime}X)^{-1} a \text{MSE})^{1/2}} \sim t_{n-p}
\end{equation*}
</div>
</div>
</div>

<div id="outline-container-org2f7f464" class="outline-3">
<h3 id="org2f7f464"><span class="section-number-3">2.3</span> <span class="done DONE">DONE</span> Simultaneous confidence intervals <code>[2/2]</code></h3>
<div class="outline-text-3" id="text-2-3">
<p>
We have discussed a confidence interval with coverage probability \(1 - \alpha\) for a particular linear function, \(a^{\prime}\beta\), of \(\beta\). In some cases, it may be desired to have confidence intervals on all linear functions of \(\beta\) of the form \(l^{\prime}\beta\), where \(l \in \mathbb{R}^p\), the \(p\) -dimensional Euclidean space, with a joint coverage probability of \(1 - \alpha\).
</p>
</div>
<div id="outline-container-orgba751e7" class="outline-4">
<h4 id="orgba751e7"><span class="done DONE">DONE</span> Lemma A</h4>
<div class="outline-text-4" id="text-orgba751e7">
<p>
For \(Z \in \mathbb{R}^m\),
</p>

\begin{equation*}
||Z||_2 \leq c \Longleftrightarrow |b^\prime Z| \leq ||b||_2 c \quad \forall b \in \mathbb{R}^m
\end{equation*}

<p>
The proof follows from Cauchy-Schwarz
</p>
</div>
</div>

<div id="outline-container-org878d746" class="outline-4">
<h4 id="org878d746"><span class="done DONE">DONE</span> Scheffes Simultaneous C.I. for \(l'\beta\)</h4>
<div class="outline-text-4" id="text-org878d746">
\begin{equation*}
l^\prime \hat{\beta} \pm \sqrt{p \cdot \text{MSE} \cdot F_{p, n-p}(1 - \alpha) \cdot l^\prime (X^\prime X)^{-1}l} \quad \forall l \in \mathbb{R}^p
\end{equation*}
</div>
</div>
</div>

<div id="outline-container-org8cfae55" class="outline-3">
<h3 id="org8cfae55"><span class="section-number-3">2.4</span> <span class="done DONE">DONE</span> Maximum Likelihood Estimation</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Multivariate normal pdf for \(Y \sim N(\mu, \Sigma)\)
</p>

\begin{equation*}
\frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \text{exp} \left(\frac{-1}{2} (Y - \mu)^\prime \Sigma^{-1} (Y - \mu) \right)
\end{equation*}

<p>
Review derivative theorems p. 53 Khuri
</p>
</div>
</div>

<div id="outline-container-orge023450" class="outline-3">
<h3 id="orge023450"><span class="section-number-3">2.5</span> <span class="done DONE">DONE</span> Less-than-full-rank linear models <code>[3/3]</code></h3>
<div class="outline-text-3" id="text-2-5">
<p>
In less-than-full rank setting, \(X^{\prime}X\) is no longer nonsingular so we can't have \(\hat{\beta}\) as we have calculated before (we can't estimate \(\beta\) with \(\hat{\beta}\)).
</p>
</div>
<div id="outline-container-orgd5739e0" class="outline-4">
<h4 id="orgd5739e0"><span class="done DONE">DONE</span> One-way ANOVA example</h4>
<div class="outline-text-4" id="text-orgd5739e0">
\begin{equation*}
y_{ij} = \mu + \alpha_i + \varepsilon_{ij}, \quad i = 1, 2, \ldots, k, \quad j = 1, 2, \ldots, n_i
\end{equation*}

<p>
In the one-way ANOVA model, the model matrix \(X\) is not full rank. The rank of \(X\) is \(k < k + 1\).
</p>
</div>
</div>

<div id="outline-container-org9e00304" class="outline-4">
<h4 id="org9e00304"><span class="done DONE">DONE</span> Generalized inverse of a matrix</h4>
<div class="outline-text-4" id="text-org9e00304">
<p>
Given a matrix \(A \in \mathbb{R}^{m \times n}\), a <b>generalized inverse</b> of \(A\) is any \(B \in \mathbb{R}^{n \times n}\) such that \(ABA = A\).
</p>

<p>
We denote the generalized inverse by \(A^-\).
</p>

<p>
The generalized inverse <span class="underline">exists</span> for any matrix \(A \in \mathbb{R}^{m \times n}\)
</p>

<p>
The generalized inverse may not be unique.
</p>

<p>
If \(A\) is square and invertible, \(B = A^{-1}\).
</p>
</div>
</div>

<div id="outline-container-orgc87d7ea" class="outline-4">
<h4 id="orgc87d7ea"><span class="done DONE">DONE</span> Properties under less-than-full-rank model</h4>
<div class="outline-text-4" id="text-orgc87d7ea">
<p>
\(X \hat{\beta}\) is unique (recall \(\hat{\beta}\) is not unique). 
</p>

<p>
\(X \hat{\beta}\) can be considered as a projection from \(Y\) onto the subspace \(\{ \lambda \in \mathbb{R}^n : \lambda = X\beta \quad \forall \beta \}\).
</p>

<p>
\(X(X^\prime X)^- X^\prime\) is not unique.
</p>

<p>
In the full rank model case, \(X \hat{\beta} = X(X^\prime X)^{-1} X^\prime Y\).
</p>

<p>
In the less-than-full-rank model case, \(X \hat{\beta} = X(X^\prime X)^- X^\prime Y\).
</p>

\begin{equation*}
\hat{\beta} = (X^\prime X)^- X^\prime Y
\end{equation*}

<p>
In the less-than-full-rank model, 
</p>

\begin{equation*}
\text{MSE} = \frac{\text{SSE}}{n - r}
\end{equation*}

<p>
is unbiased for \(\sigma^2\), where \(\text{rank}(X) = r < p, \quad X \in \mathbb{R}^{n \times p}\).
</p>
</div>
</div>
</div>

<div id="outline-container-orgce7392d" class="outline-3">
<h3 id="orgce7392d"><span class="section-number-3">2.6</span> <span class="done DONE">DONE</span> Estimable/Testable linear functions <code>[10/10]</code></h3>
<div class="outline-text-3" id="text-2-6">
<p>
Under less-than-full-rank linear model, the regression coefficient \(\beta\) is not estimable. This is because \(X\) is not full column rank. Therefore, we could come up with infinitely estimates for \(\beta\) such that \(X\beta^\ast = x\tilde{\beta}\). Both \(\beta^\ast\) and \(\tilde{\beta}\) give the same distribution for our data \((X, Y)\). 
</p>

<p>
Hence, not every linear function of \(\beta\) of the form \(a^{\prime}\beta\) can be estimated. There are, however, certain conditions on \(a\) under which \(a^{\prime}\beta\) can be estimated. 
</p>
</div>

<div id="outline-container-org379321b" class="outline-4">
<h4 id="org379321b"><span class="done DONE">DONE</span> Estimability</h4>
<div class="outline-text-4" id="text-org379321b">
<p>
We want to know if a linear function \(a^\prime \beta\) is estimable. We have
</p>

\begin{align*}
a^\prime \beta \text{ is estimable } & \Longleftrightarrow \text{ if } X\beta_1 = X\beta_2 \text{ then } a^\prime \beta_1 = a^\prime \beta_2 \\ & \Longleftrightarrow \text{ if } X(\beta_1 - \beta_2) = 0 \text{ then } a^\prime (\beta_1 - \beta_2) = 0 \\ & \Longleftrightarrow a \text{ belongs to the rowspace of } X \\ & \Longleftrightarrow a^\prime = b^\prime X \text{ for some } b
\end{align*}

<p>
If \(a^{\prime}\beta\) is estimable, then \(a^{\prime}\hat{\beta} = a^{\prime}(X^{\prime}X)^{-} X^{\prime}Y\) is invariant to the choice of (X<sup>&prime;</sup>X)^-.
</p>
</div>
</div>

<div id="outline-container-orge2c6b59" class="outline-4">
<h4 id="orge2c6b59"><span class="done DONE">DONE</span> Identifiability</h4>
<div class="outline-text-4" id="text-orge2c6b59">
<p>
If \(\beta\) is not estimable, then the model is not identifiable.
</p>
</div>
</div>

<div id="outline-container-org196fbc3" class="outline-4">
<h4 id="org196fbc3"><span class="done DONE">DONE</span> Estimable linear functions \(a'\beta\)</h4>
<div class="outline-text-4" id="text-org196fbc3">
<p>
If \(a^\prime \beta\) is estimable, then \(a^\prime \hat{\beta}\) is unique. 
</p>
</div>
</div>

<div id="outline-container-orga0ae14e" class="outline-4">
<h4 id="orga0ae14e"><span class="done DONE">DONE</span> Gauss-Markov theorem for \(a'\beta\)</h4>
<div class="outline-text-4" id="text-orga0ae14e">
<p>
Assume \(E(\varepsilon) = 0\), \(\text{Cov}(\varepsilon) = \sigma^2 I\).
</p>

<p>
Suppose \(a^\prime \beta\) is estimable.
</p>

<p>
Then \(a^\prime \hat{\beta}\) is the unique BLUE, where \(\hat{\beta}\) is any OLS solution. 
</p>

<p>
The proof of this uses a clever transformation to turn the problem into the full-rank case. 
</p>
</div>
</div>

<div id="outline-container-org36531a4" class="outline-4">
<h4 id="org36531a4"><span class="done DONE">DONE</span> Testable hypothesis</h4>
<div class="outline-text-4" id="text-org36531a4">
\begin{equation*}
\text{A hypothesis is testable} \Longleftrightarrow A\beta \text{ is estimable}
\end{equation*}

\begin{equation*}
H_0: A\beta = m \quad H_1: A\beta \neq m \\
A \in \mathbb{R}^{s \times p}
\end{equation*}

<p>
\(A\beta\) being estimable means each component \(a_i^\prime \beta\) is estimable. 
</p>

<ol class="org-ol">
<li>If \(H_0 : A\beta = m\) is testable, then \(\text{rank}(A) \leq r = \text{rank}(X)\).</li>
<li>\(H_0 : A\beta = m\) is testable \(\Leftrightarrow \exists S \in \mathbb{R}^{s \times p}\) such that \(A = SX^\prime X\).</li>
</ol>

<p>
In less-than-full-rank linear model, 
</p>

\begin{equation*}
A\hat{\beta} \sim N(A\beta, \sigma^2 A(X^\prime X)^- A^\prime)
\end{equation*}

\begin{equation*}
F = \frac{(A\hat{\beta} - m)^\prime (A(X^\prime X)A^\prime)^- (A\hat{\beta})}{\text{MSE} \cdot s} \sim F_{s, n-r} \quad \text{under } H_0
\end{equation*}

\begin{equation*}
\text{Rejection Region } R = \{F > F_{s, n-r}(1 - \alpha) \}
\end{equation*}

\begin{equation*}
F \sim F_{s, n-r}(\lambda) \quad \text{ under } H_1 \\
\lambda = \frac{1}{\sigma^2} (m_1 - m)^\prime (A(X^\prime X)^- A^\prime)^{-1} (m_1 - m)
\end{equation*}

<p>
This generalization of the \(F\) test statistic recovers what we have shown in the full-rank model case (i.e. when \(r = p\)).
</p>
</div>
</div>
<div id="outline-container-orgcd321c8" class="outline-4">
<h4 id="orgcd321c8"><span class="done DONE">DONE</span> Confidence region for \(A\beta\)</h4>
<div class="outline-text-4" id="text-orgcd321c8">
<p>
We have \(H_0 : A\beta = m\) versus \(H_1 : A\beta \neq m\), and we assume \(A\beta\) is estimable and \(\varepsilon \sim N(0, \sigma^2 I_n)\). We have that
</p>

\begin{equation*}
A\hat{\beta} \sim N(A\beta, A(X^{\prime}X)^- A^{\prime} \sigma^2)
\end{equation*}

<p>
And under \(H_0\),
</p>

\begin{equation*}
F = \frac{(A\hat{\beta} - m)^{\prime}(A(X^{\prime}X)^- A^{\prime})^{-1}(A\hat{\beta} - m)}{\text{rank}(A) \text{MSE}} \sim F_{\text{rank}(A), n-\text{rank}(X)}
\end{equation*}

<p>
So the \((1 - \alpha)100\%\) confidence region on \(A\beta\) is given by
</p>

\begin{equation*}
\frac{(A\hat{\beta} - m)^{\prime}(A(X^{\prime}X)^- A^{\prime})^{-1}(A\hat{\beta} - m)}{\text{rank}(A) \text{MSE}} \leq F_{\text{rank}(A), n - \text{rank}(X)}(1 - \alpha)
\end{equation*}

<p>
In the special case when \(A = a^{\prime}\), a test statistic concerning \(H_0 : a^{\prime}\beta = m\) versus \(H_1 : a^{\prime}\beta \neq m\) is 
</p>

\begin{equation*}
t = \frac{a^{\prime}\hat{\beta} - m}{(a^{\prime}(X^{\prime}X)^- a \text{MSE})^{1/2}}
\end{equation*}

<p>
which, under \(H_0\), has the \(t\) -distribution with \(n - \text{rank}(X)\) degrees of freedom. Accordingly, the \((1 - \alpha)100\%\) confidence interval on \(a^{\prime}\beta\) is given by
</p>

\begin{equation*}
a^{\prime}\hat{\beta} \pm (a^{\prime}(X^{\prime}X)^- a \text{MSE})^{1/2} t_{\frac{\alpha}{2}, n - \text{rank}(X)}.
\end{equation*}
</div>
</div>

<div id="outline-container-org7a66d30" class="outline-4">
<h4 id="org7a66d30"><span class="done DONE">DONE</span> Two-way ANOVA model</h4>
<div class="outline-text-4" id="text-org7a66d30">
<p>
Two-way cross classification without interaction model is
</p>

\begin{equation*}
y_{ijk} = \mu + \alpha_i + \beta_j + \varepsilon_{ijk}
\end{equation*}

<p>
where \(\alpha_i\) and \(\beta_j\) are fixed unknown parameters. 
</p>

<p>
See example 7.2 in Khuri. 
</p>
</div>
</div>

<div id="outline-container-org72e7005" class="outline-4">
<h4 id="org72e7005"><span class="done DONE">DONE</span> Simultaneous confidence interval for estimable linear functions</h4>
<div class="outline-text-4" id="text-org72e7005">
<p>
Simultaneous \((1 - \alpha)100\%\) confidence intervals on all estimable linear functions \(l^{\prime}\hat{\beta}\), where \(l^{\prime}\) belongs to the rowspace of \(A\), are given by
</p>

\begin{equation*}
l^{\prime}\hat{\beta} \pm \sqrt{(\text{rank}(X) \text{MSE} F_{\text{rank}(X), n - \text{rank}(A)} l^{\prime}(X^{\prime}X)^- l)} 
\end{equation*}

<p>
which are known as <i>Scheffe's simultaneous confidence intervals</i>. In particular, if \(\text{rank}(X) = \text{rank}(A)\), then the elements of \(A\beta\) form a basis for all estimable linear functions of \(\beta\), and we have
</p>

\begin{equation*}
l^{\prime}\hat{\beta} \pm \sqrt{(\text{rank}(A) \text{MSE} F_{\text{rank}(A), n - \text{rank}(A)} l^{\prime}(X^{\prime}X)^- l)} 
\end{equation*}
</div>
</div>

<div id="outline-container-org8755721" class="outline-4">
<h4 id="org8755721"><span class="done DONE">DONE</span> Bonferroni's intervals</h4>
<div class="outline-text-4" id="text-org8755721">
<p>
Bonferroni's Inequality is
</p>

\begin{equation*}
\mathbb{P}(\bigcap_{j = 1}^m A_j) \geq 1 - \sum_{j = 1}^{m} \mathbb{P}(A_j^c)
\end{equation*}

<p>
In some cases, simultaneous confidence intervals on only a fixed number, \(m\), of contrasts may be of interest. Let \(c_j = \sum_{i = 1}^{k} \lambda_{ij}\mu_i (i = 1, 2, \ldots, m)\) be such contrasts. An unbiased estimator of \(c_j\) is \(\hat{c}_j = \sum_{i = 1}^{k} \lambda_{ij} \bar{Y}_i\). The \((1 - \alpha)100\%\) confidence interval on \(c_j\) is then given by
</p>

\begin{equation*}
\hat{c}_j \pm \left(\text{MSE} \sum_{i = 1}^{k} \frac{\lambda_{ij}^2}{n_i} \right)^{1/2} t_{\sum_{i = 1}^{k} n_i, 1 - \frac{\alpha}{2m}}
\end{equation*}
</div>
</div>

<div id="outline-container-org8b1ed6e" class="outline-4">
<h4 id="org8b1ed6e"><span class="done DONE">DONE</span> Sidaks Intervals</h4>
<div class="outline-text-4" id="text-org8b1ed6e">
<p>
This is an alternative set of intervals for a fixed number of contrasts. These intervals make use of a theorem that states the following.
</p>

<p>
Let \(Z = (Z_1, Z_2, \ldots, Z_n)^{\prime} \sim N(0, \Sigma)\), and \(\psi\) be a positive random variable, independent of \(Z\). Then,
</p>

\begin{equation*}
\mathbb{P} \left( \bigcap_{j = 1}^{m} \{ \frac{|Z_j|}{\psi} \leq \delta_j \} \right) \geq \prod_{j = 1}^m \mathbb{P} \left( \frac{|Z_j|}{\psi} \leq \delta_j \right)
\end{equation*}

<p>
for any \(\delta_1, \delta_2, \ldots, \delta_m > 0\). 
</p>

<p>
We then get intervals
</p>

\begin{equation*}
\hat{c}_j \pm \left(\sum_{i = 1}^{k} \frac{\lambda_{ij}^2}{n_i} \text{MSE} \right)^{1/2} t_{\sum_{i = 1}^{k} n_i, 1 - \frac{\alpha}{2}}
\end{equation*}

<p>
with a probability greater than or equal to \(1 - \alpha_s\), where \(\alpha_s\) is such that \(1 - \alpha_s = (1 - \alpha)^m\). We note that these intervals are of the same form as Bonferroni's intervals, except that in the Bonferroni case, the joint probability of coverage is greater than or equal to \(1 - \tilde{\alpha}\), with \(\tilde{\alpha} = m \alpha\), instead of \((1 - \alpha)^m\) in the Sidak case. 
</p>

<p>
When we compare Sidaks intervals to Bonferronis intervals, we find that Sidaks are better (better precision for same coverage). 
</p>
</div>
</div>
</div>

<div id="outline-container-org24ef16e" class="outline-3">
<h3 id="org24ef16e"><span class="section-number-3">2.7</span> <span class="done DONE">DONE</span> Distributional properties of quadratic forms <code>[10/10]</code></h3>
<div class="outline-text-3" id="text-2-7">
<p>
Suppose \(Y \in \mathbb{R}^n \sim N(\mu, \Sigma), A \in \mathbb{R}^{n \times n}\) is symmetric with \(\text{rank}(A) = r\).
</p>

<p>
What is the distribution of \(Y^{\prime}AY\)?
</p>

<p>
<b>Example 1:</b> \(Y_1, \ldots, Y_n \sim N(\mu, \sigma^2)\)
</p>

\begin{equation*}
\frac{\sum_{i = 1}^n (Y_i - \bar{Y})}{\sigma^2} \sim \chi^2_{n-1}, \\
\sum_{i = 1}^n (Y_i - \bar{Y}) = Y^{\prime}\left(I_n - \frac{1}{n} J_n \right) Y, \\
J_n = I_n I_n^{\prime}
\end{equation*}

<p>
<b>Example 2:</b> Balanced one-way ANOVA
</p>

<p>
We can write SSA and SSE as quadratic forms. They are both distributed as independent \(\chi^2\), so their ratio is \(F\) -distributed.
</p>
</div>

<div id="outline-container-org6fb0d0d" class="outline-4">
<h4 id="org6fb0d0d"><span class="done DONE">DONE</span> Lemma 1</h4>
<div class="outline-text-4" id="text-org6fb0d0d">
<p>
Let \(Y \in \mathbb{R}^n \sim N(\mu, \Sigma), A \in \mathbb{R}^{n \times n}\) is symmetric with \(\text{rank}(A) = r\). 
</p>

<p>
\(\lambda_1, \lambda_2, \ldots, \lambda_k, (k \leq r)\) are <span class="underline">distinct</span> <span class="underline">non-zero</span> eigenvalues of \(\Sigma^{1/2}A \Sigma^{1/2}\), with multiplicity \(v_1, \ldots, v_k\). 
</p>

<p>
\(P_i \in \mathbb{R}^{n \times v_i}\) matrix whose columns are the orthonormal eigenvectors of \(\Sigma^{1/2}A \Sigma^{1/2}\) corresponding to \(\lambda_i, (1 \leq i \leq k)\). 
</p>

<p>
Then \(Y^{\prime}A Y = \sum_{i = 1}^k \lambda_i w_i, w_i \sim \chi^2_{v_i}(||\mu^{\prime} \Sigma^{-1/2} P_i ||_2^2)\) and the \(w_i\) are independent. 
</p>

<p>
This says that the distribution of \(Y^{\prime}AY\) in gheneral is a linear combination of independent \(\chi^2\). 
</p>
</div>
</div>

<div id="outline-container-org8a9c1a0" class="outline-4">
<h4 id="org8a9c1a0"><span class="done DONE">DONE</span> Spectral Decomposition</h4>
<div class="outline-text-4" id="text-org8a9c1a0">
<p>
(for symmetric matrix)
</p>

\begin{equation*}
\Sigma^{1/2} A \Sigma^{1/2} = 

\begin{pmatrix}
P_1 & P_2 & \cdots & P_k
\end{pmatrix}

\begin{pmatrix}
\lambda_1 I_{v_1} & 0 & \cdots & 0 \\
0 & \lambda_2 I_{v_2} & \cdots & 0 \\
0 & 0 & \ddots & 0 \\
0 & 0 & \cdots & \lambda_k I_{v_k} \\
\end{pmatrix}

\begin{pmatrix}
P_1 \\
P_2 \\
\vdots \\
P_k
\end{pmatrix} =
P \Lambda P^{\prime} \\
P^{\prime}P = I \quad \text{(Columns of } P \text{ are orthonormal}
\end{equation*}
</div>
</div>

<div id="outline-container-org2cf60f9" class="outline-4">
<h4 id="org2cf60f9"><span class="done DONE">DONE</span> Theorem 1</h4>
<div class="outline-text-4" id="text-org2cf60f9">
<p>
Suppose \(Y \sim N(\mu, \Sigma), A \in \mathbb{R}^{n \times n}\) is symmetric. 
</p>

<p>
Then \(Y^{\prime}AY \sim \chi^2_r(\mu^{\prime}A \mu)\) <span class="underline">if and only if</span> \(A\Sigma\) (equivalently \(\Sigma^{1/2}A\Sigma^{1/2}\)) is idempotent and \(\text{rank}(A) = r\). 
</p>

<p>
Normal distribution assumption is required to get \(\chi^2\). 
</p>
</div>
</div>

<div id="outline-container-orgbe0e7b1" class="outline-4">
<h4 id="orgbe0e7b1"><span class="done DONE">DONE</span> Moment generating function</h4>
<div class="outline-text-4" id="text-orgbe0e7b1">
<p>
We use the moment generating function to show equivalence of distributions. 
</p>

\begin{equation*}
f(t) = \mathbb{E}(e^{tx})
\end{equation*}
</div>
</div>

<div id="outline-container-orgc0ecc4c" class="outline-4">
<h4 id="orgc0ecc4c"><span class="done DONE">DONE</span> Corollary \(A \in \mathbb{R}^{n \times n}\)</h4>
<div class="outline-text-4" id="text-orgc0ecc4c">
<ol class="org-ol">
<li>\(Y \sim N(0, \Sigma)\), then \(Y^{\prime}AY \sim \chi^2_r \Leftrightarrow A\Sigma\) is idempotent, \(\text{rank}(A) = r\).</li>
<li>\(Y \sim N(\mu, \Sigma)\), then \(Y^{\prime} \Sigma^{-1}Y \sim \chi^2_n(\mu^{\prime}\Sigma^{-1}\mu)\).</li>
<li>\(Y \sim N(\mu, \sigma^2I)\), then \(Y^{\prime} \frac{A}{\sigma^2}Y \sim \chi^2_r \left(\frac{\mu^{\prime} A \mu}{\sigma^2} \right) \Leftrightarrow A \text{ is idempotent }, \text{ rank}(A) = r\)</li>
</ol>
</div>
</div>
<div id="outline-container-org378d453" class="outline-4">
<h4 id="org378d453"><span class="done DONE">DONE</span> Theorem 2 (Craig's Theorem)</h4>
<div class="outline-text-4" id="text-org378d453">
<p>
Suppose \(Y \in \mathbb{R}^n \sim N(\mu, \Sigma), A,B \in \mathbb{R}^{n \times n}\) are two symmetric matrices. Under what conditions are \(YA^{\prime}Y\) and \(Y^{\prime}BY\) independent?
</p>

\begin{equation*}
Y^{\prime}AY \perp Y^{\prime}BY \Leftrightarrow A\Sigma B = 0.
\end{equation*}

<p>
Gaussianity is required for both directions. 
</p>
</div>
</div>
<div id="outline-container-orgf2c144a" class="outline-4">
<h4 id="orgf2c144a"><span class="done DONE">DONE</span> Theorem 3.9 Khuri</h4>
<div class="outline-text-4" id="text-orgf2c144a">
<p>
\(C, D \in \mathbb{R}^{n \times n}\) are symmetric. 
</p>

<p>
\(CD = DC \Rightarrow C\) and \(D\) commute. 
</p>

<p>
\(CD = DC \Rightarrow C = P \Lambda P^{\prime}\) and \(D = P \tilde{\Lambda} P^{\prime}\). (They share the same eigenvector matrices \(P\)). 
</p>
</div>
</div>
<div id="outline-container-orge0a293c" class="outline-4">
<h4 id="orge0a293c"><span class="done DONE">DONE</span> Theorem 3</h4>
<div class="outline-text-4" id="text-orge0a293c">
<p>
Suppose \(Y \in \mathbb{R}^n \sim N(\mu, \Sigma), A \in \mathbb{R}^{n \times n}\) is symmetric, \(B \in \mathbb{R}^{m \times n}\). Under what condition are \(YA^{\prime}Y\) and \(BY\) independent?
</p>

<p>
For example, you may want to prove MSE and \(\hat{\beta}\) are independent. 
</p>

\begin{equation*}
Y^{\prime}AY \perp BY \Leftrightarrow B\Sigma A = 0.
\end{equation*}
</div>
</div>

<div id="outline-container-org1da298f" class="outline-4">
<h4 id="org1da298f"><span class="done DONE">DONE</span> Partitioning the sum of squares <code>[1/1]</code></h4>
<div class="outline-text-4" id="text-org1da298f">
\begin{equation*}
Y_i = X_i^{\prime}\beta_1 + \beta_0 + \varepsilon_i, \quad i = 1, 2, \ldots, n, \\
\bar{Y} = \frac{1}{n} \sum_{i = 1}^n Y_i, \quad \hat{Y}_i = X_i^{\prime}\hat{\beta}_1 + \hat{\beta}_0.
\end{equation*}

<p>
Then we can partition the total sum of squares as 
</p>

\begin{equation*}
\sum_{i = 1}^n (Y_i - \bar{Y})^2 = \sum_{i = 1}^n (Y_i - \hat{Y}_i)^2 + \sum_{i = 1}^n (\hat{Y}_i - \bar{Y})^2 \\
\text{SSTO} = \text{SSE} + \text{SSR}
\end{equation*}

<p>
and since \(\sum_{i = 1}^n (Y_i - \bar{Y})^2 = \sum_{i = 1}^n Y_i^2 - n\bar{Y}\), we can write
</p>

\begin{equation*}
\sum_{i = 1}^n Y_i^2 - n\bar{Y} = \sum_{i = 1}^n (Y_i - \hat{Y}_i)^2 + \sum_{i = 1}^n (\hat{Y}_i - \bar{Y})^2 \\
\downarrow \\
\sum_{i = 1}^n Y_i^2 = n\bar{Y}^2 + \sum_{i = 1}^n (Y_i - \hat{Y}_i)^2 + \sum_{i = 1}^n (\hat{Y}_i - \bar{Y})^2 \\
Y^{\prime}I_n Y = Y^{\prime} \frac{1}{n}J_n Y + Y^{\prime} \left(I_n - X\left(X^{\prime}X\right)^{-}X^{\prime}\right)Y + Y^{\prime}\left(X\left(X^{\prime}X\right)^{-}X^{\prime} - \frac{1}{n} J_n\right)Y \\
X = 
\begin{pmatrix}
1 & x_1^{\prime} \\
1 & x_2^{\prime} \\
1 & x_3^{\prime} \\
\vdots & \vdots \\
1 & x_p^{\prime} \\
\end{pmatrix}
\in \mathbb{R}^{n \times p}
\end{equation*}

<p>
Here we have
</p>

\begin{equation*}
Y^{\prime}Y = Y^{\prime}A_1 Y + Y^{\prime} A_2 + Y^{\prime} A_3 Y, \quad A_1 + A_2 + A_3 = I_n
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; One-way ANOVA example</dt><dd></dd>
</dl>
\begin{equation*}
y_{ij} = \mu + \alpha_i + \varepsilon_{ij}, \quad i = 1, 2, \ldots, k, \quad j = 1, 2, \ldots m \\
\bar{Y}_i = \frac{1}{m} \sum_{j = 1}^m y_{ij}, \quad \bar{Y} = \frac{1}{km} \sum_i \sum_j y_{ij}, \\
Y = (y_{11}, y_{12}, \ldots, y_{1m}, \ldots, y_{k1}, \ldots, y_{km})^{\prime} \\
\sum_{i = 1}^k \sum_{j = 1}^m (y_{ij} - \bar{Y})^2 = \sum_{i = 1}^k \sum_{j = 1}^m (y_{ij} - \bar{Y}_i)^2 + \sum_{i = 1}^k \sum_{j = 1}^m (\bar{Y}_i - \bar{Y})^2 \\
\sum_{i = 1}^k \sum_{j = 1}^m (y_{ij} - \bar{Y})^2 = \sum_{i = 1}^k \sum_{j = 1}^m y_{ij}^2 - km \bar{Y}^2 \\
\downarrow \\
Y^{\prime}Y = Y^{\prime}\left(\frac{1}{km} J_{km} \right) Y + Y^{\prime}\left( I_{km} - \frac{1}{m} B\right) Y + Y^{\prime} \left( \frac{1}{m} B - \frac{1}{km} J_{km}\right) Y
\end{equation*}

<p>
where \(B\) is a block diagonal matrix with elements equal to \(J\). 
</p>
</div>
</div>

<div id="outline-container-org555fcd7" class="outline-4">
<h4 id="org555fcd7"><span class="done DONE">DONE</span> Cochran's theorem</h4>
<div class="outline-text-4" id="text-org555fcd7">
<p>
Let \(Y \in \mathbb{R}^n \sim N(\mu, \sigma^2 I_n)\), and \(Y^{\prime}Y = \sum_{i = 1}^k Y^{\prime}A_i Y\), with \(\sum_{i = 1}^k A_i = I_n\), \(\text{rank}(A_i) = r_i, A_i \in \mathbb{R}^{n \times n}\) is symmetric, \(i = 1, 2, \ldots, k\).
</p>

<p>
(a) \(n = \sum_{i = 1}^k r_i\)
</p>

<p>
(b) \(\frac{1}{\sigma^2} Y^{\prime}A_i Y \sim \chi^2_{r_i} \left(\frac{1}{\sigma^2} \mu^{\prime} A_i \mu \right), \quad i = 1, 2, \ldots, k\)
</p>

<p>
(c) \(Y^{\prime}A_1 Y, \ldots, Y^{\prime}A_k Y\) are mutually independent
</p>

\begin{equation*}
\text{(a)} \Leftrightarrow \text{(b)} \Leftrightarrow \text{(c)}
\end{equation*}
</div>
</div>
</div>

<div id="outline-container-org39cb298" class="outline-3">
<h3 id="org39cb298"><span class="section-number-3">2.8</span> <span class="done DONE">DONE</span> Model selection and prediction <code>[10/10]</code></h3>
<div class="outline-text-3" id="text-2-8">
\begin{equation*}
Y_i = X_i^{\prime} \beta + \varepsilon_i, i = 1, 2, \ldots, n \\
\beta = (\beta_1, \ldots, \beta_p)^{\prime}
\end{equation*}

<p>
Some of the \(\beta_i\) 's are zero. That means some predictors are not related to the response \(Y\).
</p>

<p>
Identifying the \(\beta_i\) 's that are zero helps with interpretation and improving statistical performance (reducing noise). 
</p>
</div>

<div id="outline-container-orga5f1cca" class="outline-4">
<h4 id="orga5f1cca"><span class="done DONE">DONE</span> Expected prediction error</h4>
<div class="outline-text-4" id="text-orga5f1cca">
<p>
Write out the model in matrix form: \(Y = X\beta + \varepsilon\).
</p>

<p>
Let 
</p>

\begin{equation*}
\beta = 
\begin{pmatrix}
\beta_1 \\
\beta_2
\end{pmatrix}, 
X = 
\begin{pmatrix} 
X_1 & X_2
\end{pmatrix}, \\
\beta_1 \in \mathbb{R}^{p_1}, \beta_2 \in \mathbb{R}^{p_2}
\end{equation*}

<p>
Suppose there is a new data point \(Y_a, a \in \mathbb{R}^p\). We observe new \(a\), want to predict \(Y_a\). 
</p>

<p>
Given an estimator \(\tilde{\beta}\),
</p>

\begin{equation*}
\text{Prediction Error} = \mathbb{E}_{Y_a}(Y_a - a^{\prime}\tilde{\beta})^2 \\
\text{Expected Prediction Error} = \mathbb{E}(\text{PE}) = \mathbb{E}(Y_a + a^{\prime}\tilde{\beta})^2
\end{equation*}

<p>
Let \(a = \begin{pmatrix} a_1 \\ a_2 \end{pmatrix}, a_1 \in \mathbb{R}^{p_1}, a_2 \in \mathbb{R}^{p_2}\). 
</p>

\begin{align*}
Y_a &= a^{\prime}\beta + \varepsilon_a \\
&= a_1^{\prime}\beta_1 + a_2^{\prime}\beta_2 + \varepsilon_a
\end{align*}
</div>
</div>

<div id="outline-container-org0ddca7f" class="outline-4">
<h4 id="org0ddca7f"><span class="done DONE">DONE</span> Prediction <code>[2/2]</code></h4>
<div class="outline-text-4" id="text-org0ddca7f">
<dl class="org-dl">
<dt class="on">&#x2611; Case 1: Using only \(p_1\) variables</dt><dd></dd>
</dl>

\begin{align*}
\mathbb{E}(\text{PE}) &= \mathbb{E}(Y_a - a_1^{\prime}(X_1^{\prime}X_1)^{-1}X_1 Y)^2 \\
\vdots \\
&= \sigma^2 + \sigma^2 a_1^{\prime}(X_1^{\prime}X_1)^{-1}a_1 + [(a_1^{\prime}(X_1^{\prime}X_1)^{-1}X_1^{\prime} X_2 - a_2^{\prime}) \beta_2]^2
\end{align*}

<dl class="org-dl">
<dt class="on">&#x2611; Case 2: Using all the variables</dt><dd></dd>
</dl>

\begin{align*}
\mathbb{E}(\text{PE}) &= \mathbb{E}(Y_a - a^{\prime}(X^{\prime}X)^{-1}X Y)^2 \\
&= \sigma^2 + \sigma^2 a^{\prime}(X^{\prime}X)^{-1}a
\end{align*}

<p>
If we then partition the second term in terms of \(a_1\) and \(a_2\), we find that the expected prediction error in case 2 is larger than in case 1. So case 1 gives small prediciton error. 
</p>
</div>
</div>

<div id="outline-container-org08abe2c" class="outline-4">
<h4 id="org08abe2c"><span class="done DONE">DONE</span> Bias-variance tradeoff</h4>
<div class="outline-text-4" id="text-org08abe2c">
<p>
Given an estimator \(\tilde{\beta}\),
</p>

\begin{align*}
\mathbb{E}(\text{PE}) &= \mathbb{E}(Y_a - a^{\prime}\tilde{\beta})^2 \\
&= \sigma^2 + (a^{\prime}\mathbb{E}(\tilde{\beta}) - a^{\prime}\beta)^2 + \text{Var}(a^{\prime}\tilde{\beta}) \\
&= \text{Irreducible error} + \text{Bias}^2 + \text{Variance}
\end{align*}
</div>
</div>

<div id="outline-container-orgc437a23" class="outline-4">
<h4 id="orgc437a23"><span class="done DONE">DONE</span> Goodness of Fit <code>[2/2]</code></h4>
<div class="outline-text-4" id="text-orgc437a23">
<dl class="org-dl">
<dt class="on">&#x2611; Coefficient of Determination</dt><dd></dd>
</dl>
\begin{equation*}
R^2 = 1 - \frac{\sum_{i = 1}^n (Y_i - \hat{Y}_i)^2}{\sum_{i = 1}^n (Y_i - \bar{Y})^2} = 1 - \frac{\text{SSE}}{\text{SSTO}}
\end{equation*}

<p>
Among all variation in the data, how much can be explained by your model?
</p>

<p>
\(R^2 \rightarrow\) the proportion of variation in \(Y\) that's explained by the model.
</p>

<p>
\(R^2\) is not a great measure to select models because you will always select the model with more parameters. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Adjusted \(R^2\)</dt><dd></dd>
</dl>
<p>
Adjusts for model complexity
</p>

\begin{equation*}
\bar{R}^2 = 1 - (1 - R^2) \frac{n - 1}{n - k - 1},
\end{equation*}

<p>
where \(k\) is the total number of predictors in the model. (By default, intercept is included). (\(k\) predictors plus intercept is \(k + 1\)).
</p>

<ol class="org-ol">
<li>\(\bar{R}^2\) is not monotonic in \(k\).</li>
<li>ajusted \(R^2\) is typically smaller than \(R^2\).</li>
<li>\(\bar{R}^2 = 1 - \frac{\sum_{i = 1}^n (Y_i - \hat{Y}_i)^2 / (n - k - 1)}{\sum_{i = 1}^n (Y_i - \bar{Y})^2 / (n - 1)}\), where the numerator is MSE and the denomitor is sample variance. So when we compare models with adjusted \(R^2\), we are basically comparing with MSE.</li>
<li>\(\bar{R}^2\) can be motivated from the hypothesis testing problem. Basically testing if a subset of the \(\beta\) 's are zero.</li>
</ol>
</div>
</div>

<div id="outline-container-orgbc2a9cd" class="outline-4">
<h4 id="orgbc2a9cd"><span class="done DONE">DONE</span> Predicition error <code>[2/2]</code></h4>
<div class="outline-text-4" id="text-orgbc2a9cd">
<dl class="org-dl">
<dt class="on">&#x2611; Expected in-sample prediction error</dt><dd></dd>
</dl>

<p>
\((Y, X) \Rightarrow Y = X\beta + \varepsilon, \mathbb{E}(\varepsilon) = 0, \text{Cov}(\varepsilon) = \sigma^2 I\).
</p>

<p>
Suppose we observe new data on the same \(X\) 's. 
</p>

<p>
\((\tilde{Y}, \tilde{X}) \Rightarrow \tilde{Y} = X\beta + \tilde{\varepsilon}\). 
</p>

\begin{equation*}
\text{Expected in-sample predcition error} = \frac{1}{n} \mathbb{E}||\tilde{Y} - \hat{f}(Y)||_2^2
\end{equation*}

<p>
where \(\hat{f}(Y)\) is the predicted value based on data \((Y, X)\). 
</p>

<p>
If our method is OLS using a submatrix of \(X\) denoted \(X_s\), then
</p>

\begin{align*}
\text{EISPE} &= \frac{1}{n} \mathbb{E}||\tilde{Y} - X_s (X_s^{\prime} X_s)^{-1}X_s^{\prime} Y||_2^2 \\
\vdots \\
&= \sigma^2 + \frac{1}{n} \beta^{\prime}X^{\prime}(I - X_s(X_s^{\prime}X_s)^{-1}X_s^{\prime})X\beta + \frac{k+1}{n} \sigma^2.
\end{align*}

<p>
which we can estimate.
</p>

<p>
A general formula for in-sample prediction error:
</p>

<p>
Consider \(Y_i = f(X_i) + \varepsilon_i, i = 1, \ldots, n, \mathbb{E}(\varepsilon) = 0, \text{Cov}(\varepsilon) = \sigma^2 I\). Let \(\hat{Y}_i\) be the prediction for the response corresponding to \(X_i, i = 1, \ldots, n\). New data is \(\tilde{Y}_i = f(X_i) + \tilde{\varepsilon}_i, i = 1, \ldots, n\). 
</p>

\begin{align*}
\text{Expected in-sample prediction error} &= \mathbb{E}\left(\sum_{i = 1}^n (\hat{Y}_i - Y_i)^2\right) + \frac{2}{n} \sum_{i = 1}^n \text{Cov}(Y_i, \hat{Y}_i) \\
&= \text{training error} + \text{complexity of the model}.
\end{align*}

<dl class="org-dl">
<dt class="on">&#x2611; Mallon's Cp</dt><dd></dd>
</dl>

\begin{equation*}
Cp = \frac{\text{SSE}_0}{\text{MSE}} + 2(k+1) - n, \\
\text{SSE}_0 = ||Y - X\hat{\beta}_s||_2^2, \text{MSE} = \frac{1}{n - p - 1}||Y - X\hat{\beta}||_2^2
\end{equation*}

<p>
where \(\hat{\beta}_s\) is OLS based on a subset \(s\) of predictors. 
</p>

<p>
\(k\) is a measure of model complexity. 
</p>

<p>
Remarks: 
</p>

<ol class="org-ol">
<li>If the bias is small (close to zero), \(\mathbb{E}(Cp) \approx k + 1\). Otherwise it is much larger than \(k + 1\) if the bias is large.</li>
<li>A good strategy is to identify models whose \(Cp\) is close to \(k + 1\), and to pick the one having the smallest \(Cp\).</li>
<li>Approximately the smallest \(Cp - (k+1)\) corresponds to the largest \(\bar{R}^2\).</li>
</ol>
</div>
</div>

<div id="outline-container-orgc3d4da0" class="outline-4">
<h4 id="orgc3d4da0"><span class="done DONE">DONE</span> Degrees of freedom of given prediction method</h4>
<div class="outline-text-4" id="text-orgc3d4da0">
<p>
This is a measure of complexity of the model.
</p>

\begin{equation*}
df(\hat{Y}) = \frac{\sum_{i = 1}^n \text{Cov}(Y_i, \hat{Y}_i)}{\sigma^2}
\end{equation*}
</div>
</div>

<div id="outline-container-org08d5926" class="outline-4">
<h4 id="org08d5926"><span class="done DONE">DONE</span> Cross validation</h4>
<div class="outline-text-4" id="text-org08d5926">
<p>
See elements of statsitical learning Ch 7.10 for Cross Validation. Chapter 7 is relevant for model selection. 
</p>

<p>
Training data is \((x_i, y_i), i = 1, \ldots, n\).
</p>

<p>
If we have a new dataset available: \((\tilde{x}_i, \tilde{y}_i), i = 1, \ldots, m\), we can estimate the prediction error by \(\frac{1}{m} \sum_{i = 1}^m (\tilde{y}_i - \hat{f}(\tilde{x}_i))^2\), where \(\hat{f}(\cdot)\) is any prediction method using the training set. 
</p>

<p>
Usually a new dataset is not available, so we split the training set into two parts. We don't want either part to be too small. 
</p>

<p>
A better solution is <span class="underline">cross validation</span>, where we randomly split the training set into \(k\) roughly equal parts, fit the model using \(k-1\) of the parts, and calculate the prediction error on the left out part. We then do this for all \(k\) parts. This is called <span class="underline">\(k\) -fold cross validation</span>. 
</p>

<p>
If we let \(g(i), 1 \leq i \leq n\) index which part the \(i^{\text{th}}\) data point is assigned to, and \(\hat{f}^{-j}(\cdot)\) denote the method computed with the \(j^{\text{th}}\) part removed. 
</p>

<p>
Then the <span class="underline">cross-validation estimate of (Expected) prediction error</span> is
</p>

\begin{equation*}
CV(\hat{f}) = \frac{1}{n} \sum_{i = 1}^n (y_i - \hat{f}^{-g(i)}(x_i))^2
\end{equation*}

<p>
<span class="underline">Large \(k\)</span>: low bias, high variance
</p>

<p>
<span class="underline">Small \(k\)</span>: high bias, low variance
</p>

<p>
For \(k = n\), it is called <span class="underline">leave-one-out cross validation</span>. 
</p>

<p>
For model selection, we choose the model with \(CV(\hat{f}(\cdot))\) minimized. 
</p>
</div>
</div>

<div id="outline-container-org2f4555a" class="outline-4">
<h4 id="org2f4555a"><span class="done DONE">DONE</span> Information Criterion <code>[6/6]</code></h4>
<div class="outline-text-4" id="text-org2f4555a">
<p>
Suppose we have data \(Y_1, \ldots, Y_n\) independently drawn from some density \(f(Y)\). A model \(\mathcal{M}\) is a set of densities: \(\mathcal{M} = \{ p(Y;\theta) : \theta \in \Theta\}\). \(f(Y)\) may or may not belong to \(\mathcal{M}\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Akaike Information Criterion</dt><dd></dd>
</dl>
<p>
For a given model \(\mathcal{M}_j\), the corresponding AIC is
</p>

\begin{equation*}
\text{AIC}(\mathcal{M}_j) = 2 \sum_{i = 1}^n \log p(y_i ; \hat{\theta}_j) - 2 \text{dim}(\mathcal{M}_j)
\end{equation*}

<p>
We then pick the model with the greatest AIC. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Kullback - Leibler divergence</dt><dd></dd>
</dl>
<p>
How to measure the discrepancy between \(p(Y;\theta)\) and \(f(Y)\)?
</p>

\begin{align*}
KL(f(Y), p(Y;\theta)) &= \int f(Y) \log{\frac{f(Y)}{p(y;\theta)}} dY \\
&= \mathbb{E}_f\left[ \log{\frac{f(y)}{p(Y;\theta)}}\right]
\end{align*}

<p>
\(KL\) is non-negative, and \(KL = 0\) for equivalent distributions. 
</p>

<p>
\(KL\) is generally asymmetric. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Takeuchi's Information Criterion</dt><dd></dd>
</dl>
<p>
What if we don't assume \(f(y) \in \mathcal{M}_j\)? (Model may not be correctly specified). 
</p>

\begin{equation*}
\text{TIC}(\mathcal{M}_j) = 2 \sum_{i = 1}^n \log p(y_i ; \hat{\theta}_j) - 2 tr(\hat{J}^{-1}\hat{V}), \\
\hat{J} = -\frac{1}{n}\sum_{i = 1}^n H(Y_i ; \hat{\theta}_j), \hat{V} = \frac{1}{n} \sum_{i = 1}^n G(Y_i ; \hat{\theta}_j) G^{\prime}(Y_i ;\hat{\theta}), \\
H(Y_i, \theta) = \frac{\partial^2 \log p(Y_i;\theta)}{\partial \theta^2}, G(Y_i, \theta) = \frac{\partial \log p(Y_i;\theta)}{\partial \theta}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; AIC For Linear Regression Model</dt><dd></dd>
</dl>

<p>
Suppose \(\mathcal{M}_j = \{ Y \sim N(X\beta, \sigma^2 I_n), \beta \in \mathbb{R}^{k + 1} \}\).
</p>

<p>
If \(\sigma^2\) is unknown, then (up to constants)
</p>

\begin{equation*}
\text{AIC}(\mathcal{M}_j) = -n \log \frac{\text{SSE}}{n} - 2k.
\end{equation*}

<p>
If \(\sigma^2\) is assumed known, then 
</p>

\begin{equation*}
\text{AIC}(\mathcal{M}_j) \approx -\frac{\text{SSE}}{\text{MSE}} - 2k.
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Bayesian Information Criterion</dt><dd></dd>
</dl>

<p>
Bayesian perspective: specify prior probability and distributions for \(\mathcal{M}_j\) and \(\theta_j, j = 1, 2, \ldots, k\). We then want the model that maximizes the posterior probability. We get
</p>

\begin{equation*}
\text{BIC}(\mathcal{M}_j) = 2 \sum_{i = 1}^n \log p(y_i ; \hat{\theta}_j) - \text{dim}(\theta_j) \log n
\end{equation*} 

<p>
Want to pick model with largest BIC or AIC. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Laplace's Approximation</dt><dd></dd>
</dl>
<p>
We used this to approximate the posterior probability for BIC. It can approximate integrals of a certain form as normal distributions. 
</p>

\begin{equation*}
(\theta \in \mathbb{R}^p) \\
\int_\Theta e^{n h(\theta)} g(\theta) d\theta \approx \left( \frac{2\pi}{n} \right)^{\frac{p}{2}} e^{n h(\theta_0)} g(\theta_0) |J(\theta_0)|^{\frac{-1}{2}}, \\
\theta_0 = \arg \max_\theta h(\theta), \quad -J(\theta_0) = \frac{\partial^2 h}{\partial \theta^2} |_{\theta = \theta_0}
\end{equation*}
</div>
</div>

<div id="outline-container-orgab5e80e" class="outline-4">
<h4 id="orgab5e80e"><span class="done DONE">DONE</span> Comparison of model selection criteria for linear regression model</h4>
<div class="outline-text-4" id="text-orgab5e80e">
<p>
Consider linear regression model: \(Y = X\beta + \varepsilon, Y \in \mathbb{R}^n, X \in \mathbb{R}^{n \times p}, \varepsilon \sim N(0, \sigma^2 I_n)\), and assume some of the \(\beta_j\) are zero. 
</p>

<p>
Let the true model be \(\mathcal{M}_0 = \{ j : \beta_j \neq 0 \}\) and \(J = \{ \mathcal{M}_0, \mathcal{M}_1, \ldots, \mathcal{M}_k \}\).
</p>

<p>
Partition \(J\) into two groups:
</p>

\begin{equation*}
J_1 = \{ \mathcal{M} \in J : \mathcal{M}_0 \nsubseteq \mathcal{M} \} \\
J_2 = \{ \mathcal{M} \in J : \mathcal{M}_0 \subseteq \mathcal{M} \} \\
\end{equation*}

<p>
Let \(\hat{\mathcal{M}}\) be the model selected by optimizing a model selection criterion (e.g. AIC, BIC, etc.)  and \(R_n = \mathbb{E}||X\beta - X_{\hat{\mu}} \hat{\beta}_{\hat{\mu}}||_2^2\), where \(X_{\hat{\mu}} \hat{\beta}_{\hat{\mu}}\) is the OLS prediction from the selected model. Ideally, if we select \(\mathcal{M}_0, R_n = \sigma^2 |\mathcal{M}_0 |\), where \(|\mathcal{M}_0 |\) is the dimension of model \(\mathcal{M}_0\).
</p>

<p>
Under mild regularity conditions, for <span class="underline">Cp, AIC, LOOCV</span>:
</p>

<ol class="org-ol">
<li>For given \(\mathcal{M} \in J_1\), and any \(h>0, \mathbb{P}(\hat{\mathcal{M}} = \mathcal{M}) = o(n^{-k})\) as \(n \rightarrow \infty\).</li>
<li>\(\lim_{n \rightarrow \infty} \sum_{\mathcal{M} \in J_2, \mathcal{M} \neq \mathcal{M}_0} \mathbb{P}(\hat{\mathcal{M}} = \mathcal{M}) > 0\) if \(\mathcal{M}_0\) is not the full model.</li>
<li>\(\lim_{n \rightarrow \infty} R_n > \sigma^2 |\mathcal{M}_0 |\) if \(\mathcal{M}_0\) is not the full model.</li>
</ol>

<p>
For <span class="underline">BIC</span>:
</p>

<ol class="org-ol">
<li>For all \(\mathcal{M} \in J_1\) and \(h > 0\), \(\mathbb{P}(\hat{\mathcal{M}} = \mathcal{M}) = o(n^{-h})\) as \(n \rightarrow \infty\).</li>
<li>\(\lim_{n \rightarrow \infty} \sum_{\mathcal{M} \in J_2, \mathcal{M} \neq \mathcal{M}_0} \mathbb{P}(\hat{\mathcal{M}} = \mathcal{M}) = 0\)</li>
<li>\(\lim_{n \rightarrow \infty} R_n = \sigma^2 |\mathcal{M}_0 |\)</li>
</ol>
</div>
</div>

<div id="outline-container-org0512a10" class="outline-4">
<h4 id="org0512a10"><span class="done DONE">DONE</span> Subset selection</h4>
<div class="outline-text-4" id="text-org0512a10">
<p>
Consider linear regression model with \(p\) many predictors. 
</p>

<p>
<span class="underline">Best subset selection</span> is when we try all \(2^p\) subsets and pick the one optimizing a model selection criterion. This is computationally expensive. 
</p>

<p>
<span class="underline">Forward selection</span> is when we start with the null model, and add the single variable that optimizes a model selection criterion, and keep going until we can't optimize any more. This isn't great because we have to try so many models. 
</p>

<p>
<span class="underline">Backward elimination</span> starts with the full model and selects single variables to remove to optimize a criterion. 
</p>

<p>
<span class="underline">Stepwise selection</span> basically combines forward and backward selection. 
</p>
</div>
</div>
</div>
<div id="outline-container-org0b724ca" class="outline-3">
<h3 id="org0b724ca"><span class="section-number-3">2.9</span> <span class="done DONE">DONE</span> Shrinkage methods <code>[3/3]</code></h3>
<div class="outline-text-3" id="text-2-9">
</div>
<div id="outline-container-org93619e0" class="outline-4">
<h4 id="org93619e0"><span class="done DONE">DONE</span> James-Stein estimator</h4>
<div class="outline-text-4" id="text-org93619e0">
<p>
Consider \(Y \in \mathbb{R}^n \sim N(\mu, I_n)\). How can we estimate \(\mu \in \mathbb{R}^n\)?
</p>

<p>
\(Y\) is unbiased and UMVUE for \(\mu\), but let's consider some biased estimator. 
</p>

<p>
Specifically, consider \(\tilde{\mu} = cY \text{ for } 0 < c < 1\), which is biased. 
</p>

<p>
The James-Stein Estimator is
</p>

\begin{equation*}
\hat{\mu}_{JS} = \left( 1 - \frac{n-2}{||Y||_2^2} \right) Y
\end{equation*}

<p>
When \(n \geq 3\), \(\mathbb{E}||\hat{\mu}_{JS} - \mu||_2^2 < \mathbb{E}||\hat{\mu}_{MLE} - \mu||_2^2\) for every choice of \(\mu \in \mathbb{R}^n\).
</p>

<p>
For example, in linear regression with \(\sigma^2 = 1, X^{\prime}X = I_p \Rightarrow \hat{\beta} \sim N(\beta, I_p)\), and we have
</p>

\begin{equation*}
\hat{\beta}_{JS} = \left( 1 - \frac{p-2}{||Y\hat{\beta}||_2^2} \right) \hat{\beta}
\end{equation*}
</div>
</div>

<div id="outline-container-org40ea263" class="outline-4">
<h4 id="org40ea263"><span class="done DONE">DONE</span> Ridge Regression</h4>
<div class="outline-text-4" id="text-org40ea263">
<p>
Consider the regression model: \(Y_i = \beta_0 + X_i^{\prime}\beta_1 + \varepsilon_i, \quad i = 1, \ldots, n, \beta0 \in \mathbb{R}, \beta_1 \in \mathbb{R}^p\).
</p>

\begin{equation*}
\hat{\beta}^\text{ridge} = \arg \min_{\beta_0, \beta_1} \sum_{i = 1}^n (Y_i - \beta_0 - X_i^{\prime}\beta_1)^2 + \lambda ||\beta_1||_2^2
\end{equation*}

<p>
Here, \(\lambda ||\beta_1||_2^2\) is the penalty term with \(\lambda\) as the tuning parameter. Larger \(\lambda\) means more shrinkage, while \(\lambda = 0\) gives OLS. As \(\lambda \rightarrow \infty\), \(\hat{\beta}_1 \rightarrow 0\). 
</p>

<p>
An equivalent form for \(\hat{\beta}^\text{ridge}\) is
</p>

\begin{equation*}
\hat{\beta}^\text{ridge} = \arg \min_{\beta_0, \beta_1} \sum_{i = 1}^n (Y_i - \beta_0 - X_i^{\prime}\beta_1)^2 \text{ subject to } ||\beta_1 ||_2^2 \leq t
\end{equation*}

<p>
where without the constraint, we get OLS, and smaller \(t\) gives larger shrinkage. 
</p>

<p>
We usually do data standardization before doing ridge regression, which gives us the "scaling invariance" property. 
</p>

\begin{equation*}
\tilde{X}_{ij} = \frac{X_{ij} - \bar{X}_j}{\sqrt{\sum_{i = 1}^n (X_{ij} - \bar{X}_j)^2}}. 
\end{equation*}

<p>
After data standardization, \(\hat{\beta}_0^\text{ridge} = \hat{\beta}_0^\text{OLS}\).
</p>

<p>
Shrinkage can possibly improve estimation/prediction. 
</p>

<p>
See Chapter 3 in Elements of Statistical Learning. 
</p>
</div>
</div>

<div id="outline-container-orgdae9087" class="outline-4">
<h4 id="orgdae9087"><span class="done DONE">DONE</span> The Lasso</h4>
<div class="outline-text-4" id="text-orgdae9087">
<p>
Lasso is the same as Ridge Regression except we replace \(||\beta_1||_2^2\) by \(||\beta_1||\), which makes the solution nonlinear in \(Y\). No closed form solution in general. 
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orga1f6fd0" class="outline-2">
<h2 id="orga1f6fd0"><span class="section-number-2">3</span> STT 868 <code>[100%]</code></h2>
<div class="outline-text-2" id="text-3">
<p>
Often, data have a clustered structure. Classical statsitics assums that observations are independent and identically distrivuted (iid). Applied to clustered datam this assumption may lead to false results. Mixed effects model addresses this issue. 
</p>
</div>

<div id="outline-container-org1ef9211" class="outline-3">
<h3 id="org1ef9211"><span class="section-number-3">3.1</span> <span class="done DONE">DONE</span> Model Identifiability <code>[10/10]</code></h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-orgc7bc65f" class="outline-4">
<h4 id="orgc7bc65f"><span class="done DONE">DONE</span> One-way ANOVA model</h4>
<div class="outline-text-4" id="text-orgc7bc65f">
<p>
One-way ANOVA is an example of a fixed effects model. 
</p>

\begin{equation*}
y_{ij} = \mu + \alpha_i + \varepsilon_{ij}, \\
 i = 1 \ldots k, j = 1, \dots n_i, \\
\mu_i = \mu + \alpha_i
\end{equation*}

<p>
\(\mu_i\) are fixed effects. They are estimable.
</p>
</div>
</div>

<div id="outline-container-orgd7cef2d" class="outline-4">
<h4 id="orgd7cef2d"><span class="done DONE">DONE</span> Variance componenets models</h4>
<div class="outline-text-4" id="text-orgd7cef2d">
<p>
This is a linear mixed effects (LME) model. 
</p>

<p>
Same model as one-way ANOVA, but \(\mu_i \overset{\text{iid}}{\sim} N(\mu, \sigma^2) \Leftrightarrow \alpha_i \overset{\text{iid}}{\sim} N(0, \sigma^2)\)
</p>

<p>
The \(\mu_i\) are random effects
</p>
</div>
</div>

<div id="outline-container-org4030897" class="outline-4">
<h4 id="org4030897"><span class="done DONE">DONE</span> Properties of random effects</h4>
<div class="outline-text-4" id="text-org4030897">
<ol class="org-ol">
<li>induce dependency structure</li>
<li>bring fewer parameters to the model</li>
<li>different estimation and inference</li>
</ol>
</div>
</div>

<div id="outline-container-org1f19cf4" class="outline-4">
<h4 id="org1f19cf4">Deciding between fixed and random effects</h4>
<div class="outline-text-4" id="text-org1f19cf4">
<p>
To decide whether a set of effects is fixed or random, the context of the daa, the manner in which they were gathered and the environment from which they came are the determining factors. The important question is: <b>are the levels of the factor going to be considered a random sample from a population of values which have a distribution</b>? If yes, then the effects should be considered random effects. 
</p>

<p>
Other questions that can inform our decision are:
</p>

<p>
Do the levels of a factor come from a probability distribution? If yes, random effects.
</p>

<p>
Is there enough information about a factor to decide that the levels of it in the data are like a random sample? If yes, random effects.
</p>
</div>
</div>

<div id="outline-container-org39d1666" class="outline-4">
<h4 id="org39d1666"><span class="done DONE">DONE</span> Random intercept model</h4>
<div class="outline-text-4" id="text-org39d1666">
<p>
This may occur in the setting of a longitudinal study of \(N\) patients, where each patient has their own covariates, such as age, gender, weight, diet, and physical performance. A key assumption is that the relationship between the covariates and the response does not vary from patient to patient (no random coefficients). However, when the study begins, each patient may have a different baseline response value. A random intercept model allows us to handle these different baselines. 
</p>

\begin{equation*}
Y_{ij} = \mu_i + X_{ij} \beta + \varepsilon_{ij} \\
i = 1, \ldots N, j = 1, \ldots n_i \\
\mu_i \overset{\text{iid}}{\sim} N(\mu, \sigma_a^2)
\end{equation*}
</div>
</div>

<div id="outline-container-org17776a3" class="outline-4">
<h4 id="org17776a3"><span class="done DONE">DONE</span> Linear mixed model</h4>
<div class="outline-text-4" id="text-org17776a3">
\begin{equation*}
Y_i = X_i \beta + Z_ib_i + \varepsilon_i \\
i = 1, \ldots N
\end{equation*}

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">\(Y_i \in \mathcal{R}^{n_i}\)</td>
<td class="org-left">the response of the \(i^\text{th}\) group/cluster/subject</td>
</tr>

<tr>
<td class="org-left">\(X_i \in \mathcal{R}^{n_i \times m}\)</td>
<td class="org-left">the design matrix for the \(i^\text{th}\) group/cluster/subject</td>
</tr>

<tr>
<td class="org-left">\(\beta \in \mathcal{R}^m\)</td>
<td class="org-left">fixed effects coefficients</td>
</tr>

<tr>
<td class="org-left">\(Z_i \in \mathcal{R}^{n_i \times k}\)</td>
<td class="org-left">design matrix of random effects for the \(i^\text{th}\) group/cluster/subject</td>
</tr>

<tr>
<td class="org-left">\(b_i \in \mathcal{R}^k\)</td>
<td class="org-left">random effects (random)</td>
</tr>

<tr>
<td class="org-left">\(\varepsilon_i \in \mathcal{R}^{n_i}\)</td>
<td class="org-left">error term (random)</td>
</tr>
</tbody>
</table>

<dl class="org-dl">
<dt class="on">&#x2611; Basic assumptions</dt><dd><ol class="org-ol">
<li>Random effects and errors are mutually indpendent.</li>
<li>\(E(\varepsilon_i) = 0\) and  \(\text{Cov}(\varepsilon_i) = \sigma^2 I_{n_i}\)</li>
<li>\(E(b_i) = 0\) and  \(\text{Cov}(b_i) = \sigma^2 D\)</li>
</ol></dd>
</dl>

<p>
We know \(\{Y_i, X_i, Z_i, i = 1, \ldots, N\}\)
</p>

<p>
Unknown \(\{\sigma^2, \beta, b_i, D \}\)
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Stacked Form</dt><dd></dd>
</dl>

<p>
\(N\) equations given above can be compressed into one as 
</p>

\begin{equation*}
Y = X\beta + Zb + \varepsilon
\end{equation*}

<p>
after stacking the data in a single vector and matrix form as follows:
</p>

\begin{equation*}
Y = 

\begin{bmatrix}
Y_1\\
Y_2\\
\vdots\\
Y_N
\end{bmatrix},

X = 

\begin{bmatrix}
X_1\\
X_2\\
\vdots\\
X_N
\end{bmatrix},

Z = 

\begin{bmatrix}
Z_1 \quad 0 \quad 0\\
0 \quad \ddots \quad 0\\
0 \quad 0 \quad Z_N
\end{bmatrix},

b = 

\begin{bmatrix}
b_1\\
b_2\\
\vdots\\
b_N
\end{bmatrix},

\varepsilon = 

\begin{bmatrix}
\varepsilon_1\\
\varepsilon_2\\
\vdots\\
\varepsilon_N
\end{bmatrix}
\end{equation*}

<p>
with \(\text{Cov}(b) = \sigma^2 (I \otimes D)\) and
</p>

<p>
\(\text{Cov}(Y) = \text{diag}(\text{Cov}(Y_i))\)
</p>

<p>
\(\text{Cov}(Y_i) = \text{Cov}(X_i \beta + Z_i b_i + \varepsilon_i) = \text{Cov}(Z_i b_i) + \text{Cov}(\varepsilon) = \sigma^2_i Z_i D Z_i^{\prime} + \sigma^2 I_{n_i} = \sigma^2 (Z_i D Z_i^{\prime} + i)\)
</p>

<p>
We can think of \(Zb + \varepsilon\) as \(\tilde{\varepsilon}\)
</p>
</div>
</div>

<div id="outline-container-org96e7cbb" class="outline-4">
<h4 id="org96e7cbb"><span class="done DONE">DONE</span> Identifiability definition</h4>
<div class="outline-text-4" id="text-org96e7cbb">
<p>
A staticial model for data \(Y\) is defined by a family of distributions of \(Y : \{P_\theta : \theta \in \Theta \}\)
</p>

<p>
\(\theta\) is a parameter and \(\Theta\) is the parameter space. 
</p>

<p>
A model is identifiable on \(\Theta\) if \(P_{\theta_1} = P_{\theta_2} \Rightarrow \theta_1 = \theta_2\) for \(\theta_1, \theta_2 \in \Theta\).
</p>

<p>
We must have one-to-one mapping from parameter space to model space. 
</p>

<p>
Identifiability is important, otherwise we could produce same estimator from different model parameter values. 
</p>

<p>
It may be the case that only <i>some</i> parameter values are identifiable. 
</p>
</div>
</div>

<div id="outline-container-org9a142c2" class="outline-4">
<h4 id="org9a142c2"><span class="done DONE">DONE</span> Identifiability theorem for LMM</h4>
<div class="outline-text-4" id="text-org9a142c2">
<p>
LMM is identifiable if
</p>

<ol class="org-ol">
<li>\(X = (X_1, X_2, \ldots, X_N)^\prime\) has full column rank</li>
<li>At least one \(Z_i\) has full column rank</li>
<li>\(\sum_{i = 1}^N (n_i - k) > 0\) (\(Z\) must be a tall matrix)</li>
</ol>

<p>
The statement may not hold in the opposite direction. 
</p>

<p>
To prove this, we assumed two models with different parameter values and showed that if they have the same distribution, then the parameter values are the same. We can do this by equating expectations and blocks of covariance matrices. 
</p>
</div>
</div>

<div id="outline-container-orga18d8dc" class="outline-4">
<h4 id="orga18d8dc"><span class="done DONE">DONE</span> Kronecker Product</h4>
<div class="outline-text-4" id="text-orga18d8dc">
<p>
Just remember that \(A \otimes B\) means each element of \(A\) gets multiplied by matrix \(B\).
</p>

<p>
\((A \otimes B)^{\prime} = A^{\prime} \otimes B^{\prime}\).  
</p>
</div>
</div>

<div id="outline-container-orgb7823ba" class="outline-4">
<h4 id="orgb7823ba"><span class="done DONE">DONE</span> Vectorization</h4>
<div class="outline-text-4" id="text-orgb7823ba">
<p>
Just stack up columns into a vector, starting with first column. 
</p>

\begin{equation*}
\text{Vec}(ABC) = (B^\prime \otimes A) \text{Vec}(C)
\end{equation*}

<p>
Any \(k^2\) -dimensional vector can be written as a vectorization of a \(k \times k\) matrix.
</p>

<p>
\(\text{Vec}^{\prime}(A) \text{Vec}(B) = tr(AB^{\prime}) = tr(A^{\prime}B)\).
</p>

<p>
\(\text{Vec}^{\prime}(A) \text{Vec}(A) = ||A||_F^2\).
</p>

<p>
\(||A||_F^2\) is sum of squares of all elements in \(A\).
</p>

<p>
\(\text{Vec}(ACB) = (B^{\prime} \otimes A) \text{Vec}(C)\).
</p>

<p>
\(\sum_{i = 1}^n \text{Vec}(A_i) = \text{Vec}(\sum_{i = 1}^n A_i)\)
</p>
</div>
</div>

<div id="outline-container-orgd7719be" class="outline-4">
<h4 id="orgd7719be"><span class="done DONE">DONE</span> Schur Complement Condition</h4>
<div class="outline-text-4" id="text-orgd7719be">
\begin{equation*}
{\begin{pmatrix}
A & B\\
B^\prime & C
\end{pmatrix} \succ 0} \Leftrightarrow {A \succ 0 \\ C - B^\prime A^{-1} B \succ 0}
\end{equation*}
</div>
</div>
</div>

<div id="outline-container-org8849735" class="outline-3">
<h3 id="org8849735"><span class="section-number-3">3.2</span> <span class="done DONE">DONE</span> MLE, ANOVA estimation, MINQUE, RMLE <code>[7/7]</code></h3>
<div class="outline-text-3" id="text-3-2">
</div>
<div id="outline-container-org8ce39a3" class="outline-4">
<h4 id="org8ce39a3"><span class="done DONE">DONE</span> Log-likelihood of LMM</h4>
<div class="outline-text-4" id="text-org8ce39a3">
<p>
Under normaility assumptions, 
</p>

\begin{equation*}
Y_i \sim N(X_i \beta, \sigma^2 (I + Z_i D Z_i^\prime)) \\
i = 1, \ldots, N
\end{equation*}

\begin{equation*}
\mathbb{P}(Y_i) = (2 \pi)^{-n_i / 2} | \sigma^2 (Z_i D Z_i^{\prime} + I_{n_i}) |^\frac{-1}{2} e^ {\frac{-1}{2} (Y_i - X_i \beta)^{\prime} (\sigma^2 (Z_i D Z_i^{\prime} + I_{n_i}))^{-1} (Y_i - X_i \beta)}
\end{equation*}


<p>
The log-likelihood function is given by
</p>

\begin{equation*}
l(\theta) = \sum_{i = 1}^{N} \left[ \frac{-n_i}{2} \log \sigma^2 - \frac{1}{2} \log |Z_i D Z_i^\prime + I_{n_i} | - \frac{\sigma^2}{2} (Y_i - X_i \beta)^\prime (Z_i D Z_i^\prime + I_{n_i})^{-1} (Y_i - X_i \beta) \right]
\end{equation*}

<p>
The MLE is the solution to \(\text{argmax} l(\theta)\) over \(\theta \in \Theta\). 
</p>
</div>
</div>

<div id="outline-container-org07f9e7e" class="outline-4">
<h4 id="org07f9e7e"><span class="done DONE">DONE</span> MLE \(\hat{\beta}\) <code>[2/2]</code></h4>
<div class="outline-text-4" id="text-org07f9e7e">
\begin{equation*}
\hat{\beta} = \left[ \sum_{i = 1}^{n} X_i^\prime (Z_i \hat{D} Z_i^\prime + I_{n_i})^{-1} X_i \right]^{-1} \left[ \sum_{i = 1}^{n} X_i^\prime (Z_i \hat{D} Z_i^\prime + I_{n_i})^{-1} Y_i \right]
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; when \(\hat{D} = 0\)</dt><dd></dd>
</dl>

\begin{equation*}
\hat{\beta} = \text{OLS}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; when \(\hat{D} = d I\) and \(d \to \infty\)</dt><dd></dd>
</dl>
<p>
Do SVD of \(Z_i\) as \(U_i \Sigma_i V_i^\top\)
</p>

\begin{equation*}
\underset{\beta}{\mathrm{argmin}} \sum_{i = 1}^{n} (Y_i - X_i \beta)^\prime (I_{n_i} - U_i U_i^\prime) (Y_i - X_i \beta) = \underset{\beta}{\mathrm{argmin}} ||Y_i - X_i \beta - Z_i b_i||_2^2
\end{equation*}

<p>
Here we are basically assuming the \(b_i\) are fixed effects. Then we get linear model and we claim \(\hat{\beta}\) in this scenario is equivalent to \(\hat{\beta}\) in LMM when \(\hat{D} \rightarrow \infty\).
</p>
</div>
</div>

<div id="outline-container-org65bacb0" class="outline-4">
<h4 id="org65bacb0"><span class="done DONE">DONE</span> MLE \(\hat{\sigma}^2\)</h4>
<div class="outline-text-4" id="text-org65bacb0">
<p>
Use profile log-likelihood
</p>
</div>
</div>

<div id="outline-container-org1f93338" class="outline-4">
<h4 id="org1f93338"><span class="done DONE">DONE</span> Derivatives of log-likelihood function</h4>
<div class="outline-text-4" id="text-org1f93338">
<p>
We can have derivatives for \(\beta\), \(\sigma^2\) or \(D\). These are called the maximum likelihood equations. 
</p>

\begin{equation*}
\frac{\partial l}{\partial \beta} = \sigma^{-2} \sum_{i= 1}^{N} [X_i^{\prime}(Z_i D Z_i^{\prime} + I)^{-1} (Y_i - X_i \beta)]
\end{equation*}

\begin{equation*}
\frac{\partial l}{\partial \sigma^2} = \frac{-1}{2} (\sum_{i = 1}^{N} n_i) \sigma^{-2} + \frac{1}{2} \sigma^{-4} \sum_{i= 1}^{N} [(Y_i - X_i \beta)^{\prime} (Z_i D Z_i^{\prime} + I)^{-1} (Y_i - X_i \beta)]
\end{equation*}

\begin{equation*}
\frac{\partial l}{\partial D} = \frac{-1}{2} \sum_{i= 1}^{N} [Z_i^{\prime}(Z_i D Z_i^{\prime} + I)^{-1} Z_i - \sigma^{-2} Z_i^{\prime}(Z_i D Z_i^{\prime} + I)^{-1} (Y_i - X_i \beta) (Y_i - X_i \beta)^{\prime} (Z_i D Z_i^{\prime} + I)^{-1} Z_i]
\end{equation*}

<p>
Can use helpful identities from the <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">Matrix Cookbook</a>
</p>
</div>
</div>

<div id="outline-container-orgdc903c3" class="outline-4">
<h4 id="orgdc903c3"><span class="done DONE">DONE</span> Balanced random coefficient model <code>[3/3]</code></h4>
<div class="outline-text-4" id="text-orgdc903c3">
<p>
See section 2.3 in Demidenko 1987. 
</p>

<p>
<i>Balanced</i> means each group has the same number of data points. 
</p>

<p>
There is fixed part and random part. 
</p>

<p>
BRCM is LMM with \(Z_i = X_i = Z\), \(i = 1, 2, \ldots, N\), \(n_1 = n_2 = \ldots = n_N = n\).
</p>

<p>
The model can be written as 
</p>

\begin{equation*}
Y_i = Z\beta_i + \varepsilon_i, \quad i = 1, \ldots, N \\
\beta_i = \beta + b_i \\
\text{where } \beta = \mathbb{E}(\beta_i), \mathbb{E}(b_i) = 0
\end{equation*}


<p>
BRCM is attractive because it allows us to obtain maximum likelihood estimates in closed forms.
</p>

<p>
An example is a longitudinal study where we measure babies at different time points. If we measure all the babies at the same times, then it is balanced.  
</p>

<dl class="org-dl">
<dt class="on">&#x2611; MLE for \(\beta\)</dt><dd></dd>
</dl>

\begin{equation*}
\bar{Y} = \frac{1}{N} \sum_{i = 1}^{N} Y_i, \\
\hat{\beta}_{ML} = (Z^{\prime}Z)^{-1} Z^{\prime} \bar{Y} = \hat{\beta}_{OLS}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; MLE for \(\sigma^2\)</dt><dd></dd>
</dl>
<p>
Solving the maximum likelihood equation, we get something like SSR. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; MLE for \(D\)</dt><dd></dd>
</dl>
<p>
Solving the maximum likelihood equation, we get a solution. 
</p>

<p>
The solutions for \(\sigma^2\) and \(D\) may not be the true solutions, since there are constraints on them (\(D \geq 0\) and \(\sigma^2 > 0\)). 
</p>

<p>
If global mimizer/maximizer occurs at boundary of the constraint, then gradient may not be zero at that point. 
</p>
</div>
</div>

<div id="outline-container-org5e0bec0" class="outline-4">
<h4 id="org5e0bec0"><span class="done DONE">DONE</span> Existence of MLE</h4>
<div class="outline-text-4" id="text-org5e0bec0">
<p>
The failure of an algorithm does not mean that the MLE does not exist. 
</p>

<p>
The MLE in the LME model exists with probability \(1\) if the total number of observations is sufficiently large, particularly if \(\sum (n_i - k) - m > 0\). 
</p>

<p>
If the MLE exists, the estimate of \(\sigma^2\) must be strictly positive.
</p>

<p>
The MLE may exist but make no sense for matrix \(D\). The existence of the MLE does not guarantee that matrix \(\hat{D}\) is positive definite. 
</p>

\begin{equation*}
\text{MLE exists } \Leftrightarrow S_\text{min} \triangleq \sum_{i = 1}^{N} ||Y_i - X_i\beta - Z_i b_i ||_2^2 > 0
\end{equation*}

<p>
See also section 2.5 in Demidenko 1987.
</p>

<p>
<span class="underline">Theorem</span>: Suppose the model identifiability conditions hold. 
</p>

<p>
The MLE over \(\Theta = \{ \beta \in \mathbb{R}^m, \sigma^2 > 0, D \succeq 0 \} \text{ exists } \Leftrightarrow S_\text{min} \triangleq \sum_{i = 1}^{N} || Y_i - X_i \beta - Z_i b_i ||_2^2 > 0\) 
</p>
</div>
</div>

<div id="outline-container-org342af40" class="outline-4">
<h4 id="org342af40"><span class="done DONE">DONE</span> LMM with random intercept <code>[3/3]</code></h4>
<div class="outline-text-4" id="text-org342af40">
<p>
See section 2.4 Demidenko 1987.
</p>

\begin{equation*}
y_{ij} = u_{ij}^\prime \gamma + \alpha + b_i + \varepsilon_{ij} \\
i = 1, \ldots, N \\
j = 1, \ldots, n_i \\
b_i \sim N(0, \sigma^2 d), \varepsilon_{ij} \sim N(0, \sigma^2)
\end{equation*}

<p>
\(b_i\)'s and \(\varepsilon_{ij}\)'s are mutually independent. 
</p>

<p>
\(\gamma\) and \(\alpha\) are regression parameters. \(u_{ij}\)'s are covariates.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; MLE for \(\hat{\beta}\)</dt><dd></dd>
</dl>
<p>
Ends up being OLS.
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; MLE for \(\sigma^2\)</dt><dd></dd>
</dl>
<p>
Get two cases.
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; MLE for \(d\)</dt><dd></dd>
</dl>
<p>
Get two cases.
</p>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
</div>
<div id="outline-container-org471caef" class="outline-3">
<h3 id="org471caef"><span class="section-number-3">3.3</span> <span class="done DONE">DONE</span> Computation and optimization <code>[9/9]</code></h3>
<div class="outline-text-3" id="text-3-3">
<p>
MLE in LMM may not have closed form.
</p>
</div>
<div id="outline-container-orgf557648" class="outline-4">
<h4 id="orgf557648"><span class="done DONE">DONE</span> Gradient methods <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-orgf557648">
<p>
<i>Iterative descent</i>: start with an initial guess, successivley generate more samples such that each sample increases the function value. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Steepest descent</dt><dd></dd>
</dl>

\begin{equation*}
x^{k+1} = x^{k} - \alpha^k \nabla f(x^k) \\
\alpha^k > 0 \text{ is the step size} \\
\nabla f(x^k) \text{ is the direction chosen}
\end{equation*}

<p>
So we are basically moving in the direction of the steepest decrease based on the gradient. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Newton's method</dt><dd></dd>
</dl>
<p>
Gradient descent is guided by local information. It may be improved if we use MORE local information, such as Hessian. 
</p>

\begin{equation*}
x^{k+1} = x^{k} - \alpha^k \left[\nabla^2 f(x^k)\right]^{-1} \nabla f(x^k) \\
\left[\nabla^2 f(x^k)\right]^{-1} \text{ is the Hessian}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Pure Newton iteration</dt><dd></dd>
</dl>
<p>
This is just Newton's method with \(\alpha^k = 1\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Armijo rule</dt><dd></dd>
</dl>
<p>
This rule basically guarantees that we will make progress at each iteration given a small enough step size.
</p>
</div>
</div>
<div id="outline-container-org4a5e476" class="outline-4">
<h4 id="org4a5e476"><span class="done DONE">DONE</span> Convergence issues</h4>
<div class="outline-text-4" id="text-org4a5e476">
<p>
We may stop at a stationary point instead of the global minimizer. 
</p>

<p>
The sequence may also not converge given a bad initialization. 
</p>
</div>
</div>

<div id="outline-container-org82a3571" class="outline-4">
<h4 id="org82a3571"><span class="done DONE">DONE</span> Rate of Convergence</h4>
<div class="outline-text-4" id="text-org82a3571">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Gradient descent</td>
<td class="org-left">Linear convergence</td>
</tr>

<tr>
<td class="org-left">Newton's method</td>
<td class="org-left">Quadratic convergence</td>
</tr>
</tbody>
</table>

<p>
There is a trade-off between convergence rate and computation time. 
</p>
</div>
</div>

<div id="outline-container-org2d573e6" class="outline-4">
<h4 id="org2d573e6"><span class="done DONE">DONE</span> Expectation-Maximization algorithm</h4>
<div class="outline-text-4" id="text-org2d573e6">
<p>
<b>E Step</b>: calculate conditional expectation of latent parameters given data and parameter values from previous iteration.
</p>

<p>
<b>M step</b>: solve the maximization problem to maximize this expectation with respect to parameters.
</p>

<p>
In LMM, distribution of latent parameters (random effects) given data and parameters is Gaussian.
</p>

<p>
See also section 2.12 of Demidenko 1987.
</p>
</div>
</div>

<div id="outline-container-orgbad8a88" class="outline-4">
<h4 id="orgbad8a88"><span class="done DONE">DONE</span> Fisher Scoring Algorithm</h4>
<div class="outline-text-4" id="text-orgbad8a88">
<p>
We use this to solve maximization of \(P(Y; \theta)\) with respect to \(\theta\).
</p>

\begin{equation*}
I(\theta^k) = E\left[-\nabla^2 \log P(Y;\theta^k) \right] \\
\theta^{k+1} = \theta^k + \alpha^k I^{-1}(\theta^k) \nabla \log P(Y ; \theta^k)
\end{equation*}

<p>
\(I(\theta^k)\) is the <i>Fisher information matrix</i>.
</p>
</div>
</div>

<div id="outline-container-orgf8e9de0" class="outline-4">
<h4 id="orgf8e9de0"><span class="done DONE">DONE</span> RMLE in LMM</h4>
<div class="outline-text-4" id="text-orgf8e9de0">
<p>
RMLE is the MLE of transformed data. We transform the data to get rid of nuisance parameters. RMLE can reduce the bias of MLE.
</p>

<p>
For example, MLE of \(\sigma^2\) is \(\text{SSE} / n\), which is biased. RMLE of \(\sigma^2\) is MSE, which is unbiased. 
</p>

<p>
The data transformation is of the form \(\tilde{Y} = A^\prime Y\). RMLE will not depend on the choice of A. 
</p>
</div>
</div>
<div id="outline-container-org213787e" class="outline-4">
<h4 id="org213787e"><span class="done DONE">DONE</span> MINQUE in LMM</h4>
<div class="outline-text-4" id="text-org213787e">
<p>
This is similar to idea of BLUE (best linear unbiased estimator).
</p>

<p>
Now we are interested in the Minimum norm quadratic unbiased estimator. We use this because \(\hat{\sigma}^2 = \text{MSE}\) is not a linear esitmator, but a quadratic estimator. It takes the form
</p>

\begin{equation*}
Y^\prime AY \\
A \succeq 0
\end{equation*}

<p>
Which quadratic forms are unbiased? <span class="underline">In LM setting</span> \(Y = X\beta + \varepsilon\), we have three conditions to make sure \(Y^\prime AY\) is unbiased. 
</p>

\begin{equation*}
X^\prime A X = 0 \\
\text{tr}(A) = 1 \\
A \succeq 0
\end{equation*}

<p>
The we find the MINQUE by solving \(\text{argmin} ||A||_\text{F}^2\) under these conditions.
</p>

<p>
In the gaussian case, solving for MINQUE is actually just reducing the variance of the quadratic form. 
</p>

<p>
<span class="underline">In LMM case</span>, we have different conditions for \(Y^\prime A Y\) to be unbiased.
</p>

\begin{equation*}
X^\prime A X = 0 \\
\text{tr}(A) = 1 \\
Z^\prime A Z = 0 \\
A \succeq 0
\end{equation*}

<p>
In this case, MINQUE is like MSE under linear model with \(Zb\) treated as fixed effects. 
</p>

<p>
Also see 1.5.2 in Jiang 2007. 
</p>
</div>
</div>

<div id="outline-container-org80eb2a4" class="outline-4">
<h4 id="org80eb2a4"><span class="done DONE">DONE</span> ANOVA Estimation</h4>
<div class="outline-text-4" id="text-org80eb2a4">
<p>
The basic idea comes from the method of moments. Use expectations of different sums of squares and solve for the parameters of interest. The hardest part is coming up with the relevant sums of squares.
</p>

<p>
Suppose there are \(q\) variance components involved in a linear mixed model. Let \(Q\) be a \(q\) -dimensional vector whose components are quadratic functions of the data. The ANOVA estimators of the variance components are obtained by solving the system of equations \(E(Q) = Q\). Then the problem is just choosing \(Q\). See 1.5.1 in Jiang 2007. 
</p>
</div>
</div>
<div id="outline-container-orged81b08" class="outline-4">
<h4 id="orged81b08"><span class="done DONE">DONE</span> A general method of moments</h4>
<div class="outline-text-4" id="text-orged81b08">
<p>
Construct sample moments, match to population moments, and solve the system of equations. 
</p>
</div>
</div>
</div>
<div id="outline-container-org1564b2b" class="outline-3">
<h3 id="org1564b2b"><span class="section-number-3">3.4</span> <span class="done DONE">DONE</span> Hypothesis testing and confidence intervals <code>[6/6]</code></h3>
<div class="outline-text-3" id="text-3-4">
</div>
<div id="outline-container-orgeb942b2" class="outline-4">
<h4 id="orgeb942b2"><span class="done DONE">DONE</span> F test</h4>
<div class="outline-text-4" id="text-orgeb942b2">
<p>
The testing problem is: \(H_0: D = 0 \quad H_1 : D \neq 0\).
</p>

<p>
We are basically testing the presence of random effects. 
</p>

<p>
SSE under full model,
</p>

\begin{equation*}
S_\text{min} = \min_{\beta, \{b_i\}} \sum_{i = 1}^N ||Y_i - X_i \beta - Z_i b_i ||_2^2
\end{equation*}

<p>
SSE under null,
</p>

\begin{equation*}
S_\text{OLS} = \min_{\beta} \sum_{i = 1}^N ||Y_i - X_i \beta||_2^2
\end{equation*}

<p>
We then use quadratic form theory to show that both SSE's are chi-squared and independent, and then we can construct the \(F\) test statistic as
</p>

\begin{equation*}
F = \frac{(S_{\text{OLS}} - S_\min) / \tilde{r}}{S_\min / r} \sim F_{\tilde{r}, r} \quad \text{under } H_0 \\
\tilde{r} = \text{rank}(W) - \text{rank}(X), \quad W = (X \vert Z) \\
r = \sum_{i = 1}^N n_i - \text{rank}(W)
\end{equation*}

<p>
We reject \(H_0\) if \(F > F_{\tilde{r}, r} (1 - \alpha)\)
</p>

<p>
In general in LMM, we don't have a nice \(F\) test for \(A\beta\).
</p>
</div>
</div>

<div id="outline-container-org2c21e3a" class="outline-4">
<h4 id="org2c21e3a"><span class="done DONE">DONE</span> Likelihood ratio test</h4>
<div class="outline-text-4" id="text-org2c21e3a">
<p>
Let \(X_1, \ldots, X_n\) be a random sample from density \(P(X ; \theta)\) with parameter \(\theta\) and parameter space \(\Theta\). Consider the test
</p>

\begin{equation*}
H_0 : \theta \in \Theta_0 \\
(\Theta_0 \subseteq \Theta \text{ is a subset of the parameter space})
\end{equation*}

<p>
The likelihood ratio statistic is then:
</p>

\begin{equation*}
R = \frac{\sup_{\theta \in \Theta_0} \prod_{i = 1}^{n} P(X_i ; \theta)}{\sup_{\theta \in \Theta} \prod_{i = 1}^{n} P(X_i ; \theta)}
\end{equation*}

<p>
We reject \(H_0\) when \(R\) is small, where \(0 \leq R \leq 1\).
</p>

<p>
We don't actually work directly with \(R\), instead we work with \(-2 \log R\), where
</p>

\begin{equation*}
-2 \log R \rightarrow \chi^2_r \text{ as } n \rightarrow \infty \text{ under } H_0, \\
r = \text{dim}(\Theta) - \text{dim}(\Theta_0)
\end{equation*}

<p>
Therefore, we can only assymptotically control type I error, with rejection region
</p>

\begin{equation*}
\{ -2 \log R > c\}, c = \chi^2_r(1 - \alpha)
\end{equation*}
</div>
</div>

<div id="outline-container-org9f74e33" class="outline-4">
<h4 id="org9f74e33"><span class="done DONE">DONE</span> C.I. for \(\sigma^2\) in LMM</h4>
<div class="outline-text-4" id="text-org9f74e33">
<p>
\(S_\min = \min_{\beta, \{b_i\}} \sum_{i = 1}^N ||Y_i - X_i \beta - Z_i b_i ||_2^2\).
</p>

\begin{equation*}
W = 
\begin{pmatrix}
X_1 & Z_1 & 0 & 0 \\
\vdots & 0 & \ddots & 0 \\
X_n & 0 & 0 & Z_n
\end{pmatrix}
\end{equation*}

<p>
Our pivot is then 
</p>

\begin{equation*}
\frac{S_\min}{\sigma^2} \sim \chi^2_r, \quad r = \sum_{i = 1}^{N} n_i - \text{rank}(W)
\end{equation*}

\begin{equation*}
\mathbb{P}\left(\chi_r^2 (\frac{\alpha}{2}) \leq \frac{S_\min}{\sigma^2} \leq \chi^2_r (1 - \frac{\alpha}{2})\right) = 1 - \alpha
\end{equation*}

<p>
Solving for \(\sigma^2\) gives a \(1 - \alpha\) level confidence interval. We get
</p>

\begin{equation*}
\left( \frac{S_\min}{\chi^2_r (1 - \frac{\alpha}{2})},  \frac{S_\min}{\chi^2_r (\frac{\alpha}{2})} \right)
\end{equation*}
</div>
</div>

<div id="outline-container-org17659e2" class="outline-4">
<h4 id="org17659e2"><span class="done DONE">DONE</span> Confidence region for \(D \in \mathbb{R}^{k \times k}\)</h4>
<div class="outline-text-4" id="text-org17659e2">
<p>
An exact C.I. for \(D\) may be obtained in some special cases. Foe example,
</p>

\begin{equation*}
y_{ij} = \mu + \alpha_i + \varepsilon_{ij}, \quad i = 1, \ldots, N, \quad j = 1, \ldots, n, \\
\alpha_i \sim N(0, \sigma^2_a) \\
\varepsilon_{ij} = N(0, \sigma^2)
\end{equation*}

<p>
So here, \(D = \frac{\sigma^2_a}{\sigma^2}\)
</p>

<p>
We then know
</p>

\begin{equation*}
\text{SSA} = \sum_{i = 1}^N \sum_{j = 1}^n (\bar{Y_i} - \bar{Y})^2, \quad \bar{Y_i} = \frac{1}{n} \sum_{j = 1}^n y_{ij} \\
\text{SSE} = \sum_{i = 1}^N \sum_{j = 1}^n (y_{ij} - \bar{Y_i})^2, \quad \bar{Y} = \frac{1}{Nn} \sum_{i = 1}^N \sum_{j = 1}^n y_{ij} = \frac{1}{N} \sum_{i = 1}^N \bar{Y_i}
\end{equation*}

<p>
with 
</p>

\begin{equation*}
\frac{\text{SSE}}{\sigma^2} \sim \chi^2_{Nn-N}, \\
\frac{\text{SSA}}{n \sigma^2_a + \sigma^2} \sim \chi^2_{N-1}, \\
\text{SSA} \perp \text{SSE}
\end{equation*}

<p>
Therefore, we can construct an \(F\) distribution to get a \(1 - \alpha\) level C.I. for \(D = \frac{sigma^2_a}{\sigma^2}\) as
</p>

\begin{equation*}
\left[ \frac{1}{n} \left( \frac{\text{MSA} / \text{MSE}}{F_{N - 1, N(n-1)}(1 - \frac{\alpha}{2})} - 1 \right), \frac{1}{n} \left( \frac{\text{MSA} / \text{MSE}}{F_{N - 1, N(n-1)}(\frac{\alpha}{2})} - 1 \right) \right], \\

\text{MSA} = \frac{\text{SSA}}{N - 1}, \quad \text{MSE} = \frac{\text{SSE}}{N(n-1)}
\end{equation*}
</div>
</div>

<div id="outline-container-orgb357343" class="outline-4">
<h4 id="orgb357343"><span class="done DONE">DONE</span> C.I. for functions of \(\sigma^2\) and \(D\)</h4>
<div class="outline-text-4" id="text-orgb357343">
<p>
An exact C.I. may exist in some special cases, such as the one we just considered above. 
</p>

<p>
For example, we may want a C.I. for \(\sigma^2_a + \sigma^2\).
</p>

<p>
If we look at the data \(y_{11}, y_{21}, \ldots, y_{n1}\), we know that they are iid \(N(\mu, \sigma^2_a + \sigma^2)\). This can be called the first group \((i = 1)\). The idea is to get a summary statistic for each group, denoted \(Q_1, Q_2, \ldots, Q_N\), in the form
</p>

\begin{equation*}
Q_i = \sum_{j = 1}^{n} c_j y_{ij} \sim N(\mu, \sigma^2_a + \sigma^2)
\end{equation*}

<p>
with two constraints to match the mean and variance, respectively,
</p>

\begin{equation*}
\sum_{j = 1}^n c_j = 1, \\
\sum_{j = 1}^n c_j^2 = 1
\end{equation*}

<p>
This way we can use all the data instead of just one group. 
</p>
</div>
</div>

<div id="outline-container-org28f9792" class="outline-4">
<h4 id="org28f9792"><span class="done DONE">DONE</span> Approximate C.I. for variance components <code>[2/2]</code></h4>
<div class="outline-text-4" id="text-org28f9792">
<p>
Continuing the example from above, suppose we want a C.I. for some linear function
</p>

\begin{equation*}
\xi = c_1 \mathbb{E}(\text{MSA}) + c_2 \mathbb{E}(\text{MSE}), \quad c_1, c_2 > 0 \\
\mathbb{E}(\text{MSA}) = n\sigma^2_a + \sigma^2, \quad \mathbb{E}(\text{MSE}) = \sigma^2
\end{equation*}

<p>
e.g. \(\sigma^2_a + \sigma^2 = \text{Var}(y_{ij}) \Rightarrow c_1 = \frac{1}{n}, \quad c_2 = 1 - \frac{1}{n}\)
</p>

<p>
We then have that \(\hat{\xi} = c_1 \text{MSA} + c_2 \text{MSE}\) is unbiased for \(\xi\). 
</p>

<p>
And we can approximate \(\hat{\xi}\) by a \(\chi^2\) distribution.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Sattertheuaite's Approximation</dt><dd></dd>
</dl>
<p>
We match the first and second moments as 
</p>

\begin{equation*}
\frac{\hat{\xi}}{\xi} \sim \frac{\chi^2_d}{d}, \\
\text{Var}(\frac{\hat{\xi}}{\xi}) = \text{Var}(\frac{\chi^2_d}{d})
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Large-sample approximation</dt><dd></dd>
</dl>
<p>
We have 
</p>

\begin{equation*}
\frac{\hat{\xi} - \xi}{\sqrt{\text{Var}(\hat{\xi})}} \rightarrow N(0, 1), \quad N \rightarrow \infty
\end{equation*}
</div>
</div>
</div>

<div id="outline-container-org5a77854" class="outline-3">
<h3 id="org5a77854"><span class="section-number-3">3.5</span> <span class="done DONE">DONE</span> Generalized linear models <code>[6/6]</code></h3>
<div class="outline-text-3" id="text-3-5">
</div>
<div id="outline-container-org37a9069" class="outline-4">
<h4 id="org37a9069"><span class="done DONE">DONE</span> GLM Setup</h4>
<div class="outline-text-4" id="text-org37a9069">
<p>
Recall classical linear models: \(Y_i = X_i^{\prime} \beta + \varepsilon_i, \quad i = 1, \ldots, n\) with \(\varepsilon_i \sim N(0, \sigma^2)\).
</p>

<ol class="org-ol">
<li>the <span class="underline">random</span> component: \(Y_i \sim N(\mu_i, \sigma^2)\) with all the \(Y_i\) independent</li>
<li>the <span class="underline">systematic</span> component: a linear predictor \(\eta_i + X_i^{\prime} \beta, \quad i = 1, \ldots, n\)</li>
<li>the <span class="underline">link</span> between the random and systematic component: \(\mu_i = \eta_i, \quad i = 1, \ldots, n\)</li>
</ol>

<p>
GLM can be viewed as an extension of linear models, where
</p>

<p>
a. The distribution in the random component may come from an exponential family
</p>

<p>
b. The link between \(\mu_i\) and \(\eta_i\) may be through general monotonic differentiable functions: \(\eta_i = g(\mu_i)\).
</p>
</div>
</div>
<div id="outline-container-org03a1d8a" class="outline-4">
<h4 id="org03a1d8a"><span class="done DONE">DONE</span> Exponential family distribution <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-org03a1d8a">
<p>
The pdf/pmf can be expressed in the form:
</p>

\begin{equation*}
f(y ; \theta, \phi) = \exp \left[ \frac{y \theta - b(\theta)}{a(\phi)} + c(\phi, y) \right]
\end{equation*}

<p>
where \(a(\cdot), b(\cdot), \text{ and } c(\cdot)\) are some specific functions. 
</p>

<p>
\(\theta\): canonical parameter
</p>

<p>
\(\phi\): dispersion parameter (either known or unknown). 
</p>

\begin{equation*}
\mathbb{E}(y) = b^{\prime}(\theta) \triangleq \mu \\
\text{Var}(y) = b^{\prime\prime}(\theta) a(\phi) \\
\theta = (b^{\prime})^{-1} (\mu), (b \text{ derivative inverse of } \mu) \\
\text{"Variance function" } = b^{\prime\prime}((b^{\prime})^{-1}(\mu)) = V(\mu)
\end{equation*}

<p>
\(a(\phi)\) is positive in general.
</p>

<p>
Denote the log-likelihood function for the exponential family:
</p>

\begin{equation*}
l(\theta, \phi) = \frac{y \theta - b(\theta)}{a(\phi)} + c(\phi, y)
\end{equation*}

<p>
We know
</p>

\begin{equation*}
\text{Score } = \mathbb{E} \left(\frac{\partial l}{\partial \theta} \right) = 0 \\
\text{Information } = \text{Var}\left(\frac{\partial l}{\partial \theta}\right) = - \mathbb{E}\left(\frac{\partial^2 l}{\partial \theta^2}\right)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Gaussian</dt><dd></dd>
</dl>

\begin{equation*}
y \sim N(\mu, \sigma^2), \\
f(y) = \exp \left[ \frac{y\mu - \frac{\mu^2}{2}}{\sigma^2} - \frac{1}{2} \left( \frac{y^2}{\sigma^2} + \log (2 \pi \sigma^2) \right) \right] \\

\theta = \mu, \phi = \sigma^2, b(\theta) = \frac{\theta^2}{2}, a(\phi) = \phi, c(\phi, y) = \frac{-1}{2} \left( \frac{y^2}{\sigma^2} + \log (2 \pi \sigma^2) \right)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Poisson</dt><dd></dd>
</dl>

\begin{equation*}
\mathbb{P}(y = k) = e^{-\lambda} \frac{\lambda^k}{k!}, k = 0, 1, \ldots, \quad \lambda > 0
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Binomial</dt><dd></dd>
</dl>

\begin{equation*}
\mathbb{P}(y = k) = {n \choose k} p^k (1-p)^{n - k}, k = 0, 1, \ldots, n, \quad p \in (0, 1)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Gamma</dt><dd></dd>
</dl>

\begin{equation*}
\mathbb{P}(y) = \frac{\beta^\alpha}{\Gamma(\alpha)} y^{\alpha - 1} e^{-\beta y}, y > 0, \alpha, \beta > 0
\end{equation*}
</div>
</div>

<div id="outline-container-org6ef6bbb" class="outline-4">
<h4 id="org6ef6bbb"><span class="done DONE">DONE</span> Link Functions <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-org6ef6bbb">
\begin{equation*}
\mu = \mathbb{E}(Y) \\
g(\mu) = \eta = X^{\prime}\beta
\end{equation*}

<ol class="org-ol">
<li>In classical linear model, \(g(\mu) = \mu\).</li>
<li>When \(Y\) is not continuous over \((-\infty, \infty)\), the identity link is less attractive.</li>
</ol>

<p>
The link function links together the mean of \(y_i\) and the linear predictors. 
</p>

<p>
Some popular choices for binary data, which map \([0, 1] \rightarrow \mathbb{R}\)
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Logit</dt><dd></dd>
</dl>

<p>
"Logistic regression"
</p>

\begin{equation*}
g(\mu) = \log \left( \frac{\mu}{1 - \mu} \right)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Probit</dt><dd></dd>
</dl>

\begin{equation*}
g(\mu) = \Phi^{-1} (\mu)
\end{equation*}

<p>
where \(\Phi(\cdot)\) is cdf of \(N(0, 1)\) 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Complementary log-log</dt><dd></dd>
</dl>

\begin{equation*}
g(\mu) = \log [ -\log (1 - \mu)]
\end{equation*}

<p>
Deciding which link function to use is a model selection problem. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Canonical links</dt><dd></dd>
</dl>
<p>
\(\theta\) is the canonical parameter in the exponential family, with \((\theta = b^{\prime})^{-1}(\mu)\). So, the canonical link is just \((b^{\prime})^{-1}(\cdot)\).
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Distribution</th>
<th scope="col" class="org-left">\(b(\theta)\)</th>
<th scope="col" class="org-left">Canonical Link</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Normal</td>
<td class="org-left">\(\frac{\theta^2}{2}\)</td>
<td class="org-left">\(g(\mu) = \mu\)</td>
</tr>

<tr>
<td class="org-left">Poisson</td>
<td class="org-left">\(e^{\theta}\)</td>
<td class="org-left">\(g(\mu) = \log \mu\)</td>
</tr>

<tr>
<td class="org-left">Bernoulli</td>
<td class="org-left">\(\log(1 + e^\theta)\)</td>
<td class="org-left">\(g(\mu) = \log \frac{\mu}{1 - \mu}\)</td>
</tr>

<tr>
<td class="org-left">Gamma</td>
<td class="org-left">\(- \log (-\theta)\)</td>
<td class="org-left">\(g(\mu) = \frac{-1}{\mu}\)</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org14d32e7" class="outline-4">
<h4 id="org14d32e7"><span class="done DONE">DONE</span> log-likelihood for GLM</h4>
<div class="outline-text-4" id="text-org14d32e7">
\begin{equation*}
l(\beta, \phi) = \sum_{i = 1}^n \left[ \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(\phi, y_i) \right]
\end{equation*}

<p>
We can replace \(\theta_i\) with function of \(X_i^{\prime} \beta\) since \(\mu_i = b^{\prime}(\theta_i)\) and \(g(\mu_i) = X_i^{\prime} \beta\). 
</p>
</div>
</div>

<div id="outline-container-orga045866" class="outline-4">
<h4 id="orga045866"><span class="done DONE">DONE</span> Fisher scoring algorithm</h4>
<div class="outline-text-4" id="text-orga045866">
<p>
We want to maximize \(l(\beta, \phi)\) for \(\beta\) and \(\phi\).
</p>

<p>
We assume without loss of generality that \(a(\phi) > 0\).
</p>

\begin{equation*}
\hat{\beta}_\text{ML} = \arg\max_{\substack{\beta \in \mathbb{R}^p}} \sum_{i = 1}^n (y_i \theta_i - b(\theta_i)) \triangleq \arg\max_{\substack{\beta \in \mathbb{R}^p}} \tilde{l}(\beta)
\end{equation*}

<p>
We use the Fisher Scoring Algorithm (iterative least squares) to minimize \(-\tilde{l} (\beta)\)
</p>

\begin{equation*}
\beta^{t+1} = \beta^t + \alpha^t \left[ \sum_{i = 1}^n \frac{X_iX_i^{\prime}}{V(\mu_i) (g^{\prime}(\mu_i))^2} \right]^{-1} \left[ \sum_{i = 1}^n \frac{(y_i - \mu_i)}{V(\mu_i) g^{\prime}(\mu_i)} X_i \right] \\

\mu_i = g^{-1} (X_i^{\prime}\beta^t)
\end{equation*}

<p>
where \(\alpha^t\) is the step size. 
</p>

<p>
We can also write it as
</p>

\begin{equation*}
Y = 
\begin{pmatrix}
y_1 \\ \vdots \\ y_n
\end{pmatrix}, 

\mu = 
\begin{pmatrix}
\mu_1 \\ \vdots \\ \mu_n
\end{pmatrix}, 

\Delta = 
\begin{pmatrix}
g^{\prime}(\mu_1) & \ldots & 0 \\
0 & \ddots & 0 \\
0 & \ldots & g^{\prime}(\mu_n)
\end{pmatrix}, \\

X = 
\begin{pmatrix}
X_1^{\prime} \\ \vdots \\ X_n^{\prime}
\end{pmatrix}, 

W = 
\begin{pmatrix}
\frac{1}{V(\mu_1)(g^{\prime}(\mu_1))^2} & \ldots & 0 \\
0 & \ddots & 0 \\
0 & \ldots & \frac{1}{V(\mu_n)(g^{\prime}(\mu_n))^2})
\end{pmatrix}

\end{equation*}

<p>
So \(\beta^{t+1} = \beta^t + \alpha^t (X^{\prime}WX)^{-1} X^{\prime}W\Delta(Y - \mu)\).
</p>

<p>
We commonly choose \(\alpha^t = 1\), so we get
</p>

\begin{equation*}
\beta^{t+1} = (X^{\prime}WX)^{-1} X^{\prime}W [X\beta^t + \Delta(Y - \mu)]
\end{equation*}

<p>
which we recognize as weighted OLS.
</p>

<p>
In the Gaussian case, we get OLS in one step. 
</p>

<p>
When using a canonical link, you always get a convex optimization problem, and the Fisher scoring algorithm is equivalent to Newton's method. 
</p>

<p>
After getting \(\hat{\beta}\), we plug it back into \(l(\beta, \phi)\) and solve the one-dimensional problem for \(\phi\). 
</p>
</div>
</div>

<div id="outline-container-org721c0c4" class="outline-4">
<h4 id="org721c0c4"><span class="done DONE">DONE</span> Inference in GLM <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-org721c0c4">
<p>
We have \(\{ y_i \}_{i = 1}^n\) are independent.
</p>

<p>
Each \(y_i\) has pmf/pdf
</p>

\begin{equation*}
f(y ; \theta, \phi) = \exp \left[ \frac{y \theta - b(\theta)}{a(\phi)} + c(\phi, y) \right] \\
\mathbb{E}(y_i) = b^{\prime}(\theta_i) = \mu_i, \quad g(\mu_i) = X_i^{\prime} \beta.
\end{equation*}

<p>
The parameters are \(\theta = (\beta, \phi)\). 
</p>

<p>
The log-likelihood function is \(l_n(\theta)\).
</p>

<p>
The score function is \(S_n(\theta) = \frac{\partial l_n(\theta)}{\partial \theta}\).
</p>

<p>
The information matrix is \(F_n(\theta) = \text{Cov} (S_n(\theta)) = \mathbb{E} \left[ - \frac{\partial^2 l_n(\theta)}{\partial \theta^2} \right]\). 
</p>

<p>
Generally speaking, no exact tests such as \(F\) -tests are available. We rely on large-sample tests. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Likelihood ratio test</dt><dd></dd>
</dl>

\begin{equation*}
H_0: \theta \in \Theta_0, \quad H_1: \theta \in \Theta \backslash \Theta_0
\end{equation*}

<p>
where \(\Theta\) is the parameter space of \(\theta\). 
</p>

<p>
The likelihood ratio test statistic is 
</p>

\begin{equation*}
T_R = -2 \log \frac{\max_{\theta \in \Theta_0} e^{l_n(\theta)}}{\max_{\theta \in \Theta} e^{l_n(\theta)}} = 2 \left[ \sup_{\theta \in \Theta} l_n(\theta) - \sup_{\theta \in \Theta_0} l_n(\theta) \right], \\
T_R \rightarrow \chi_r^2 \text{ as } n \rightarrow \infty \text{ under } H_0, \\
r = \text{dim}(\Theta) - \text{dim}(\Theta_0)
\end{equation*}

<p>
Reject \(H_0\) if \(T_R\) is large. 
</p>

\begin{equation*}
T_R > \chi^2_r (1 - \alpha)
\end{equation*}

<p>
Type 1 error \(\rightarrow \alpha\) as \(n \rightarrow \infty\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Wald Test</dt><dd></dd>
</dl>
<p>
The Wald test uses the large-sample normality of the ML estimator to form a test. 
</p>

\begin{equation*}
H_0: h(\theta) = 0, \quad \Theta_0 = \{\theta : h(\theta) = 0 \}, \quad h: \mathbb{R}^p \rightarrow \mathbb{R}^q, \\ 

h(\theta) = 

\begin{pmatrix}
h_1(\theta) \\ \vdots \\ h_q(\theta)
\end{pmatrix}
\end{equation*}

<p>
Assume \(h\) is continuously differentiable. 
</p>

<p>
The Jacobian \(Dh(\theta) \in \mathbb{R}^{q \times p}\) has entries \(\left[ Dh(\theta) \right]_{ij} = \frac{\partial h_i(\theta)}{\partial \theta_j}\).
</p>

<p>
\(Dh(\theta)\) is full rank under \(H_0\).
</p>

<p>
Denote the MLE \(\hat{\theta}_n = \arg\max_{\substack{\theta \in \Theta}} l_n(\theta)\). 
</p>

\begin{equation*}
\hat{\theta}_n \approx N(\theta, F_n^{-1}(\theta))
\end{equation*}

<p>
and using the Delta method to get asymptotic distribution of a function of the MLE, we have
</p>

\begin{equation*}
h(\hat{\theta}_n) \approx N(h(\theta), Dh(\theta) F_n^{-1}(\theta) D^{\prime}h(\theta)) \\
\Downarrow \\
(h(\hat{\theta} - 0)^{\prime} [Dh(\theta) F_n^{-1}(\theta) D^{\prime}h(\theta)]^{-1} (h(\hat{\theta} - 0) \approx \chi^2_q
\end{equation*}

<p>
and since we don't know \(\theta\), we replace by \(\hat{\theta}\) to get 
</p>

\begin{equation*}
T_W \triangleq (h(\hat{\theta} - 0)^{\prime} [Dh(\hat{\theta}) F_n^{-1}(\hat{\theta}) D^{\prime}h(\hat{\theta})]^{-1} (h(\hat{\theta} - 0) \approx \chi^2_q
\end{equation*}

<p>
Reject if \(T_W \geq \chi^2_q (1 - \alpha)\).
</p>

<p>
The Wald Test and the LRT for the same \(H_0\) give the same asymptotic distribution, \(\chi^2_q = \chi^2_r, \quad q = r\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Score Test</dt><dd></dd>
</dl>

\begin{equation*}
H_0: \theta \in \Theta_0, \quad H_1: \theta \in \Theta \backslash \Theta_0, \\
\tilde{\theta}_n = \arg\max_{\substack{\theta \in \Theta}} l_n(\theta)
\end{equation*}

<p>
Under regularity conditions,
</p>

\begin{equation*}
T_S \triangleq S_n^{\prime}(\tilde{\theta}_n) F_n^{-1}(\tilde{\theta}_n) S_n(\tilde{\theta}_n) \rightarrow \chi^2_r \text{ as } n \rightarrow \infty \text{ under } H_0 \\
r = \text{dim}(\Theta) - \text{dim}(\Theta_0)
\end{equation*}

<p>
We reject \(H_0\) if \(T_s > \chi^2_r (1 - \alpha)\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Confidence Intervals</dt><dd></dd>
</dl>
<p>
Exact C.I. is not available in general. We construct large-sample C.I.
</p>

<ol class="org-ol">
<li>C.I. for \(\xi = h(\theta) (h: \mathbb{R}^p \rightarrow \mathbb{R}^q\) based on <span class="underline">LRT statistic</span>.</li>
</ol>

<p>
Approximate pivot:
</p>

\begin{equation*}
P_R = 2 \left[ \sup_{\theta \in \Theta} l_n(\theta) - \sup_{\theta \in \Theta_0} l_n(\theta) \right], \\
\Theta_0 = \{\theta \in \Theta : h(\theta) = \xi \} \\
P_R \rightarrow \chi^2_q \text{ as } n \rightarrow \infty
\end{equation*}

<ol class="org-ol">
<li>C.I. for \(\xi = h(\theta)\) based on <span class="underline">Wald statistic</span>.</li>
</ol>

<p>
Approximate pivot:
</p>

\begin{equation*}
P_W = (h(\hat{\theta} - \xi)^{\prime} [Dh(\hat{\theta}) F_n^{-1}(\hat{\theta}) D^{\prime}h(\hat{\theta})]^{-1} (h(\hat{\theta} - \xi)
P_W \rightarrow \chi^2_q \text{ as } n \rightarrow \infty
\end{equation*}

<ol class="org-ol">
<li>C.I. for \(\theta\) based on <span class="underline">Score statistic</span>.</li>
</ol>

<p>
Approximate pivot:
</p>

\begin{equation*}
P_S = S_n^{\prime}(\theta) F_n^{-1}(\theta) S_n(\theta) \rightarrow \chi^2_p \text{ as } n \rightarrow \infty
\end{equation*}

<p>
If instead we want a C.I. for \(\xi = h(\theta)\), we use
</p>

\begin{equation*}
P_S = S_n^{\prime}(\tilde{\theta}_\xi) F_n^{-1}(\tilde{\theta}_\xi) S_n(\tilde{\theta}_\xi) \rightarrow \chi^2_p \text{ as } n \rightarrow \infty \\
\tilde{\theta}_\xi = \arg \max_{\theta : h(\theta) = \xi} l_n(\theta)
\end{equation*}
</div>
</div>
</div>

<div id="outline-container-org1d2272d" class="outline-3">
<h3 id="org1d2272d"><span class="section-number-3">3.6</span> <span class="done DONE">DONE</span> Quasi-likelihood estimation <code>[3/3]</code></h3>
<div class="outline-text-3" id="text-3-6">
<p>
In many problems of statistical estimation, we know some detail of the distribution governing the data, but may be unwilling to specify it exactly. Maximum likelihood requires exact specification of the distrivubution in order to construct the likelihood. Quasi-likelihood is a method of estimation that requires only a model for the mean of the data and the relationship between the mean and the variance. 
</p>

<p>
The idea is to use normality-based estimators even if the data are not really normal. 
</p>
</div>

<div id="outline-container-orga36a180" class="outline-4">
<h4 id="orga36a180"><span class="done DONE">DONE</span> Review of MLE</h4>
<div class="outline-text-4" id="text-orga36a180">
<p>
Important characteristics of likelihood:
</p>

\begin{equation*}
\mathbb{E}\left( \frac{\partial \log p(Y ; \theta^*)}{\partial \theta} \right) = 0, \\
\text{Var}\left( \frac{\partial \log p(Y ; \theta^*)}{\partial \theta} \right) = \mathbb{E}\left( \frac{\partial^2 \log p(Y ; \theta^*)}{\partial \theta^2} \right)
\end{equation*}

<p>
Suppose \(Y_1, Y_2, \ldots, Y_n \sim \mathbb{P}(Y ; \theta^*)\)
</p>

\begin{equation*}
l_n(\theta) = \sum_{i = 1}^n \log p(Y_i ; \theta), \quad S_n(\theta) = \sum_{i = 1}^n \frac{\partial \log p(Y ; \theta)}{\partial \theta}
\end{equation*}

\begin{equation*}
\hat{\theta}_n = \arg \max_\theta l_n (\theta), \\
\end{equation*}

\begin{equation*}
{S_n (\hat{\theta}_n) = 0, \\
\mathbb{E}(S_n(\theta^*)) = 0, \\
S_n(\theta) \approx \mathbb{E}(S_n(\theta))} \\ \Downarrow \\ \hat{\theta}_n \approx \theta^*
\end{equation*}

<p>
And using a first order Taylor expansion, we have that
</p>

\begin{equation*}
\sqrt{n} (\hat{\theta}_n - \theta^*) \approx N(0, I^{-1}(\theta^*)), \\
I(\theta^*) = \text{Cov}\left( \frac{\partial \log p(Y ; \theta^*)}{\partial \theta} \right)
\end{equation*}
</div>
</div>

<div id="outline-container-org3cafa64" class="outline-4">
<h4 id="org3cafa64"><span class="done DONE">DONE</span> Construction of Quasi-likelihood function</h4>
<div class="outline-text-4" id="text-org3cafa64">
<p>
For a random variable \(Y \in \mathbb{R}\), let \(\mathbb{E}(Y) = \mu, \text{Var}(Y) = \sigma^2 \cdot V(\mu)\). 
</p>

<p>
Define the function: \(h(Y;\mu) = \frac{Y - \mu}{\sigma^2 V(\mu)}\).
</p>

<p>
Then
</p>

\begin{equation*}
\mathbb{E}(h(Y ; \mu)) = 0 \\
\text{Var}(h(Y ; \mu)) = -\mathbb{E}\left( \frac{\partial h(Y;\mu)}{\partial \mu} \right) = \frac{1}{\sigma^2 V(\mu)}
\end{equation*}

<p>
The log quasi-likelihood function:
</p>

\begin{equation*}
Q(Y ;\mu) = \int_y^\mu \frac{y - t}{\sigma^2 V(t)} dt.
\end{equation*}
</div>
</div>

<div id="outline-container-org4bb05a5" class="outline-4">
<h4 id="org4bb05a5"><span class="done DONE">DONE</span> Maximum quasi-likelihood estimation</h4>
<div class="outline-text-4" id="text-org4bb05a5">
<p>
Back to our regression setting \(\{(x_i, y_i)\}_{i = 1}^n\).
</p>

<p>
The log quasi-likelihood function is:
</p>

\begin{equation*}
L(\beta) = \sum_{i = 1}^n Q(Y_i ; \mu_i), \text{ where } g(\mu_i) = X_i^{\prime}\beta
\end{equation*}

<p>
The quasi-likelihood estimator \(\hat{\beta}\) satisfies 
</p>

\begin{equation*}
\sum_{i = 1}^n \frac{(Y_i - \hat{\mu}_i)X_i^{\prime}}{V(\hat{\mu}_i)g^{\prime}(\hat{\mu}_i)} = 0
\end{equation*}

<p>
where \(g(\hat{\mu}_i) = X_i^{\prime}\hat{\beta})\).
</p>

<p>
Let
</p>

\begin{equation*}
W = 
\begin{pmatrix}
\frac{1}{V(\mu_1)g^{\prime}(\hat{\mu}_1)^2} & &  \\
& \ddots &  \\
& & \frac{1}{V(\mu_n)g^{\prime}(\hat{\mu}_n)^2}
\end{pmatrix}, 
\quad \Delta =
\begin{pmatrix}
g^{\prime}(\mu_1)^2 & &  \\
& \ddots &  \\
& & g^{\prime}(\mu_n)^2
\end{pmatrix}, \\
Y = 
\begin{pmatrix}
Y_1 \\
\vdots \\
Y_n
\end{pmatrix}, \quad 
\mu = 
\begin{pmatrix}
\mu_1 \\
\vdots \\
\mu_n
\end{pmatrix}, \quad 
X = 
\begin{pmatrix}
X_1 \\
\vdots \\
X_n
\end{pmatrix}
\end{equation*}

<p>
Under regularity conditions, \(\hat{\beta} \approx N(\beta, \sigma^2 (X^{\prime}WX)^{-1})\).
</p>

<p>
We compute the quasi-likelihood estimator using the Fisher scoring algorithm as:
</p>

\begin{align*}
\beta^{t + 1} &= \beta^t + (X^{\prime}WX)^{-1}X^{\prime}W\Delta(Y - \mu) \\
&= (X^{\prime}WX)^{-1}X^{\prime}W(X\beta^t + \Delta(Y - \mu))
\end{align*}

<p>
where \(W, \Delta, \mu\) all depend on \(\beta^t\). 
</p>

<p>
Estimation of \(\sigma^2\):
</p>

\begin{equation*}
\hat{\sigma}^2 = \frac{1}{n-p} \sum_{i = 1}^n \frac{(Y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)},
\end{equation*}

<p>
where \(g(\hat{\mu}_i) = X_i^{\prime}\hat{\beta}), \hat{\beta} \in \mathbb{R}^p\).
</p>

<p>
See more about Quasi-likelihood in Ch. 9 of McCullagh and Nelder. 
</p>
</div>
</div>
</div>

<div id="outline-container-orgab57e5a" class="outline-3">
<h3 id="orgab57e5a"><span class="section-number-3">3.7</span> <span class="done DONE">DONE</span> Generalized linear mixed models <code>[10/10]</code></h3>
<div class="outline-text-3" id="text-3-7">
</div>
<div id="outline-container-org02679b9" class="outline-4">
<h4 id="org02679b9"><span class="done DONE">DONE</span> General setup</h4>
<div class="outline-text-4" id="text-org02679b9">
<p>
\(Y_i | b \sim \mathbb{P}(Y_i | b) = \exp \left[ \frac{Y_i \theta_i - b(\theta_i)}{a(\phi)} + c(\phi, Y_i) \right], \quad i = 1, \ldots, n\).
</p>

<p>
\(\mu_i = b^{\prime}(\theta_i) = \mathbb{E}(Y_i | b)\).
</p>

<p>
\(g(\mu_i) = X_i^{\prime}\beta + Z_i^{\prime} b\), \(g\) is a link function. 
</p>

<p>
\(b \sim f_\gamma(b)\), \(\gamma\) is the parameter in the random effect distribution. 
</p>

<p>
This formulation is for one group/cluster data. 
</p>

<p>
Like in LMM, \(b\) induces dependency among \(\{ Y_i \}_{i = 1}^n\) (data within group).
</p>

<p>
GLMM extends LMM to deal with more types of data (such as binary or integers). 
</p>
</div>
</div>
<div id="outline-container-org1450002" class="outline-4">
<h4 id="org1450002"><span class="done DONE">DONE</span> Mean</h4>
<div class="outline-text-4" id="text-org1450002">
\begin{align*}
\mathbb{E}(Y_i) &= \mathbb{E}[\mathbb{E}(Y_i | b)] \\
&= \mathbb{E}(\mu_i) \\
&= \mathbb{E}[g^{-1}(X_i^{\prime}\beta + Z_i^{\prime}b)]
\end{align*}

<p>
which can't be further simplified in general since \(g^{-1}(\cdot)\) is nonlinear. 
</p>
</div>
</div>

<div id="outline-container-orgfef6b7d" class="outline-4">
<h4 id="orgfef6b7d"><span class="done DONE">DONE</span> Variance</h4>
<div class="outline-text-4" id="text-orgfef6b7d">
<p>
\(\text{Var}(Y_i | b) = a(\phi) + b^{\prime\prime}(\theta_i)\), with \(b^{\prime\prime}(\theta_i) = V(\mu_i)\). 
</p>

\begin{align*}
\text{Var}(Y_i) &= \mathbb{E}[\text{Var}(Y_i | b)] + \text{Var}[\mathbb{E}(Y_i | b)] \\
&= \mathbb{E}[a(\phi)V(g^{-1}(X_i^{\prime}\beta + Z_i^{\prime}b))] + \text{Var}[g^{-1}(X_i^{\prime}\beta + Z_i^{\prime}b)]
\end{align*}
</div>
</div>

<div id="outline-container-org5d2fc49" class="outline-4">
<h4 id="org5d2fc49"><span class="done DONE">DONE</span> Covariance</h4>
<div class="outline-text-4" id="text-org5d2fc49">
\begin{align*}
\text{Cov}(Y_i, Y_j) &= \text{Cov}(\mathbb{E}(Y_i | b), \mathbb{E}(Y_j | b)) + \mathbb{E}(\text{Cov}((Y_i, Y_j | b)) \\
&= \text{Cov}(g^{-1}(X_i^{\prime}\beta + Z_i^{\prime}b), g^{-1}(X_j^{\prime}\beta + Z_j^{\prime}b)) + 0
\end{align*}
</div>
</div>

<div id="outline-container-org1b4c153" class="outline-4">
<h4 id="org1b4c153"><span class="done DONE">DONE</span> Likelihood function</h4>
<div class="outline-text-4" id="text-org1b4c153">
<p>
In many situations, there is no closed form for the likelihood function. 
</p>

\begin{equation*}
L = \int \exp \left[ \sum_{i = 1}^n \left[ \frac{Y_i \theta_i - b(\theta_i)}{a(\phi)} + c(\phi, Y_i) \right] \right] \cdot f_\gamma(b) db
\end{equation*}

<p>
This is a form of "\(k\) -dimensional integration". 
</p>
</div>
</div>

<div id="outline-container-orgfe69f55" class="outline-4">
<h4 id="orgfe69f55"><span class="done DONE">DONE</span> log-likelihood function</h4>
<div class="outline-text-4" id="text-orgfe69f55">
<p>
Does not have closed form in general. 
</p>
</div>
</div>
<div id="outline-container-org0565ec1" class="outline-4">
<h4 id="org0565ec1"><span class="done DONE">DONE</span> Gauss-hermite quadrecture</h4>
<div class="outline-text-4" id="text-org0565ec1">
<p>
Used to evalue an integral of the form \(\int_{-\infty}^\infty h(x)e^{-x^2} dx\). 
</p>

<p>
We have 
</p>

\begin{equation*}
\int_{-\infty}^\infty h(x)e^{-x^2} dx \approx \sum_{k = 1}^m h(x_k) w_k
\end{equation*}

<p>
where \(x_k\) are evolution points, \(w_k\) are weights, and \(h(x) = \sum_{j = 0}^n a_j x^j\) is a given polynomial. We pick \(n\) to be \(2m - 1\) to have enough equations to solve for all \(x_k\) and \(w_k\). We have software to give evaluation points and weights for given \(m\). 
</p>
</div>
</div>

<div id="outline-container-org66e106f" class="outline-4">
<h4 id="org66e106f"><span class="done DONE">DONE</span> EM algorithm for GLMM</h4>
<div class="outline-text-4" id="text-org66e106f">
<p>
<span class="underline">Step 1</span>
</p>

<p>
Treat \(b\) as latent variable (missing data).
</p>

<p>
\(\begin{pmatrix} Y \\ b \end{pmatrix}\) is the complete data. 
</p>

<p>
<span class="underline">Step 2</span>
</p>

<p>
Need log-likelihood of complete data. 
</p>

\begin{align*}
\log \mathbb{P}(Y, b) &= \log \mathbb{P}(Y | b) \mathbb{P}(b) \\
&= \sum_{i = 1}^n \left[ \frac{Y_i \theta_i - b(\theta_i)}{a(\phi)} + c(\phi, Y_i) \right] + \log f_\gamma(b) \\
&= \log \mathbb{P}(Y, b ; \beta, \phi, \gamma)
\end{align*}

<p>
<span class="underline">Step 3</span>
</p>

<p>
E-step; conditional expectation of log-likelihood of complete data with respect to \(b|Y\). 
</p>

\begin{align*}
(\beta^{t + 1}, \phi^{t+1}) &= \arg \max_{\beta, \phi} \mathbb{E}_b \left[ \sum_{i = 1}^n \left( \frac{Y_i \theta_i - b(\theta_i)}{a(\phi)} + c(\phi, Y_i) \right) | Y \right] \text{ under } \beta = \beta^t, \phi = \phi^t \\
\gamma^{t + 1} &= \arg \max_\gamma \mathbb{E}_b[\log f_\gamma (b) | Y ] \text{ under } \gamma = \gamma^t
\end{align*}

<p>
\(\mathbb{E}_b[\cdot|Y]\) is taken under the value \((\beta^t, \phi^t, \gamma^t)\). This is gaussian under Gaussian LMM, but this is not true in general for GLMM. It's hard to compute. 
</p>

\begin{equation*}
\mathbb{P}(b|Y) = \frac{\mathbb{P}(Y|b)\mathbb{P}(b)}{\mathbb{P}(Y)}
\end{equation*}

<p>
\(\mathbb{P}(Y)\) is not readily available, use MCMC. 
</p>
</div>
</div>

<div id="outline-container-orgd16aa19" class="outline-4">
<h4 id="orgd16aa19"><span class="done DONE">DONE</span> Markov Chain Monte Carlo algorithm</h4>
<div class="outline-text-4" id="text-orgd16aa19">
<p>
<span class="underline">Markov Chain</span>: a sequence of random vectors in \(\mathbb{R}^k :X_1, X_2, X_3, \ldots\) form a (time homogeneous) Markov Chain if
</p>

\begin{equation*}
\mathbb{P}(X_{n + 1} = x_{n+1} | X_1 = x_1, \ldots, X_n = x_n) = \mathbb{P}(X_{n + 1} = x_{n+1} | X_n = x_n) = Q(x_{n + 1} ; x_n) \text{ "transition kernel"}
\end{equation*}

<p>
for all \(n \geq 1\) and all \(x_1, \ldots, x_n\) values. 
</p>

<p>
"Conditional on the present, the future and the past are independent."
</p>

<p>
<span class="underline">Stationary Distribution</span>: Let \(\pi_n(\cdot)\) be the distribution for \(X_n\). 
</p>

\begin{align*}
\pi_{n+1}(a) = \mathbb{P}(X_{n + 1} = a) &= \int \mathbb{P}(X_{n+1} = a | X_n = y) \mathbb{P}(X_n = y)dy \\
&= \int Q(a ;y) \pi_n(y) dy
\end{align*}

<p>
\(\pi(\cdot)\) is called a stationary distribution if and only if \(\pi(a) = \int Q(a;y)\pi(y)dy\) for all \(y\). 
</p>

<p>
"If \(X_n\) has distribution \(\pi\), then \(X_{n + 1}\) will have distribution \(\pi\)."
</p>

<p>
Under regularity conditions on the Markov Chain, it holds that:
</p>

\begin{equation*}
\pi_n(\cdot) \rightarrow \pi(\cdot) \text{ as } n \rightarrow \infty
\end{equation*}

<p>
regardless of the initial distribution \(\pi_1(\cdot)\). 
</p>

<p>
This follows from "ergodic theory", which states that for a function \(f: \mathbb{R}^k \rightarrow \mathbb{R}\), \(\frac{1}{n} \sum_{i = 1}^n f(x_i) \rightarrow \int f(x)\pi(x) dx = \mathbb{E}(f(x))\) as \(n \rightarrow \infty\), where \(X \sim \pi(\cdot)\).
</p>
</div>
</div>

<div id="outline-container-org4df1829" class="outline-4">
<h4 id="org4df1829"><span class="done DONE">DONE</span> Metropolis-Hastings algorithm</h4>
<div class="outline-text-4" id="text-org4df1829">
<p>
We aim to approximate \(\mathbb{E}_b[h(b) | Y] = \int h(b) \mathbb{P}(b|Y)db\), where \(\mathbb{P}(b|Y)\) is the conditional density of \(b|Y\).
</p>

<p>
We construct a Markov Chain with stationary distribution \(\mathbb{P}(b|Y)\), with samples \(b_1, b_2, \ldots\). Then
</p>

\begin{equation*}
\frac{1}{n} \sum_{i = 1}^n h(b_i) \rightarrow \mathbb{E}[h(b) | Y]
\end{equation*}

<p>
<b><span class="underline">Algorithm</span></b>
</p>

<p>
<span class="underline">Step 1</span> Initialization: choose an arbitrary point \(b_1\) as the first sample.
</p>

<p>
<span class="underline">Step 2</span> for each iteration \(t\),
</p>

<p>
generate a candidate \(\tilde{b}\) from the proposal distribution \(g(\cdot | b_t)\)
</p>

<p>
calculate the acceptance ratio 
</p>
\begin{equation*} 
\alpha = \min \left\{1, \frac{\mathbb{P}(\tilde{b}|Y)g(b_t | \tilde{b})}{\mathbb{P}(b_t|Y)g(\tilde{b} | b_t)} \right\} 
\end{equation*}

<p>
generate a uniform random number from \([0, 1]\), denoted by \(u\). 
</p>

<p>
if \(u \leq \alpha\), accept the candidate: \(b_{t+1} = \tilde{b}\),
</p>

<p>
if \(u > \alpha\), reject the candidate: \(b_{t+1} = b_t\),
</p>
</div>
</div>
</div>

<div id="outline-container-org204d288" class="outline-3">
<h3 id="org204d288"><span class="section-number-3">3.8</span> <span class="done DONE">DONE</span> Generalized estimation equations <code>[4/4]</code></h3>
<div class="outline-text-3" id="text-3-8">
</div>
<div id="outline-container-orgf00109a" class="outline-4">
<h4 id="orgf00109a"><span class="done DONE">DONE</span> Estimating functions</h4>
<div class="outline-text-4" id="text-orgf00109a">
<p>
\(Y \in \mathbb{R}^n, \theta \in \mathbb{R}^k, g(Y, \theta) \in \mathbb{R}^k\) is <span class="underline">estimating function</span>. 
</p>

<p>
If \(\mathbb{E}_\theta g(Y, \theta) = 0\) for all \(\theta \in \Theta\), solve \(g(Y, \theta) = 0\) for \(\theta\) to obtain \(\hat{\theta}\). 
</p>

<p>
\(g(Y, \theta) = 0\) is the _estimating equation.
</p>

<p>
Let \(\theta^*\) be the true parameter value that generates the data. 
</p>

<p>
For example, when \(g(Y, \theta)\) is score function (derivative of log-likelihood), we have \(\mathbb{E}_{\theta^*}(g(Y, \theta)) = 0\) when \(\theta = \theta^*\).
</p>
</div>
</div>

<div id="outline-container-org2c0e16f" class="outline-4">
<h4 id="org2c0e16f"><span class="done DONE">DONE</span> Class of linear estimating functions</h4>
<div class="outline-text-4" id="text-org2c0e16f">
<p>
Back to the regression setting, \(\mu = (\mu_1, \ldots, \mu_n)^{\prime}\).
</p>

<p>
\(\mathbb{E}(Y) = \mu(X, \theta), \text{Cov}(Y) = V, Y \in \mathbb{R}^n, \theta \in \mathbb{R}^k\).
</p>

<p>
Consider a class of linear estimating functions: \(g(Y, \theta) = H(X, \theta) (Y - \mu(X, \theta))\).
</p>

<p>
\(H(X, \theta) \in \mathbb{R}^{k \times n}\) depends on \(X\) and \(\theta\) only, not \(Y\). 
</p>
</div>
</div>

<div id="outline-container-org9997c88" class="outline-4">
<h4 id="org9997c88"><span class="done DONE">DONE</span> Optimal linear estimating equation</h4>
<div class="outline-text-4" id="text-org9997c88">
<p>
The choice \(H(X, \theta) = \dot{\mu}^{\prime} V^{-1}\) gives the "best" asymtpotic covariance matrix for the \(\hat{\theta}\) from the estimating equation, where
</p>

\begin{equation*}
\dot{\mu} =
\begin{pmatrix}
\frac{\partial \mu_1}{\partial \theta} \\
\vdots \\
\frac{\partial \mu_n}{\partial \theta}
\end{pmatrix} \in \mathbb{R}^{n \times k} \text{ (Jacobian Matrix)}
\end{equation*}

<p>
Quasi-likelihood solution is optimal linear estimating equation solution. 
</p>
</div>
</div>

<div id="outline-container-org9fbf39e" class="outline-4">
<h4 id="org9fbf39e"><span class="done DONE">DONE</span> Generalized estimating equation</h4>
<div class="outline-text-4" id="text-org9fbf39e">
<p>
These methods capture some of the benefits of quasi-likelihood estimation in the context of correlated data models, and are robust in the presence of misspecification of the variance-covariance structure of the data. These estimates are often easier to compute than ML estimates. 
</p>

<p>
For clustered/grouped data: \(Y_i = (Y_{i1}, \ldots, Y_{in_i})^{\prime} \in \mathbb{R}^{n_i}, X_i = (X_{i1}, \ldots, X_{in_i})^{\prime} \in \mathbb{R}^{n_i \times m}, i = 1, 2, \ldots, N\).
</p>

<p>
Assume the \(Y_i\) are independent, with \(\mathbb{E}(Y_i) = \mu_i(X_i, \theta), \theta \in \mathbb{R}^k, \text{Cov}(Y_i) = V_i \in \mathbb{R}^{n_i \times n_i}\). 
</p>

<p>
Use theory from before of optimal linear estimating equations
</p>

\begin{equation*}
Y = 
\begin{pmatrix}
Y_1 \\
\vdots \\
Y_N
\end{pmatrix}, 
\mu = 
\begin{pmatrix}
\mu_1 \\
\vdots \\
\mu_N
\end{pmatrix},
V = 
\begin{pmatrix}
V_1 & \cdots & 0 \\
0 & \ddots & 0\\
0 & \cdots & V_N
\end{pmatrix}  
\end{equation*}

<p>
The optimal linear estimating equation:
</p>

\begin{equation*}
\sum_{i = 1}^N \dot{\mu}_i V_i^{-1} (Y_i - \mu_i) = 0 \\

\dot{\mu}_i =
\begin{pmatrix}
\frac{\partial \mu_{i1}}{\partial \theta} \\
\vdots \\
\frac{\partial \mu_{in_i}}{\partial \theta}
\end{pmatrix} \in \mathbb{R}^{n_i \times k}
\end{equation*}

<p>
The true \(V_i\) is typically unknown, so we usually estimate it or use a "working" covariance matrix. 
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org4e43c95" class="outline-2">
<h2 id="org4e43c95"><span class="section-number-2">4</span> STT 872 <code>[100%]</code></h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org9ccd2fe" class="outline-3">
<h3 id="org9ccd2fe"><span class="section-number-3">4.1</span> <span class="done DONE">DONE</span> Preparations <code>[9/9]</code></h3>
<div class="outline-text-3" id="text-4-1">
</div>
<div id="outline-container-org44773d1" class="outline-4">
<h4 id="org44773d1"><span class="done DONE">DONE</span> Measure Theory <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-org44773d1">
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.3</dt><dd>Keener</dd>
</dl>
<p>
A collection \(\mathcal{A}\) of subsets of a set \(\mathcal{X}\) is a \(\sigma\) -field (or \(\sigma\) -algebra) if
</p>

<ol class="org-ol">
<li>\(\mathcal{X} \in \mathcal{A}\) and \(\emptyset \in \mathcal{A}\).</li>
<li>If \(A \in \mathcal{A}\), then \(A^c = \mathcal{X} - A \in \mathcal{A}\).</li>
<li>If \(A_1, A_2, \ldots \in \mathcal{A}\), then \(\bigcup_{i = 1}^\infty A_i \in \mathcal{A}\)</li>
</ol>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.4</dt><dd>Keener</dd>
</dl>
<p>
A function \(\mu\) on a \(\sigma\) -field \(\mathcal{A}\) of \(\mathcal{X}\) is a <span class="underline">measure</span> if
</p>

<ol class="org-ol">
<li>For every \(A \in \mathcal{A}, 0 \leq \mu(A) \leq \infty\); that is, \(\mu : \mathcal{A} \rightarrow [0, \infty]\).</li>
<li>If \(A_1, A_2, \ldots\) are disjoint elements of \(\mathcal{A}\), then</li>
</ol>

\begin{equation*}
\mu \left(\bigcup_{i = 1}^\infty A_i \right) = \sum_{i = 1}^\infty \mu(A_i).
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.2.1</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.2.2</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
<div id="outline-container-orgd3fcf36" class="outline-4">
<h4 id="orgd3fcf36"><span class="done DONE">DONE</span> Integration <code>[8/8]</code></h4>
<div class="outline-text-4" id="text-orgd3fcf36">
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.7</dt><dd>Keener</dd>
</dl>
<p>
If \((\mathcal{X}, \mathcal{A})\) is a measurable space and \(f\) is a real-valued function on \(\mathcal{X}\), then \(f\) is measurable if
</p>

\begin{equation*}
f^{-1}(B) \triangleq \{x \in \mathcal{X} : f(x) \in B \} \in \mathcal{A}
\end{equation*}

<p>
for every Borel set \(B\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.8</dt><dd>Keener</dd>
</dl>
<p>
We can take limit of non-negative simple functions to get any non-negative measurable function.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.2.3</dt><dd>Lehmann and Casella</dd>
</dl>

<div style="margin-bottom: 150px;"></div>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.2.5</dt><dd>Lehmann and Casella (Dominated Convergence Theorem)</dd>
</dl>
<p>
If \(f\) is the limit of measurable functions \(f_n\), and if a function \(g(x) \geq |f_n(x)|\) for all \(x\), then \(f\) and \(f_n\) are integrable and the integral of \(f\) is the limit of the integrals of \(f_n\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 1.2.6</dt><dd>Lehmann and Casella (Fatou's Lemma)</dd>
</dl>
<p>
Cannot pull limsup/liminf out of integral of sequence of non-negative functions, get \(\geq\) or \(\leq\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Section 1.4</dt><dd>Keener</dd>
</dl>
<p>
Null sets have measure zero.
</p>

<p>
A statement holding <i>almost everywhere</i> means it holds for all sets minus null sets.  
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.9</dt><dd>Keener (Absolue continuous)</dd>
</dl>
<p>
Let \(P\) and \(\mu\) be measures on a \(\sigma\) -field \(\mathcal{A}\) of \(\mathcal{X}\). Then \(P\) is called <span class="underline">absolutely continuous</span> with respect to \(\mu\), written \(P \ll \mu\) if \(P(A) = 0\) whenever \(\mu(A) = 0\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.10</dt><dd>Keener (<a href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem">Radon-Nikodym Theorem</a>)</dd>
</dl>
<p>
If a finite measure \(P\) is absolutely continuous with respect to a \(\sigma\) -finite measure \(\mu\), then there exists a nonnegative measurable function \(f\) such that 
</p>

\begin{equation*}
P(A) = \int_A f d\mu \triangleq \int f 1_A d\mu.
\end{equation*}

<p>
The function \(f\) in this theorem is called the Radon-Nikodym derivative of \(P\) with respect to \(\mu\), or the <i>density</i> of \(P\) with respect to \(\mu\), denoted 
</p>

\begin{equation*}
f = \frac{dP}{d\mu}.
\end{equation*}
</div>
</div>

<div id="outline-container-org226f807" class="outline-4">
<h4 id="org226f807"><span class="done DONE">DONE</span> Probability Spaces <code>[11/11]</code></h4>
<div class="outline-text-4" id="text-org226f807">
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.11</dt><dd>Keener</dd>
</dl>

\begin{equation*}
F_X(x) = P(X \leq x) = P_X((- \infty, x]) = \int_{- \infty}^x p(u) du
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.12 </dt><dd>Keener</dd>
</dl>

\begin{equation*}
P(X \in A) = P_X(A) = \int_A p d\mu = \sum_{x \in \mathcal{X}_0} p(x) 1_A(x)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Section 1.7</dt><dd>Keener</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Statistics</dt><dd>p. 16 Keener</dd>
</dl>
<p>
<span class="underline">Smoothing identity</span>
</p>

\begin{equation*}
Ef(X, Y) = EE[f(X, Y) | X]
\end{equation*}

<p>
In particular, when \(f(X, Y) = Y\), then \(EY = EE(Y|X)\)
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.13</dt><dd>Keener (Expectation, Variance, Covariance)</dd>
</dl>

\begin{equation*}
Ef(X) = \int f(x)p(x)dx \\
Ef(X) = \sum_{x \in \mathcal{X}_0} f(x)p(x) \\
E(aX + bY) = aE(X) + bE(Y) \\
\text{Var}(X) = E(X - EX)^2 \\
\text{Cov}(X, Y) = E(X - EX)(Y - EY)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Section 1.9 intro</dt><dd>Keener</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.15</dt><dd>Keener</dd>
</dl>
<p>
Product measure of Lebesgue measures is Lebesgue measure.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.16</dt><dd>Keener</dd>
</dl>
<p>
Product measure of counting measures is counting measure. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.17</dt><dd>Keener (Fubini's Theorem)</dd>
</dl>
<p>
Integration with respect to product measure can be taken in either order. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.18</dt><dd>Keener (Independence)</dd>
</dl>

\begin{equation*}
P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Proposition 1.19</dt><dd>Keener</dd>
</dl>
<p>
Measurable functions taken on independent random vectors are still independent. 
</p>
</div>
</div>
<div id="outline-container-org5829b89" class="outline-4">
<h4 id="org5829b89"><span class="done DONE">DONE</span> Group families <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-org5829b89">
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.4.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Can add a constant \(a\) to a random variable \(U\) and get another random variable with \(P(X \leq x) = F(x - a)\), where \(F\) is the distribution of \(U\). The totality of these distributions are said to constitute a <i>location family</i>.
</p>

<p>
A <i>scale family</i> is same thing but multiply a random variable \(U\) by a constant \(b\) and get \(P(X \leq x) = F(x/b)\).
</p>

<p>
Combine both to get <i>location-scale family</i>, where \(P(X \leq x) = F(\frac{x - a}{b})\).
</p>

<p>
Location-scale families include <b>normal</b>, <b>double exponential</b>, <b>cauchy</b>, <b>logistic</b>, <b>exponential</b>, and <b>uniform</b>. See p. 18 Table 1.4.1 in Lehmann and Casella.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.4.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
A <i>group</i> must satisfy
</p>

<ol class="org-ol">
<li>you can have multiplication of any two elements (product, \(ab\))</li>
<li>\((ab)c = a(bc)\) (associative law)</li>
<li>\(ea = ae = a\), here \(e\) is called <i>identity</i> and it is in the group</li>
<li>\(aa^{-1} = a^{-1}a = e\), where \(a^{-1}\) is called <i>inverse</i></li>
</ol>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 1.4.3</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
A <i>transformation group</i> is closed under both composition and inversion. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.4.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Can extend group and scale families to vectors of random variables. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.4.5</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Multivariate normal distribution can be thought of as location-scale family for vector of standard normals. 
</p>
</div>
</div>
<div id="outline-container-orgc70351a" class="outline-4">
<h4 id="orgc70351a"><span class="done DONE">DONE</span> Exponential families <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-orgc70351a">
<dl class="org-dl">
<dt class="on">&#x2611; Section 2.1</dt><dd>intro Keener</dd>
</dl>
<p>
Exponential family in canonical form:
</p>

\begin{equation*}
p_\eta(x) = \text{exp}\left[\sum_{i = 1}^s \eta_i T_i(x) - A(\eta) \right] h(x), \\
x \in \mathcal{R}^n \\
A(\eta) < \infty\end{equation*}

<p>
\(\eta\) is called <i>canonical parameter</i>.
</p>

<p>
Exponential family in alternative form:
</p>

\begin{equation*}
p_\theta(x) = \text{exp}\left[\sum_{i = 1}^s \eta_i(\theta) T_i(x) - B(\theta) \right] h(x), \\
x \in \mathcal{R}^n
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 2.1</dt><dd>Keener</dd>
</dl>

<div style="margin-bottom: 150px;"></div>

<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3</dt><dd>Keener</dd>
</dl>
<p>
Normal distribution is exponential family.
</p>

<p>
Multivariate normal is exponential family. 
</p>

<p>
In fact, joint density of any exponential family gives exponential family of specific form.
</p>

\begin{equation*}
\text{exp}\left[\sum_{i = 1}^s \eta_i(\theta) (\sum_{j = 1}^n T_i(x_j) - nB(\theta) \right] \prod_{j = 1}^n h(x_j)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.4</dt><dd>Keener</dd>
</dl>
<p>
Exponential families are guaranteed to have nice-playing integrals for computing moments and expectations
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.5.8</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This theorem gives us a shortcut for calculating expected values in exponential families. 
</p>
</div>
</div>
<div id="outline-container-org338a73f" class="outline-4">
<h4 id="org338a73f"><span class="done DONE">DONE</span> Moment and cumulant generating functions <code>[7/7]</code></h4>
<div class="outline-text-4" id="text-org338a73f">
<p>
Moment generating function for exponential family distribution is
</p>

\begin{equation*}
M_T(u) = \frac{e^{A(\eta + u)}}{e^{A(\eta})} = Ee^{uT}
\end{equation*}

<p>
To get \(k^\text{th}\) central moment, take \(k^\text{th}\) derivative of MGF and evaluate at \(u = 0\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Section 2.4 intro</dt><dd>Keener</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Expectations of powers of \(T_1, T_2, \ldots, T_s\),</dt><dd>p. 28 Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 2.7</dt><dd>Keener</dd>
</dl>
<p>
The MGF determines the distribution of \(X\), at least if it is finite in some open interval.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.8</dt><dd>Keener</dd>
</dl>
<p>
MGF has continous derivatives of all orders at the origin, which allows us to calculate <i>cumulants</i>.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 2.9</dt><dd>Keener</dd>
</dl>
<p>
For independent \(X\) and \(Y\), if \(X\) and \(X\) are both positive, or if \(E|X|\) and \(E|Y|\) are both finite, then 
</p>

\begin{equation*}
EXY = EX \times EY
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.5.11</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Binomial Moments
</p>

<div style="margin-bottom: 150px;"></div>

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.5.14</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Gamma moments
</p>

<div style="margin-bottom: 150px;"></div>
</div>
</div>

<div id="outline-container-orgf7b21bc" class="outline-4">
<h4 id="orgf7b21bc">Models, Estimators, and Risk Functions</h4>
<div class="outline-text-4" id="text-orgf7b21bc">
<p>
This comes from Section 3.1 in Keener.
</p>

<p>
Inferential statistics is concerned with learning about an unknown parameter \(\theta\) from data \(X\), where \(X\) follows a distribution \(P_\theta\). 
</p>

\begin{equation*}
X \sim P_\theta
\end{equation*}

<p>
A statistic is a function of the data X. In estimation, the goal is to find a statistic \(\delta\) so that \(\delta(X)\) is close to \(g(\theta)\). Here, \(\delta(X)\) is called an estimator of \(g(\theta)\). We could consider the case where \(g(\theta) = \theta\). 
</p>

<p>
We need a criteria to judge the performance of different estimators. We use decision theory, which starts with a loss function \(L\) which is chosen so that \(L(\theta, d)\) is the loss associated with estimating \(g(\theta)\) by a value \(d\). We assume \(L(\theta, g(\theta)) = 0\), and \(L(\theta, d) \geq 0\) for all \(\theta\) and \(d\). Since \(X\) is random, the loss is random and may be large if we are unlucky, even if \(\delta\) is very good. So instead we judge by average loss, or <span class="underline">risk function</span>. 
</p>

\begin{equation*}
R(\theta, \delta) = E_\theta L(\theta, \delta(X)).
\end{equation*}

<p>
We take expectation when \(X \sim P_\theta\). 
</p>

<p>
Sometimes the risk functions cross for different estimators, so it is not clear which estimator is better. 
</p>
</div>
</div>

<div id="outline-container-org5c02c23" class="outline-4">
<h4 id="org5c02c23"><span class="done DONE">DONE</span> Sufficient Statistics <code>[22/22]</code></h4>
<div class="outline-text-4" id="text-org5c02c23">
<p>
Basically to find a sufficient statistic, calucalte the joint density and use the facotization criterion. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Section 1.10</dt><dd>Keener</dd>
</dl>
<p>
Conditional probability in discrete case:
</p>

\begin{equation*}
P(Y \in B | X = x) = \frac{P(Y \in B, X = x)}{P(X = x)}
\end{equation*}

<p>
<i>Smoothing identity</i>
</p>

\begin{equation*}
Ef(X, Y) = EE \left[ f(X, Y) | X \right]
\end{equation*}

<p>
When \(f(X, Y) = Y\), we get
</p>

\begin{equation*}
EY = EE(Y|X)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Section 3.2 intro</dt><dd>Keener</dd>
</dl>
<p>
A <i>sufficient statistic</i> \(T\) provides just as much information about \(\theta\) as the data \(X_1, \ldots, X_n\), as we could construct fake data \(\tilde{X}_1, \ldots, \tilde{X}_n\) equivalent to \(X_1, \ldots, X_n\) using any convenient variable \(U\) that is uniformly distributed on \((0, 1)\).
</p>

<p>
<b>Heuristic Definition</b>. We say \(T\) is a sufficient statsitic if the statistician who knows the value of T can do just as good a job of estimating the unkonw parameter \(\theta\) as the statistician who knows the entire random sample. 
</p>

<p>
<b>Mathematical Definition Explanation</b>. Let \(T = r(X_1, \ldots, X_n)\) be a sufficient statistic. Statistician A knows the entire random sample \(X_1, \ldots, X_n\), but statistician B only knows the value of \(T\), call it \(t\). Since the conditional distribution of \(X_1, \ldots, X_n\) given \(\theta\) and \(T\) does not depend on \(\theta\), statistician B knows this conditional distribution. So they can use their computer to generate a random sample \(X^\prime_1, \ldots, X^\prime_n\) which has this conditional distribution. But then this random sample has the same distribution as a random sample drawn from the popultaion (with its unknown value of \(\theta\)). So statistician B can use their random samnple \(X^\prime_1, \ldots, X^\prime_n\), and they will (on average) do as well as statistician A. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.2</dt><dd>Keener</dd>
</dl>
<p>
\(X\) has distribution from a family \(\mathcal{P} = \{ P_\theta : \theta \in \Omega \}\).
</p>

<p>
\(T = T(X)\) is a sufficient statistic for \(\mathcal{P}\) if for every \(t\) and \(\theta\), the conditional distribution of \(X\) under \(P_\theta\) given \(T = t\) does not depend on \(\theta\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.3</dt><dd>Keener</dd>
</dl>
<p>
Can have a randomized estimator based on sufficient statistic \(T\) that has the same risk function as any estimator \(\delta(X)\) of \(g(\theta)\). 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.6.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
For sufficient statistic, calculate joint distribution, condition on statistic \(T(X)\), then show it is independent of parameter of interest. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.6</dt><dd>Keener (Factorization Theorem)</dd>
</dl>

<p>
The definition of sufficient statistic is less useful for actually finding one, or for truing to determine whether a specific statistic is sufficient. Instead, we use Factorization Theorem for cases where the distributions in the family are specified by densities. To do this, we simply look at the form of the densities. 
</p>

<p>
Write density as 
</p>

\begin{equation*}
p_\theta(x) = g_\theta(T(x))h(x) \\
g_\theta \geq 0 \\
h \geq 0
\end{equation*}

<p>
to show that \(T\) is a sufficient statistic.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.8</dt><dd>Keener</dd>
</dl>
<p>
When \(\{x : p_\theta(x) > 0\}\) depends on \(\theta\), care is needed to ensure that formulas for \(p_\theta\) used in the factorization theorem work for all \(x\). To accomplish this, indicator functions are often used. For example, in the case of \(X_1, \ldots, X_n \sim U(\theta, \theta + 1)\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.9</dt><dd>Keener (Minimal sufficient)</dd>
</dl>
<p>
From the factorization theorem, if \(T\) is a sufficient statistic for a familiy of distributions \(\mathcal{P}\), and if \(T = f(\tilde{T})\), the \(\tilde{T}\) is also sufficient.
</p>

<p>
A statistic \(T\) is <i>minimal sufficient</i> if it is sufficient and for every sufficient statistic \(\tilde{T}\), there exists a function \(f\) such that \(T = f(\tilde{T})\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.10</dt><dd>Keener</dd>
</dl>
<p>
In this example, we have a sample from $N(&theta;, 1), and we have the sum of the first half of the data and the sum of the second half of the data are together sufficient. However, they are not minimal sufficient. Minimal sufficient would be the full sum of all the data.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.11</dt><dd>Keener</dd>
</dl>
<p>
This shows that a statistic is minimal sufficient if there is a one-to-one relation between the statistic and the likelihood shape. 
</p>

<p>
Let \(\mathcal{P} = \{ P_\theta : \theta \in \Omega \}\) with densities \(p_\theta (x) = g_\theta(T(x))h(x)\). If \(p_\theta(x) \propto_\theta p_\theta(y)\) implies \(T(x) = T(y)\), then \(T\) is minimal sufficient. 
</p>

<p>
\(\propto_\theta\) means that the two expressions are proportional when viewed as functions of \(\theta\). So here it means that \(p_\theta(x) = c(x, y) p_\theta(y)\)
</p>

<p>
It basically says that the shape of the likelihood is minimal sufficient, and so a minimal sufficient "statistic" exists for dominated families. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.12</dt><dd>Keener</dd>
</dl>
<p>
By the factorization theorem, \(T\) is sufficient in an \(s\) -parameter exponential family with densities
</p>

\begin{equation*}
p_\theta(x) = e^{\eta(\theta) \cdot T(x) - B(\theta)} h(x).
\end{equation*}

<p>
And using theorem 3.11, \(T\) is also minimal sufficient if we assume \(p_\theta(x) \varpropto_\theta p_\theta (y)\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.13</dt><dd>Keener</dd>
</dl>
<p>
Order statistics are \(X_{(1)} \leq X_{(2)} \leq \ldots \leq X_{(n)}\). Get order statistics by listing \(X_1, \ldots X_n\) in increasing order. Order statistics are sufficient by factorization theorem. And if we assume \(p_\theta(x) \varpropto_\theta p_\theta (y)\), then they are minimal sufficient for common marginal density
</p>

\begin{equation*}
f_\theta(x) = \frac{1}{2} e^{- | x - \theta |}.
\end{equation*}


<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.14</dt><dd>Keener</dd>
</dl>
<p>
Completeness is a technical condition that strengthens sufficiency in a useful fashion. 
</p>

<p>
A statistic \(T\) is <i>complete</i> for a family \(\mathcal{P}\) if 
</p>

\begin{equation*}
E_\theta f(T) = c, \text{ for all } \theta
\end{equation*}

<p>
implies \(f(T) = c\). 
</p>

<p>
We typically take \(c = 0\) for convenience. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.16</dt><dd>Keener</dd>
</dl>
<p>
TO show completeness, get sufficient statistic \(T\), figure out it's distribution, calculate expectation of \(f(T)\) for generic \(f\) and set equal to \(0\). Show that \(f\) must be \(0\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.17</dt><dd>Keener</dd>
</dl>
<p>
If \(T\) is complete and sufficient, then \(T\) is minimal sufficient.
Being complete is the best thing you can do. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.18</dt><dd>Keener</dd>
</dl>
<p>
Full rank exponential family has two conditions. Needs not empty interior of \(\eta(\Omega)\) and \(T_1, \ldots, T_s\) do not satisfy a linear constraint of the form \(v \cdot T = c\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.19</dt><dd>Keener</dd>
</dl>
<p>
In an exponential family of full rank, \(T\) is complete (and is therefore also minimal). 
</p>

<p>
Recall, 
</p>

\begin{equation*}
p_\theta(x) = \exp\{\eta(\theta) \cdot T(x) - B(\theta) \}h(x), \theta \in \Omega
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.20</dt><dd>Keener</dd>
</dl>
<p>
A statistic \(V\) is called <i>ancillary</i> if its distribution does not depend on \(\theta\). So \(V\) by itself provides no information about \(\theta\).
</p>

<p>
For example, distances between order statistics are usually ancillary. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.21</dt><dd>Keener (Basu)</dd>
</dl>
<p>
If \(T\) is complete and \(V\) is ancillary, then \(T\) and \(V\) are independent under \(P_\theta\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.22</dt><dd>Keener</dd>
</dl>
<p>
Sample mean is complete for joint normals. Sample variance is ancillary for the mean parameter. So sample mean and sample variance are independent by Basu. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.6.25 (i)</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If you have a minimal sufficient statistic, but a function of it equals a constant and is not a constant function, then it is not complete. This is basically a way of generating a counterexample to show not complete. A statistic can therefore be minimal sufficient but not complete. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.6.26</dt><dd>Lehmann and Casella</dd>
</dl>

<div style="margin-bottom: 150px;"></div>
</div>
</div>

<div id="outline-container-org6ed6886" class="outline-4">
<h4 id="org6ed6886"><span class="done DONE">DONE</span> Convexity <code>[10/10]</code></h4>
<div class="outline-text-4" id="text-org6ed6886">
<p>
Examples of convex functions are
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Function</th>
<th scope="col" class="org-left">Interval</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(\vert x \vert\)</td>
<td class="org-left">\(-\infty < x < \infty\)</td>
</tr>

<tr>
<td class="org-left">\(x^2\)</td>
<td class="org-left">\(-\infty < x < \infty\)</td>
</tr>

<tr>
<td class="org-left">\(x^p, p > 1\)</td>
<td class="org-left">\(0 < x\)</td>
</tr>

<tr>
<td class="org-left">\(1/x^p, p > 0\)</td>
<td class="org-left">\(0 < x\)</td>
</tr>

<tr>
<td class="org-left">\(e^x\)</td>
<td class="org-left">\(-\infty < x < \infty\)</td>
</tr>

<tr>
<td class="org-left">\(- \log x\)</td>
<td class="org-left">\(0 < x < \infty\)</td>
</tr>
</tbody>
</table>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.23</dt><dd>Keener (convex function)</dd>
</dl>
<p>
For any two points \(x\) and \(y\), the straight line connecting the points \(f(x)\) and \(f(y)\) should be above the function \(f\) between \(x\) and \(y\). 
</p>

<p>
Convex functions are U-shaped. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.7.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
For convex functions, the derivative should be non-decreasing. If the derivative is increasing, then it is strictly convex. 
</p>

<p>
The second derivative of a convex function should be non-negative. It should be positive for a strictly convex function. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.24</dt><dd>Keener</dd>
</dl>
<p>
We can always find a "support line" under any point \(x\) such that the function is above the line but the line touches \(f\) at \(x\). 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.25</dt><dd>Keener (Jensen's Inequaltiy)</dd>
</dl>
<p>
For convex function \(f\) with \(EX\) finite, we have 
</p>

\begin{equation*}
f(EX) \leq Ef(X)
\end{equation*}

<p>
If \(f\) is strictly convex, the inequality is strict unless \(X\) is almost surely constant. 
</p>

<p>
Jensen's inequality also holds in higher dimensions, with \(X\) a random vector. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.27</dt><dd>Keener</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.7.7</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
KL distance between density functions \(f\) and \(g\) is
</p>

\begin{equation*}
E_f \left[ \log(f(X) / g(X)) \right] = \int \log \left[f(x)/g(x) \right] f(x) dx
\end{equation*}

<p>
KL distance is always \(\geq 0\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.28</dt><dd>Keener (Rao-Blackwell)</dd>
</dl>
<p>
Recall that is \(\delta(X)\) is an estimator of \(g(\theta)\), then the risk of \(\delta\) for a loss function \(L(\theta, \delta)\) is \(R(\delta, \theta) = E_\theta L(\theta, \delta(X))\). Suppose \(T\) is a sufficient statistic. Then we know there is a randomized estimator based on \(T\) with the same risk as \(\delta\). 
</p>

<p>
The Rao-Blackwell theorem shows that for convex loss functions, there is generally a non-randomized estiamtor based on \(T\) that has smaller risk than \(\delta\). 
</p>

<p>
This result shows that with convex loss functions the only estimators worth considering, at least if estimators are judged soley by their risk, are functions of \(T\) but not \(X\). It can also be used to show that any randomized estimator is worse than a corresponding nonrandomized estimator. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 1.7.9</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Randomized estimators may be useful in reducing maximum risk, but this can never be the case when the loss function is convex. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.7.13</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Hessian matrix is positive semidefinite for convex function in $k$-dimensional space. 
</p>

<p>
Strictly convex comes when the Hessian matrix is positive definite.  
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.7.21</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
For higher-dimension convex function, we can find "support plane" rather than support line. This allows us to generalize Jensen's inequality. ]
</p>
</div>
</div>

<div id="outline-container-orgb739b08" class="outline-4">
<h4 id="orgb739b08"><span class="done DONE">DONE</span> Large sample theory <code>[18/18]</code></h4>
<div class="outline-text-4" id="text-orgb739b08">
<p>
We use this to study and compare the performance of various estimators in large samples. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 8.1</dt><dd>Keener</dd>
</dl>
<p>
<i>Convergence in probability</i>, written as \(Y_n \overset{p}{\rightarrow} Y\), if for every \(\epsilon > 0\),
</p>

\begin{equation*}
P(|Y_n - Y| \geq \epsilon) \rightarrow 0
\end{equation*}

<p>
as \(n \rightarrow \infty\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 8.2</dt><dd>Keener (Chebychev's Inequality)</dd>
</dl>
<p>
For random variable \(X\) and constant \(a > 0\),
</p>

\begin{equation*}
P(|X| \geq a) \leq \frac{EX^2}{a^2}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Definition 8.6</dt><dd>Keener</dd>
</dl>
<p>
In statistics, there is a family of distributions of interest, indexed by a parameter \(\theta \in \Omega\), and the symbol \(\overset{P_\theta}{\rightarrow}\) is used to denote convergence in probability with \(P_\theta\) as the underlying probability measure. 
</p>

<p>
A sequence of estimators \(\delta_n\), \(n \geq 1\), is <i>consistent</i> for \(g(\theta)\) if for any \(\theta \in \Omega\),
</p>

\begin{equation*}
\delta_n \overset{P_\theta}{\rightarrow} g(\theta)
\end{equation*}

<p>
as \(n \rightarrow \infty\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.8.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If MSE goes to zero for all \(\theta\), then you have a consistent estimator. 
</p>

<p>
Equivalenetly, if bias and variance both go to zero asymptotically. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 1.8.3</dt><dd>Lehmann and Casella (Weak Law of Large Numbers)</dd>
</dl>
<p>
Sample mean is consistent for true mean as long as we have finite variance. 
</p>

<p>
We can see this because variance of the sample mean has \(n\) in the denominator, so variance goes to zero as \(n \rightarrow \infty\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Proposition 8.5</dt><dd>Keener</dd>
</dl>
<p>
For continuous function \(f\) at \(c\), if \(Y_n \overset{p}{\rightarrow} c\), then \(f(Y_n) \overset{p}{\rightarrow} f(c)\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 8.7</dt><dd>Keener</dd>
</dl>
<p>
<i>Convergence in distribution</i> (or law) means that the CDFs converge to the CDF of the target. 
</p>

<p>
For notation we use \(\Rightarrow\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 8.8</dt><dd>Keener</dd>
</dl>
<p>
Definition of convergence in distribution only requires pointwise convergence of the CDFs at continuity points of the target CDF. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 8.9</dt><dd>Keener</dd>
</dl>
<p>
\(Y_n \Rightarrow Y\) holds <i>if and only if</i> \(Ef(Y_n) \rightarrow Ef(Y)\) for all bounded continuous functions \(f\).
</p>

<p>
This generalizes easily to random vectors.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Corollary 8.11</dt><dd>Keener</dd>
</dl>
<p>
If \(g\) is a continuous function and \(Y_n \Rightarrow Y\), then
</p>

\begin{equation*}
g(Y_n) \Rightarrow g(Y)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 8.12</dt><dd>Keener (Central Limit Theorem)</dd>
</dl>
<p>
Suppose \(X_1, X_2, \ldots, X_n\) are i.i.d. with common mean \(\mu\) and variance \(\sigma^2\). Then
</p>

\begin{equation*}
\sqrt{n} (\bar{X}_n - \mu) \Rightarrow N(0, \sigma^2)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 8.13</dt><dd>Keener (Slutsky's Theorem)</dd>
</dl>
<p>
If \(Y_n \Rightarrow Y\), \(A_n \overset{p}{\rightarrow} a\), and \(B_n \overset{p}{\rightarrow} b\), then
</p>

\begin{equation*}
A_n + B_n Y_n \Rightarrow a + bY
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Proposition 8.14</dt><dd>Keener (Delta Method)</dd>
</dl>
<p>
If \(f\) is differentiable at \(\mu\), then 
</p>

\begin{equation*}
\sqrt{n} (f(\bar{X}_n) - f(\mu)) \Rightarrow N(0, [f^\prime (\mu)]^2 \sigma^2)
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.8.14</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If \(\sqrt{n} [T_n - \theta] \Rightarrow N(0, \tau^2)\) and if \(h^\prime(\theta) = 0\), then
</p>

\begin{equation*}
n[h(T_n) - h(\theta)] \rightarrow \frac{1}{2} h^{\prime \prime} (\theta) \chi_1^2
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 1.8.13</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Section 8.3</dt><dd>Keener</dd>
</dl>
<p>
Maximum likelihood estimators may be biased.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.8.22</dt><dd>Lehmann and Casella (Multivariate Delta Method)</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 1.8.21</dt><dd>Lehmann and Casella (Multivariate Central Limit Theorem)</dd>
</dl>
<p>
Converges in distribution to multivariate normal. Makes sense. 
</p>
</div>
</div>
</div>

<div id="outline-container-orgedbe639" class="outline-3">
<h3 id="orgedbe639"><span class="section-number-3">4.2</span> <span class="done DONE">DONE</span> Unbiasedness <code>[5/5]</code></h3>
<div class="outline-text-3" id="text-4-2">
<p>
If two estimators are unbiased, then it may not be true that their risk functions will cross, so we will be better able to compare them. We may even be able to identify a best unbiased estimator.
</p>
</div>

<div id="outline-container-org1174495" class="outline-4">
<h4 id="org1174495"><span class="done DONE">DONE</span> Minimum Variance Unbiased Estimator <code>[9/9]</code></h4>
<div class="outline-text-4" id="text-org1174495">
<dl class="org-dl">
<dt class="on">&#x2611; Definition 2.1.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
An estimator \(\delta(X)\) of \(g(\theta)\) is <i>unbiased</i> if
</p>

\begin{equation*}
E_\theta \left[ \delta(X) \right] = g(\theta) \text{ for all } \theta \in \Omega
\end{equation*}

<p>
If there exists an unbiased estimator of \(g\), then the estimand \(g\) will be called <i>U-estimable</i>.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.1</dt><dd>Keener</dd>
</dl>
<p>
In this example we come up with conditions for an estimator to be unbiased by using the definition of unbiased. Set expectation equal to the parameter value and solve for the estimator. 
</p>

<p>
If we cannot equate both sides, then the parameter (or function of parameter) is not U-estimable (see example 4.2 Keener). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 2.1.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
In the search for an unbiased estimator with uniformly minimum risk, a natural approach is to minimize the risk for some particular value of \(\theta_0\) and then see whether the result is independent of \(\theta_0\).
</p>

<p>
This lemma gives us the totality of unbiased estimators, which are given by \(\delta = \delta_0 - U\) where \(U\) is any unbiased estimator of \(0\) and \(\delta_0\) is any unbiased estimator of \(g(\theta)\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 2.1.5</dt><dd>Lehmann and Casella</dd>
</dl>

<div style="margin-bottom: 150px;"></div>

<dl class="org-dl">
<dt>Keener p. 62</dt><dd>With squared error loss, the risk of an unbiased estimator is just its variance, so the goal would be to minimize the variance.</dd>

<dt class="on">&#x2611; Definition 2.1.6</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
An unbiased estimator is the <i>uniform minimum variance unbiased</i> (UMVU) estimator if it's variance is \(\leq\) the variance of any other unbiased estimator, for all \(\theta\). 
</p>

<p>
An unbiased estimator is the <i>locally minimum variance unbiased</i> (LMVU) estimator if it's variance is \(\leq\) the variance of any other unbiased estimator, for \(\theta = \theta_0\).
</p>

<p>
<span class="underline">UMVU estimators are unique</span>. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.1.7</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Denote the class of estimators \(\delta\) with \(E_\theta \delta^2 < \infty\) for all \(\theta\) by \(\Delta\).
</p>

<p>
Let \(\delta\) be an estimator in \(\Delta\), and let \(\mathcal{U}\) denote the est of all unbiased estimators of zero which are in \(\Delta\). Then, a necessary and sufficient condition for \(\delta\) to be a UMVU estimator of its expectation \(g(\theta)\) is that 
</p>

\begin{equation*}
E_\theta(\delta U) = 0 \text{ for all } U \in \mathcal{U} \text{ and all } \theta \in \Omega
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 4.4</dt><dd>Keener</dd>
</dl>
<p>
In general, there is no reason to suspect that there will be a UMVU estimator. 
</p>

<p>
However, if a family has a complete sufficient statistic, a UMVU will exist, at least when \(g\) is U-estimable. 
</p>

<p>
Suppose \(g\) is I-estimable and \(T\) is complete sufficient. Then there is an essentially unique unbiased estimator based on \(T\) that is UMVU.
</p>

<p>
From the uniqueness assertion in this theorem, if \(T\) is complete sufficient and \(\eta(t)\) is unbiased, then \(\eta(T)\) must be UMVU. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; UMVU Method One: Solving for \(\delta\),</dt><dd>Lehmann and Casella p. 88</dd>
</dl>
<p>
If \(T\) is a complete sufficient statistic, the UMVU estimator of any U-estimable function \(g(\theta)\) is uniquely determined by the set of equations
</p>

\begin{equation*}
E_\theta \delta(T) = g(\theta) \text{ for all } \theta \in \Omega
\end{equation*}

<p>
Basically is we find a function of a complete sufficient statistic whose expectation is \(g(\theta)\), then it will be UMVUE. 
</p>

<p>
See example 4.5 in Keener. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; UMVU Method Two: Conditioning,</dt><dd>Lehmann and Casella p. 89</dd>
</dl>
<p>
If we take the conditional expectation of any unbiased estimator \(\delta(X)\) given a complete sufficient statistic \(T\), then it will be UMVUE. 
</p>

<p>
It doesn't matter which unbiased estimator \(\delta\) is being conditioned, we should choose whichever one makes our lives easiest. 
</p>

<p>
See example 4.6 in keener.
</p>

<dl class="org-dl">
<dt>Second thoughts about bias, Keener 4.2</dt><dd>It may not make sense to only consider unbiased estimators. Estimators with considerable bias may not be worth considering, but estimators with small bias may be quite reasonable.</dd>
</dl>
</div>
</div>

<div id="outline-container-org75d4812" class="outline-4">
<h4 id="org75d4812"><span class="done DONE">DONE</span> Continuous distributions and UMVU <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-org75d4812">
<dl class="org-dl">
<dt class="on">&#x2611; Section 4.3</dt><dd>Keener</dd>
</dl>

<p>
Let \(X \sim N(\mu, \sigma^2)\) and take \(Z = (X - \mu)/\sigma\). 
</p>

<p>
Standard normal is \(Z \sim N(0, 1)\). 
</p>

<p>
Moment generating function of \(Z\) is \(M_Z(u) = e^{u^2 / 2}\), \(u \in \mathbb{R}\). 
</p>

<p>
More generally, for \(X \sim N(\mu, \sigma^2)\), \(aX + b \sim N(a\mu + b, a^2 \sigma^2)\)
</p>

<p>
Moment generating function of \(X\) is \(M_X(u) = e^{u\mu + u^2 \sigma^2 / 2}\), \(u \in \mathbb{R}\).
</p>

<p>
Sample mean is 
</p>

\begin{equation*}
\bar{X} = \frac{X_1 + \cdots + X_n}{n}
\end{equation*}

<p>
Sample variance is
</p>

\begin{equation*}
S^2 = \frac{1}{n-1} \sum_{i = 1}^{n} (X_i - \bar{X})^2
\end{equation*}

<p>
Since one-to-one relationships preserve sufficiency and completeness, \((\bar{X}, S^2)\) is a complete sufficient statistic for \((\mu, \sigma^2)\).
</p>

<p>
We have 
</p>

\begin{equation*}
\bar{X} \sim N(\mu, \sigma^2 / n)
\end{equation*}

<p>
Derivation for distribution of \(S^2\) is more involved. We get
</p>

\begin{equation*}
V = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}.
\end{equation*}

<p>
Sum of normals is normal with mean equal to sum of means and variance equal to sum of variances. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 2.2.1</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.2.2</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.2.5</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>

<dl class="org-dl">
<dt>Normal One-Sample Problem &#x2013; Estimation, 4.4 Keener</dt><dd></dd>
</dl>

<p>
\(S^2\) is UMVU for \(\sigma^2\). Note that UMVU for \(\sigma\) is not \(S\), although \(S\) is a common and natural choice in practice. 
</p>

<p>
\(\bar{X}\) is the UMVU estimator of \(\mu\). However, \(\bar{X}^2\) is biased for \(\mu^2\). If we substract the bias, we get \(\bar{X}^2 - S^2/n\) is UMVU for \(\mu^2\). 
</p>
</div>
</div>

<div id="outline-container-org80b18cf" class="outline-4">
<h4 id="org80b18cf"><span class="done DONE">DONE</span> UMVU for discrete distributions <code>[8/8]</code></h4>
<div class="outline-text-4" id="text-org80b18cf">
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3.1</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Power series distributions p. 104</dt><dd>Lehmann and Casella</dd>
</dl>

\begin{equation*}
P(X = x) = \frac{a(x) \theta^x}{C(\theta)} \\
x = 0, 1, \ldots , \\
\theta > 0
\end{equation*}

<p>
Binomial distribution is an example. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 2.3.6</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If \(X_1, \ldots, X_n\) are from a power series family, then \(X_1 + \cdots + X_n\) is sufficient for \(\theta\), and the distribution of \(T = X_1 + \cdots + X_n\) is the power series family
</p>

\begin{equation*}
P(T = t) = \frac{A(t, n) \theta^t}{[C(\theta)]^n}
\end{equation*}

<p>
where \(A(t, n)\) is the coefficient of \(\theta^t\) in the power series expansion of \([C(\theta)]^n\).
</p>

<p>
It follows that \(T\) is complete and that the UMVU estimator of \(\theta^r\) on the basis of a sample of \(n\) is
</p>

\begin{equation*}
\frac{A(t - r, n)}{A(t, n)} \text{ if } t \geq r \\
0 \text{ otherwise }
\end{equation*}


<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3.7</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3.8</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3.9</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3.10</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.3.11</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
<div id="outline-container-org2e80111" class="outline-4">
<h4 id="org2e80111"><span class="done DONE">DONE</span> Information inequality <code>[12/12]</code></h4>
<div class="outline-text-4" id="text-org2e80111">
<dl class="org-dl">
<dt class="on">&#x2611; Section 4.5</dt><dd>Keener</dd>
</dl>

\begin{equation*}
\text{Cov}(X, Y) = E(X - EX)(Y - EY) = EXY - (EX)(EY)
\end{equation*}

<p>
So if either \(X\) or \(Y\) have mean \(0\), then \(\text{Cov}(X, Y) = EXY\).
</p>

<p>
<i>Covariance inequality</i> is
</p>

\begin{equation*}
\text{Cov}^2(X, Y) \leq \text{Var}(X) \text{Var}(Y)
\end{equation*}

<p>
Using the covariance inequality, if \(\delta\) is an unbiased estimator of \(g(\theta)\) and \(\psi\) is an arbitrary random variable, then
</p>

\begin{equation*}
\text{Var}_\theta (\delta) \geq \frac{\text{Cov}^2_\theta (\delta, \psi)}{\text{Var}_\theta (\psi)}.
\end{equation*}

<p>
The right hand side of this inequality involves \(\delta\), so this seems rather useless as a bound for the variance of \(\delta\). To make headway we need to choose \(\psi\) cleverly, so that \(\text{Cov}_\theta (\delta, \psi)\) is the same for all \(\delta\) that are unbiased for \(g(\theta)\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Equation 4.13</dt><dd>p. 72 Keener (Hammersley-Chapman-Robbins inequality)</dd>
</dl>
<p>
This is a more general form of the Cramer Rao bound, which doesn't require differentiation under the integral sign. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Equation 4.14</dt><dd>p. 72 Keener (Fisher information)</dd>
</dl>

\begin{equation*}
I(\theta) = E_\theta \left(\frac{\partial \log p_\theta(X)}{\partial \theta} \right)^2
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Equation 4.17</dt><dd>p. 73 Keener (Cramer Rao Bound)</dd>
</dl>
<p>
Let \(\delta\) have mean \(g(\theta) = E_\theta \delta\) and take \(\psi = \partial \log p_\theta / \partial \theta\). Then with sufficient regularity,
</p>

\begin{equation*}
g^\prime(\theta) = E_\theta \delta \psi
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 4.9</dt><dd>Keener (Cramer Rao Bound)</dd>
</dl>

<p>
Let \(\mathcal{P} = \{P_\theta : \theta \in \Omega \}\) be a dominated family with \(\Omega\) an open set in \(\mathbb{R}\) and densities \(p_\theta\) differentiable with respect to \(\theta\). If \(E_\theta \psi = 0\), \(E_\theta \delta^2 < \infty\), and \(g^\prime (\theta) = E_\theta \delta \psi\) hold for all \(\theta \in \Omega\), then 
</p>

\begin{equation*}
\text{Var}_\theta (\delta) \geq \frac{\left[g^\prime (\theta) \right]^2}{I(\theta)} \\
\theta \in \Omega
\end{equation*}


<dl class="org-dl">
<dt class="on">&#x2611; Equation 4.18</dt><dd>p. 74 Keener (Reparameterization)</dd>
</dl>

<p>
You can reparameterize if you have a one-to-one mapping from \(\Xi\) to \(\Omega\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.12</dt><dd>Keener</dd>
</dl>
<p>
Higher dimesnional example for \(s\) -parameter exponential family. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.5.5</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If \(X\) is distributed according to an exponential family with \(s = 1\), then 
</p>

\begin{equation*}
I(E_\theta(T)) = \frac{1}{\text{Var}_\theta(T)}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 2.5.6</dt><dd>Lehmann and Casella</dd>
<dt class="on">&#x2611; Example 4.11</dt><dd>Keener</dd>
</dl>

<p>
For location families, \(I(\theta)\) is constant and does not vary with \(\theta\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.5.12</dt><dd>Lehmann and Casella (Attainment)</dd>
</dl>
<p>
Gives conditions under which exponential families attain the information bound. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.5.13</dt><dd>Lehmann and Casella</dd>
</dl>
</div>
</div>

<div id="outline-container-org5929d2c" class="outline-4">
<h4 id="org5929d2c"><span class="done DONE">DONE</span> Multiparameter information inequality <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-org5929d2c">
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.6.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
<i>Information matrix</i> is \(s \times s\) matrix
</p>

\begin{equation*}
I(\theta) = ||I_{ij}(\theta)||
\end{equation*}

<p>
where 
</p>

\begin{equation*}
I_{ij}(\theta) = E_\theta \left[ \frac{\partial}{\partial \theta_i} \log p_\theta(X) \cdot \frac{\partial}{\partial \theta_j} \log p_\theta(X) \right]
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.6.2</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 2.6.3</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 2.6.6</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Equation 2.6.27</dt><dd>p. 128 Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
</div>

<div id="outline-container-org31d7093" class="outline-3">
<h3 id="org31d7093"><span class="section-number-3">4.3</span> <span class="done DONE">DONE</span> Equivariance <code>[1/1]</code></h3>
<div class="outline-text-3" id="text-4-3">
</div>
<div id="outline-container-orgb559a38" class="outline-4">
<h4 id="orgb559a38"><span class="done DONE">DONE</span> First Examples <code>[26/26]</code></h4>
<div class="outline-text-4" id="text-orgb559a38">
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This is an interesting example to motivate the location equivariant problem. If we have \(n\) draws from a binomial, and we are trying to estimate \(p\), we may use the estimator \(\frac{1}{n} \sum X_i\). If, however, we find out that \(p\) is actually the probability of failure, and we want to estimate \(1 -p\), then we can just use \(1 - \frac{1}{n} \sum X_i\). The estimation is <i>invariant</i> under the transormation \(d^\prime = 1 - d\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.1.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
A family of densities is <i>location invariant</i> if you can add a value to the parameter, and add that same value to the data, and it is equivalent to the originial problem.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.1.3</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
<i>Location equivariant estimator</i> is
</p>

\begin{equation*}
\delta(X_1 + a, X_2 + a, \ldots, X_n + a) = \delta(X_1, X_2, \ldots, X_n) + a \text{ for all } a
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.1.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Bias, risk, and variance are constant for location equivariant family (they do not depend on the location parameter \(\xi\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.1.5</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
<i>Minimum risk equivariant</i> (MRE) estimator is location equivariant estimator that minimizes the constant risk. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 3.1.6</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This gives a general representation for a location equivariant estimator, as a family made up of functions of a given equivariant estimator. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 3.1.7</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
How do we come up with the function to get family of equivariant estimators. Needs to be function of the differences \(x_i - x_n\) for \(n \geq 2\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.1.8</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Characterization of equivariant estimators.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.9</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If \(n = 1\), then the only equivariant estimators are \(X + c\) for some constant \(c\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.1.10</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This gives way to determine equivariant estimator with minimum risk.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Corollary 3.1.11</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Gives conditions for MRE to exist and be unique. Depends on the shape of the loss function. Needs to be convex and not monotone for existence, and strictly convex for uniquenes. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Corollary 3.1.12</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Characterizes the MRE under squared error loss and abolute error loss.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.15</dt><dd>Lehmann and Casella (MRE under 0-1 loss)</dd>
</dl>
<p>
In this case, there are two MRE. Not unique. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.16</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
\(\bar{X}\) is MRE for estimating mean of normals with known variance. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.1.17</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
"least favorable" property of the normal distribution
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.18</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
An MRE estimator need not be unbiased.
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.19</dt><dd>Lehmann and Casella</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.1.20</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Use <i>pitman estimator</i> under squared error loss
</p>

\begin{equation*}
\frac{\int_{-\infty}^{\infty} u f(x_1 - u, \ldots, x_n - u) du}{\int_{-\infty}^{\infty} f(x_1 - u, \ldots, x_n - u) du}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1.21</dt><dd>Lehmann and Casella</dd>
<dt class="on">&#x2611; Example 3.1.22</dt><dd>Lehmann and Casella</dd>
<dt class="on">&#x2611; Randomized estimators for equivariant estimation</dt><dd>p. 155 Lehmann and Casella</dd>
<dt class="on">&#x2611; Lemma 3.1.23</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Under squared error loss, we have
</p>
<ol class="org-ol">
<li>When \(\delta(\mathbf{X})\) is any equivariant estimator with constant bias \(b\), then \(\delta(\mathbf{X}) - b\) is equivariant, unbiased, and has smaller risk than \(\delta(\mathbf{X})\).</li>
<li>The unique MRE estimator is unbiased.</li>
<li>If a UMVU estimator exists and is equivariant, it is MRE.</li>
</ol>
<dl class="org-dl">
<dt class="on">&#x2611; Definition 3.1.24</dt><dd>Lehmann and Casella</dd>
<dt class="on">&#x2611; Example 3.1.25</dt><dd>Lehmann and Casella</dd>
<dt class="on">&#x2611; Example 3.1.26</dt><dd>Lehmann and Casella</dd>
<dt class="on">&#x2611; Theorem 3.1.27</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If \(\delta\) is MRE for estimating \(\xi\) in a location invariant model with a loss function \(\rho(\delta - \xi)\), then it is risk-unbiased. 
</p>

<p>
This means that it has lower risk than for any other value of the parameter \(\theta\). 
</p>
</div>
</div>
</div>
<div id="outline-container-org54614d3" class="outline-3">
<h3 id="org54614d3"><span class="section-number-3">4.4</span> <span class="done DONE">DONE</span> Average risk optimality <code>[6/6]</code></h3>
<div class="outline-text-3" id="text-4-4">
</div>
<div id="outline-container-org772f333" class="outline-4">
<h4 id="org772f333"><span class="done DONE">DONE</span> Introduction <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-org772f333">
<p>
We are concerned with minimizing the (weighted) average risk for some suitable non-negative weight function. 
</p>

\begin{equation*}
r(\Lambda, \delta) = \int R(\theta, \delta) d\Lambda(\theta)
\end{equation*}

<p>
where 
</p>

\begin{equation*}
\int d \Lambda(\theta) = 1
\end{equation*}

<p>
An estimator \(\delta\) minimizing \(r(\Lambda, \delta)\) is called a <span class="underline">Bayes estimator</span>.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 4.1.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Let \(\Theta\) have distribution \(\Lambda\), and given \(\Theta = \theta\), let \(X\) have distribution \(P_\theta\). Suppose, in addition, the following assumptions hold for the problem of estimating \(g(\Theta)\) with non-negative loss function \(L(\theta, d)\).
</p>

<ol class="org-ol">
<li>There exists an estimator \(\delta_0\) with finite risk.</li>
<li>For almost all \(x\), there exists a value \(\delta_\Lambda(x)\) minimizing</li>
</ol>

\begin{equation*}
E\{L[\Theta, \delta(x)]|X = x\}.
\end{equation*}

<p>
Then, \(\delta_\Lambda(X)\) is a Bayes estimator.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 4.1.2</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
This tells us what the Bayes estimator is in the case of squared error loss, weighted squared error loss, and absolute error, under the assumptions of the previous theorem. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.1.3</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Poisson example. We give a Gamma prior. This shows that the choice of loss function can have a large effect on the resulting Bayes estimator. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 4.1.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
These are sufficient conditions for a Bayes solution is unique.
Basically it requires a convex loss function with finite average risk. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.1.5</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Binomial example with Beta prior. The Bayes estimator for \(p\) is a weighted average between the UMVU \(X/n\) and the prior mean.  
</p>
</div>
</div>

<div id="outline-container-org1e6f266" class="outline-4">
<h4 id="org1e6f266"><span class="done DONE">DONE</span> First examples <code>[7/7]</code></h4>
<div class="outline-text-4" id="text-org1e6f266">
<p>
We construct Bayes estimators as functions of the posterior density, and we decide which prior and loss function to use. These choises will affect the properties of the estimator.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.2.2</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Normal mean example with known variance. This is an example of Normal-Normal conjugacy. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 4.2.3</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Let \(\Theta\) have a distribution \(\Lambda\), and let \(P_\theta\) denote the conditional distribution of \(X\) given \(\theta\). Consider the estimation of \(g(\theta)\) when the loss function is squared error. Then, no unbiased estimator \(\delta(X)\) can be a Bayes solution unless 
</p>

\begin{equation*}
E[\delta(X) - g(\Theta)]^2 = 0
\end{equation*}

<p>
where the expectation is taken with respect to variation in both \(X\) and \(\Theta\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.2.4</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Apply the last theorem to sample means.
</p>


<dl class="org-dl">
<dt class="on">&#x2611; Example 4.2.5</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Gamma is conjugate for normal precision parameter. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.2.6</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Normal variance with unknown mean. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.2.8</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Bayes estimator may still be defined even with improper prior. Improper prior has
</p>

\begin{equation*}
\int d\Lambda(\theta) = \infty
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Definition 4.2.10</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
A nonrandomized estimator \(\delta(x)\) is a <span class="underline">limit of Bayes estimators</span> if there exists a seequence of proper priors \(\pi_\nu\) and Bayes estimators \(\delta^{\pi_\nu}\) such that \(\delta^{\pi_\nu}(x) \rightarrow \delta(x)\) a.e. as \(\nu \rightarrow \infty\).
</p>
</div>
</div>

<div id="outline-container-org08d7e75" class="outline-4">
<h4 id="org08d7e75"><span class="done DONE">DONE</span> Single Prior Bayes <code>[3/3]</code></h4>
<div class="outline-text-4" id="text-org08d7e75">
<p>
Denote the prior by the density \(\pi(\theta | \gamma)\).
</p>

<p>
We can hen write a Bayes model in a general form as
</p>

\begin{equation*}
X|\Theta \sim f(x|\theta),
\end{equation*}

\begin{equation*}
\Theta | \gamma \sim \pi(\theta | \gamma).
\end{equation*}

<p>
In this section, we assume that the function form of the prior, and the value of \(\gamma\), is known so we have one completely specified prior. 
</p>

<p>
Given a loss function \(L(\theta, d)\), we then look for the estimator that minizes
</p>

\begin{equation*}
\int L(\theta, d(x)) \pi(\theta | x, \gamma) d \theta,
\end{equation*}

<p>
where \(\pi(\theta | x, \gamma) = f(x | \theta) \pi(\theta | \gamma) / \int f(x | \theta) \pi (\theta | \gamma) d \theta\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.3.1</dt><dd>Lehmann and Casella</dd>
</dl>

<div style="margin-bottom: 150px;"></div>

<dl class="org-dl">
<dt class="on">&#x2611; Conjugate exponential family</dt><dd>p. 244 Lehmann and Casella</dd>
</dl>
<p>
In exponential families, there is a general expression for the conjugate prior distribution and use of this conjugate prior results in a simple expression for the posterior mean. For the density
</p>

\begin{equation*}
p_\eta (x) = e^{\eta x - A(\eta)} h(x),
\end{equation*}

<p>
the conjugate prior family is 
</p>

\begin{equation*}
\pi(\eta | \kappa, \mu) = c(\kappa, \mu) e^{\kappa \eta \mu - \kappa A(\eta)},
\end{equation*}

<p>
where \(\mu\) can be thought of as a prior mean and \(\kappa\) is proportional to a prior variance. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.3.7</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
We can apply the conjugate prior for exponential families to the gamma distribution. 
</p>
</div>
</div>

<div id="outline-container-org87855e1" class="outline-4">
<h4 id="org87855e1"><span class="done DONE">DONE</span> Hierarchical Bayes <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-org87855e1">
<dl class="org-dl">
<dt class="on">&#x2611; Section 4.5 intro</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
In a hierarchical Bayes model, rather than specifying the prior distribution as a single function, we specify it in a hierarchy. Thus, we place another level on the model and write
</p>

\begin{equation*}
X|\theta \sim f(x | \theta), \\
\Theta | \gamma \sim \pi(\theta | \gamma), \\
\Gamma \sim \psi(\gamma),
\end{equation*}

<p>
where we assume that \(\psi(\cdot)\) is known and not dependent on any other unknown hyperparameters (as parameters of a prior are sometimes called). 
</p>

<p>
This allows us to model relatively complicated situations using a series of simpler steps; that is, both \(\pi(\theta | \gamma)\) and \(\psi(\gamma)\) may be of simple form (even conjugate), but \(\pi(\theta)\) may be more complex. 
</p>

<p>
Given a loss function \(L(\theta, d)\), we would then determine the estimator that minimizes 
</p>

\begin{equation*}
\int L(\theta, d(x))\pi(\theta | x) d\theta
\end{equation*}

<p>
where 
</p>

\begin{equation*}
\pi(\theta | x) = \frac{\int f(x | \theta) \pi(\theta | \gamma) \psi(\gamma) d\gamma}{\iint f(x | \theta) \pi(\theta | \gamma) \psi(\gamma) d\theta d\gamma}
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.5.1 &amp; 4.5.2</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Conjugate Normal Hierarchy
</p>

\begin{align*}
X_i | \theta &\sim N(\theta, \sigma^2), \sigma^2 \text{ known}, \quad i = 1, \ldots, n, \\
\theta|\tau &\sim N(0, \tau^2) \\
\frac{1}{\tau^2} &\sim \text{Gamma}(a, b), \quad a, b \text{ known}. 
\end{align*}

<p>
The hierarchical Bayes estimator of \(\theta\) under squared error loss is
</p>

\begin{equation*}
\mathbb{E}(\Theta | x) = \mathbb{E}[\mathbb{E}(\Theta | x, \tau^2)]
\end{equation*}

<p>
Even though at each stage of the model a conjugate prior was used, the resulting Bayes estimator is not from a conjugate prior and it is not expressible in a simple form. Such an occurrence is somewhat commonplace in hierachical Bayes analysis.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.5.3</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Beta-binomial hierachy
</p>

\begin{align*}
X|p &\sim \text{binomial}(p, n), \\
p|a, b &\sim \text{beta}(a, b), \\
(a, b) &\sim \psi(a, b),
\end{align*}

<p>
leading to posterior mean
</p>

\begin{equation*}
\mathbb{E}(p | x) = \frac{\int_0^1 p^{x + 1}(1-p)^{n - x} \pi(p) dp}{\int_0^1 p^{x}(1-p)^{n - x} \pi(p) dp}
\end{equation*}

<p>
where
</p>

\begin{equation*}
\pi(p) = \iint \frac{\Gamma (a + b)}{\Gamma (a) \Gamma (b)} p^{a - 1} (1-p)^{b - 1} \psi(a, b) da db.
\end{equation*}

<p>
which is difficult to calculate. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Gibbs sampling</dt><dd>p. 256 Lehmann and Casella</dd>
</dl>

<p>
Technically, these computations are not
approximations, as they are exact in the limit. However, since they involve only
a finite number of computations, we think of them as approximations, but realize
that any order of precision can be achieved.
</p>

<p>
Suppose we are interested in calculating the posterior distribution \(\pi(\theta | x)\) (or \(\mathbb{E}(\Theta | x)\), or some other feature of the posterior distribution). We calucalte the full conditionals 
</p>

\begin{align*}
\Theta|x, \gamma &\sim \pi(\theta | x, \gamma), \\
\Gamma |x, \theta &\sim \pi(\gamma | x, \theta),
\end{align*}

<p>
which are the posterior distributions of each parameter conditional on all others.
</p>

<p>
If, for \(i = 1, 2, \ldots, M\), random variables are generated according to 
</p>

\begin{align*}
\Theta_i|x, \gamma_{i - 1} &\sim \pi(\theta | x, \gamma_{i - 1}), \\
\Gamma_i |x, \theta_i &\sim \pi(\gamma | x, \theta_i),
\end{align*}

<p>
this defines a Markov chain \((\Theta_i, \Gamma_i)\). It follows from the rich theory of such chains that there exist distributions \(\pi(\theta | x)\) and \(\pi(\gamma | x)\) such that 
</p>

\begin{align*}
\Theta_i &\rightarrow \Theta \sim \pi(\theta | x), \\
\Gamma_i &\rightarrow \Gamma \sim \pi(\gamma | x)
\end{align*}

<p>
as \(i \rightarrow \infty\), and
</p>

\begin{equation*}
\frac{1}{m} \sum_{i = 1}^M h(\Theta_i) \rightarrow \mathbb{E}(h(\Theta)|x) = \int h(\theta)\pi(\theta|x)d\theta
\end{equation*}

<p>
as \(M \rightarrow \infty\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.5.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Poisson hierarchy with Gibbs sampling. 
</p>

\begin{align*}
X|\lambda &\sim \text{Poisson}(\lambda) \\
\Lambda|b &\sim \text{Gamma}(a, b), \quad a \text{ known} \\
\frac{1}{b} &\sim \text{Gamma}(k, \tau),
\end{align*}

<p>
leading to the full conditionals 
</p>

\begin{align*}
\Lambda | x, b &\sim \text{Gamma}\left(a + x, \frac{b}{1 + b} \right) \\
\frac{1}{b} | x, \lambda &\sim \text{Gamma}\left(a + k, \frac{\tau}{1 + \lambda \tau} \right). 
\end{align*}
</div>
</div>

<div id="outline-container-orgbce9b0a" class="outline-4">
<h4 id="orgbce9b0a"><span class="done DONE">DONE</span> Empirical Bayes <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-orgbce9b0a">
<dl class="org-dl">
<dt class="on">&#x2611; Section 4.6 intro</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Empircal Bayes estimators tend to be more robust against misspecification of the prior distribution. 
</p>

<p>
Treat \(\gamma\) as an unkown parameter of the model, which also needs to be estimated. We begin with the Bayes model
</p>

\begin{align*}
X_i | \theta &\sim f(x|\theta), \quad i = 1, \ldots, p, \\
\Theta | \gamma &\sim \pi(\theta | \gamma). 
\end{align*}

<p>
and calculate the marginal distribution of \(X\), with density
</p>

\begin{equation*}
m(x | \gamma) = \int \prod f(x_i | \theta) \pi(\theta | \gamma) d\theta.
\end{equation*}

<p>
Based on \(m(x | \gamma)\), we obtain an estimate, \(\hat{\gamma}(x)\), of \(\gamma\). It is common to take \(\hat{\gamma}(x)\) to be the MLE of \(\gamma\). We now substitute \(\hat{\gamma}(x)\) for \(\gamma\) in \(\pi(\theta | \gamma)\) and determine the estimator that minimizes the empircal posterior loss
</p>

\begin{equation*}
\int L(\theta, \delta(x)) \pi(\theta | x, \hat{\gamma}(x)) d\theta. 
\end{equation*}

<p>
This minimizing estimator is the empirical Bayes estimator.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.6.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Normal empirical Bayes
</p>

<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 4.6.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Empirical Bayes binomial
</p>

<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 4.6.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
For estimating the natural parameter of an exponential family, the empirical Bayes estimator (using the marginal MLE) can be expressed in the same form as a formal Bayes estimator. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.6.5</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Hierarchical Bayes approximation
</p>

<p>
A hierarchical Bayes estimator averages over the hyperparameter, while an empirical Bayes estimator estimates the hyperparameter. 
</p>
</div>
</div>

<div id="outline-container-orgd619015" class="outline-4">
<h4 id="orgd619015"><span class="done DONE">DONE</span> Shrinkage Estimators <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-orgd619015">
<dl class="org-dl">
<dt class="on">&#x2611; Example 4.7.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
The James-Stein estimator. 
</p>

<p>
The James-Stein estimator is an empirical Bayes estimator for the mean of a multivariate normal distribution under sum-of-squared-errors loss. 
</p>

<p>
It has a smaller MSE than the MLE \(X\) for all \(\theta\), where \(X \sim N_p(\theta, \sigma^2 I)\).
</p>

<p>
However, the James-Stein estimator (or any empirical Bayes estimator) cannot attain as small a Bayes risk as the Bayes estimator. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 11.1</dt><dd>Keener (Stein's Identity)</dd>
</dl>
<p>
Suppose \(x \sim N(\mu, \sigma^2), h: \mathbb{R} \rightarrow \mathbb{R}\) is differentiable (absolutely continuous is also sufficient), and 
</p>

\begin{equation*}
\mathbb{E}|h^{\prime}(X)| < \infty.
\end{equation*}

<p>
Then
</p>

\begin{equation*}
\mathbb{E}(X - \mu)h(X) = \sigma^2\mathbb{E}h^{\prime}(X)
\end{equation*}


<dl class="org-dl">
<dt class="on">&#x2611; Corollary 4.7.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This gives us an unbiased estimator of the risk. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 4.7.3</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Bayes risk of the James-Stein estimator.
</p>

<p>
It turns out that the James-Stein empirical Bayes estimator has a reasonable Bayes risk. 
</p>
</div>
</div>
</div>
<div id="outline-container-org876e59a" class="outline-3">
<h3 id="org876e59a"><span class="section-number-3">4.5</span> <span class="done DONE">DONE</span> Minimaxity and admissibility <code>[3/3]</code></h3>
<div class="outline-text-3" id="text-4-5">
</div>
<div id="outline-container-org9ee4c4a" class="outline-4">
<h4 id="org9ee4c4a"><span class="done DONE">DONE</span> Admissibility <code>[5/5]</code></h4>
<div class="outline-text-4" id="text-org9ee4c4a">
<dl class="org-dl">
<dt class="on">&#x2611; Inadmissible definintion</dt><dd>p. 213 Keener</dd>
</dl>
<p>
A decision rule \(\delta\) is called <span class="underline">inadmissible</span> if a competing rule \(\delta^*\) has a better risk function, specifically if \(R(\theta, \delta^*) \leq R(\theta, \delta)\) for all \(\theta \in \Omega\) with \(R(\theta, \delta^*) < R(\theta, \delta)\) for some \(\theta \in \Omega\). If this happens, we say \(\delta^*\) <span class="underline">dominates</span> \(\delta\). All other rules are called <span class="underline">admissible</span>. 
</p>

<p>
If your goal is to minimize risk, then you should never want to use an inadmissible rule. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 11.6</dt><dd>Keener</dd>
</dl>
<p>
Let \(\Lambda\) be a prior distribution. The decision rule \(\delta\) is called a <span class="underline">Bayes</span> rule for \(\Lambda\) if it minimizes the integrated risk. If a Bayes rule \(\delta\) for \(\Lambda\) is essentially unique, then \(\delta\) is admissible. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 11.7</dt><dd>Keener</dd>
</dl>
<p>
If risk functions for all decision rules are continuous in \(\theta\), if \(\delta\) is Bayes for \(\Lambda\) and has finite integrated risk \(R(\Lambda, \delta) < \infty\), and if the support of \(\Lambda\) is the whole parameter space \(\Omega\), then \(\delta\) is admissible. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 11.9</dt><dd>Keener</dd>
</dl>
<p>
In regular cases amu admissible rule will be a limit of Bayes rules. Unfortunately, some limits may give inadmissible rules. This result gives a sufficient condition for admissibility. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 11.10</dt><dd>Keener</dd>
</dl>
<p>
This is a Bayesian formulation of the one-sample problem. 
</p>
</div>
</div>
<div id="outline-container-orgb628bf3" class="outline-4">
<h4 id="orgb628bf3"><span class="done DONE">DONE</span> Minimax Estimation <code>[12/12]</code></h4>
<div class="outline-text-4" id="text-orgb628bf3">
<p>
Choosing an estimator to minimize the maximum risk leads to minimax estimators. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 5.1.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
An estimator \(\delta^M\) of \(\theta\), which minimzes the maximum risk, that is, which satisfies
</p>

\begin{equation*}
\inf_\delta \sup_\theta R(\theta, \delta) = \sup_\theta R(\theta, \delta^M),
\end{equation*}

<p>
is called a <span class="underline">minimax</span> estimator. 
</p>

<p>
It is difficult to determine minimax estimators for large classes of problems, so we will have to treat problems individually. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 5.1.3</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Denote the average risk (Bayes risk) of the Bayes solution \(\delta_\Lambda\) by
</p>

\begin{equation*}
r_\Lambda = r(\Lambda, \delta_\Lambda) = \int R(\theta, \delta_\Lambda) d\Lambda(\theta).
\end{equation*}

<p>
A prior distribution \(\Lambda\) is <span class="underline">least favorable</span> if \(r_\Lambda \geq r_{\Lambda^{\prime}}\) for all prior distributions \(\Lambda^{\prime}\). 
</p>

<p>
This is the prior distributions which causes the statistician the greatest average loss. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 5.1.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Provides a simple condition for a Bayes estimator \(\delta_\Lambda\) to be minimax.
</p>

<p>
Suppose that \(\Lambda\) is a distribution on \(\Theta\) such that
</p>

\begin{equation*}
r(\Lambda, \delta_\Lambda) = \int R(\theta, \delta_\Lambda) d\Lambda(\theta) = \sup_\theta R(\theta, \delta_\Lambda).
\end{equation*}

<p>
(The average of \(R(\theta, \delta_\Lambda)\) is equal to its maximum. This will be the case when the risk function is constant, or, more generally, when \(\Lambda\) assigns probability 1 to the set on which the risk function takes on its maximum values). 
</p>

<p>
Then:
</p>

<ol class="org-ol">
<li>\(\delta_\Lambda\) is minimax.</li>
<li>If \(\delta_\Lambda\) is the unique Bayes solution with respect to \(\Lambda\), it is the unique minimax procedure.</li>
<li>\(\Lambda\) is least favorable.</li>
</ol>
<dl class="org-dl">
<dt class="on">&#x2611; Corollary 5.1.5</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If a Bayes solution \(\delta_\Lambda\) has constant risk, then it is minimax. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.1.7</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Binomial example. This is a good example to review. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.1.8</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Randomized minimax estimator example. 
</p>

<p>
It is possible to reduce the maximum risk through randomization.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.1.9</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Difference of two binomials example. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.1.10</dt><dd>Lehmann and Casella (helpful)</dd>
</dl>

<p>
Let \(\delta\) be a Bayes (respectively, UMVU, minimax, admissible) estimator of \(g(\theta)\) for squared error loss. Then, \(a\delta + b\) is Bayes (respectively, UMVU, minimax, admissible) for \(ag(\theta) + b\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Definition 5.1.11</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Theorem 5.1.4 implies that a least favorable distribution exists. When such a distribution does not exist, theorem 5.1.4 is not applicable. Consider, for example, the problem of estimating the mean \(\theta\) of a normal distribution with known variance. Since all possible values of \(\theta\) play a completely symmetrical role, in the sense that none is easier to estimate than any other, it is natural to conjecture that the least favorable distribution is "uniform" on the real line, that is, that the least favorabale distribution is Lebesgue measure. This is the Jeffreys prior and, in this case, it is not a proper distribution. 
</p>

<p>
There are two ways in which the approach of Theorem 5.1.4 can be generalized to include improper priors.
</p>

<ol class="org-ol">
<li>It may turn out that the posterior distribution given \(x\) is a proper distribution. One can then compute the expectation \(\mathbb{E}(g(\Theta) | x)\) for this distribution, a <i>generalized</i> Bayes estimator.</li>
<li>Alternatively, one can approximate the improper prior distribution with a sequence of proper distributions.</li>
</ol>

<p>
A sequence of prior distributions \(\{ \Lambda_n \}\) is <span class="underline">least favorable</span> if for every prior distribution \(\Lambda\) we have
</p>

\begin{equation*}
r_\Lambda \leq r = \lim_{n \rightarrow \infty} r_{\Lambda_n},
\end{equation*}

<p>
where 
</p>

\begin{equation*}
r_{\Lambda_n} = \int R(\theta, \delta_n) d\Lambda_n(\theta)
\end{equation*}

<p>
is the Bayes risk under \(\Lambda_n\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 5.1.12</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Suppose that \(\{\Lambda_n\}\) is a sequence of prior distributions with Bayes risk \(r_n\) satisfying
</p>

\begin{equation*}
r_n \leq r = \lim_{n \rightarrow \infty} r_n,
\end{equation*}

<p>
and that \(\delta\) is an estimator for which 
</p>

\begin{equation*}
\sup_\theta R(\theta, \delta) = r.
\end{equation*}

<p>
Then
</p>

<ol class="org-ol">
<li>\(\delta\) is minimiax and</li>
<li>the sequence \(\{\Lambda_n\}\) is least favorable.</li>
</ol>


<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.1.13</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This lemme helps us evaluate \(r\) in the previous theorem, and hence the Bayes risk \(r_{\Lambda_n}\).
</p>

<p>
If \(\delta_\Lambda\) is the Bayes estimator of \(g(\theta)\) with respect to \(\Lambda\) and if
</p>

\begin{equation*}
r_\Lambda = \mathbb{E} [\delta_\Lambda(X) - g(\Theta)]^2
\end{equation*}

<p>
is its Bayes risk, then
</p>

\begin{equation*}
r_\Lambda = \int \text{Var}[g(\Theta | x] dP(x)
\end{equation*}

<p>
In particular, if the posterior variance of \(g(\Theta)|X\) is independent of \(x\), then 
</p>

\begin{equation*}
r_\Lambda = \text{Var} [g(\Theta)|x]
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.1.14</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Normal mean example. If we have known variance and conjugate normal prior, as the prior variance \(\rightarrow \infty\), the Bayes risk \(\uparrow \sigma^2/n\), and this shows that \(\bar{X}\) is minimax. 
</p>
</div>
</div>
<div id="outline-container-org42d3e76" class="outline-4">
<h4 id="org42d3e76"><span class="done DONE">DONE</span> Admissibility and minimaxity in exponential families <code>[13/13]</code></h4>
<div class="outline-text-4" id="text-org42d3e76">
<p>
A UMVU estimator \(\delta\) need not be admissible. If a biased estimator \(\delta^{\prime}\) has uniformly smaller risk, the choice between \(\delta\) and \(\delta^{\prime}\) is not clear cut: One must balance the advantage of unbiasedness against the drawback of larger risk. The situation is, however, different for minimax estimators. If \(\delta^{\prime}\) dominates a minimax estimator \(\delta\), then \(\delta^{\prime}\) is also minimax and, thus, definitely preferred. It is, therefore, particularly important to ascertain whether a proposed minimax estimator is admissible. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.2.1</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
To prove inadmissibility of an estimator \(\delta\), it is sufficient to produce an estimator \(\delta^{\prime}\) which dominates it. 
</p>

<p>
Let the range of the estimand \(g(\theta)\) be an interval with end-points \(a\) and \(b\), and suppose that the loss function \(L(\theta, d)\) is positive when \(d \neq g(\theta)\) and zero when \(d = g(\theta)\), and that for any fixed \(\theta\), \(L(\theta, d)\) is increasing as \(d\) moves away from \(g(\theta)\) in either direction. Then, any estimator \(\delta\) taking on values outside the closed interval \([a, b]\) with postiive probability is inadmissible. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.2.2</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Randomized response example.
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.2.4</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Any unique Bayes estimator is admissible.  
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.2.5</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Admissibility of linear estimators. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 5.2.6</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
This is an inadmissibility result for linear estimators which is quite general and does not require the assumption of normality. 
</p>

<p>
Let \(X\) be a random variable with mean \(\theta\) and variance \(\sigma^2\). Then \(aX + b\) is an inadmissible estimator of \(\theta\) under squared error loss whenever
</p>

<ol class="org-ol">
<li>\(a > 1\), or</li>
<li>\(a < 0\), or</li>
<li>\(a = 1\) and \(b \neq 0\).</li>
</ol>
<dl class="org-dl">
<dt class="on">&#x2611; Example 5.2.8</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Two proofs for the admissibility of \(\bar{X}\) for estimating the mean of a normal distribution. The first proof uses the Limiting Bayes Method. The second proof uses the Information Inequality Method. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.2.12</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
Let \(X\) and \(Y\) be independent (possibly vector-valued) with distributions \(F_\xi\) and \(G_\eta\), respectively, where \(\xi\) and \(\eta\) vary independently. Then, if \(\delta(X)\) is admissible for estimating \(\xi\) when \(Y\) is not present, it continues to be so in the presence of \(Y\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 5.2.13</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
Normal variance. 
</p>

<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 5.2.14</dt><dd>Lehmann and Casella (Karlin's Theorem)</dd>
</dl>
<p>
Let X have probability density 
</p>

\begin{equation*}
p_\theta)(x) = \beta(\theta) e^{\theta T(x)} \quad (\theta, T \text{ real valued})
\end{equation*}

<p>
with respect to \(\mu\) and let \(\Omega\) be the natural parameter space. Then, \(\Omega\) is an interval, with endpoints say \(\theta_1\) and \(\theta_2\) \((- \infty \leq \theta_1 \leq \theta_2 \leq \infty)\). For estimating \(\mathbb{E}_\theta (T)\), the estimator \(aT + b\) is inadmissible if \(a < 0\) or \(a > 1\) and is constant for \(a = 0\). To state Karlin's sufficient condition in the remaining cases, it is convenient to write the estimator as 
</p>

\begin{equation*}
\delta_{\lambda, \gamma}(x) = \frac{1}{1 + \lambda}T + \frac{\gamma \lambda}{1 + \lambda},
\end{equation*}

<p>
with \(0 \leq \lambda < \infty\) corresponding to \(0 < a \leq 1\). 
</p>

<p>
A sufficient condition for the admissibility of \(\delta_{\lambda, \gamma}(x)\) for estimating \(g(\theta) = \mathbb{E}_\theta(T)\) with squared error loss is that the integral of \(e^{-\gamma \lambda \theta}[\beta(\theta)]^{-\lambda}\) diverges at \(\theta_1\) and \(\theta_2\); that is, that for some (and hence for all) \(\theta_1 < \theta_0 < \theta_1\), the two integrals
</p>

\begin{equation*}
\int_{\theta_0}^{\theta^*} \frac{e^{-\gamma \lambda \theta}}{[\beta(\theta)]^\lambda}d \theta \quad \text{and} \quad \int_{\theta_*}^{\theta^0} \frac{e^{-\gamma \lambda \theta}}{[\beta(\theta)]^\lambda}d \theta
\end{equation*}

<p>
tend to infinity as \(\theta^*\) tends to \(\theta_2\) and \(\theta_1\), respectively. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 5.2.18</dt><dd>Lehmann and Casella</dd>
</dl>

<p>
If the natural parameter space of \(p_\theta)(x) = \beta(\theta) e^{\theta T(x)}\) is the whole real line so that \(\theta_1 = -\infty, \theta_2 = \infty\), then \(T\) is admissible for estimating \(\mathbb{E}_\theta (T)\) with squared error loss. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.2.19</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If an estimator has constant risk and is admissible, it is minimax. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Corollary 5.2.20</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If the natural parameter space of \(p_\theta)(x) = \beta(\theta) e^{\theta T(x)}\) is the whole real line so that \(\theta_1 = -\infty, \theta_2 = \infty\), \(T\) is the unique minimax estimator of \(g(\theta) = \mathbb{E}_\theta (T)\) for the loss function \([d - g(\theta)]^2/\text{Var}_\theta (T)\).
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 5.2.21</dt><dd>Lehmann and Casella</dd>
</dl>
<p>
If an estimator is unique minimax, it is admissible. 
</p>
</div>
</div>
</div>
<div id="outline-container-org8f7095c" class="outline-3">
<h3 id="org8f7095c"><span class="section-number-3">4.6</span> <span class="done DONE">DONE</span> Uniformly most powerful tests <code>[6/6]</code></h3>
<div class="outline-text-3" id="text-4-6">
</div>
<div id="outline-container-org7da21f9" class="outline-4">
<h4 id="org7da21f9"><span class="done DONE">DONE</span> Stating the problem <code>[1/1]</code></h4>
<div class="outline-text-4" id="text-org7da21f9">
<dl class="org-dl">
<dt class="on">&#x2611; Chapter 3 Section 1</dt><dd>Lehmann</dd>
</dl>

<p>
We wish to decide whether or not some hypothesis that has been formulated is correct. The choice here lies between only two decisions: accepting or rejecting the hypothesis. A decision procedure for such a problem is called a <i>test</i> of the hypothesis in question. 
</p>

<p>
The decision is made based on the value of a certain random variable \(X\), the distribution \(P_\theta\) of which is known to belong to a class \(\{P_\theta, \theta \in \Omega \}\). We classify these distributions into two groups, those for which the hypothesis is true and those for which it is false. These classes are mutually exclusive and denoted as \(H\) and \(K\), respectively, with corresponding subsets of \(\Omega\) being \(\Omega_H\) and \(\Omega_K\). \(K\) is then the <i>class of alternatives</i>. 
</p>

<p>
There are two decisions to be made
</p>

\begin{equation*}
d_0 \quad \text{accepting } H, \\
d_1 \quad \text{rejecting } H
\end{equation*}

<p>
A nonrandomized test procedure assigns to each possible value \(x\) of \(X\) one of these two decisions, and thereby divides the sample space into two complementary regions \(S_0\) and \(S_1\). If \(X\) falls into \(S_0\) the hypothesis is accepted, otherwise it is rejected. \(S_0\) is called the region of acceptance, and \(S_1\) is the region of rejection, or <i>critical</i> region. 
</p>

<p>
There are two types of errors to be made:
</p>

\begin{equation*}
\text{Type I error: reject } H \text{ when it is true} \\
\text{Type II error: accept } H \text{ when it is false}
\end{equation*}

<p>
When the number of observations is given, probabilites of both types of error cannot be controlled simultaneously. It is customary therefore to assign a bound to the probability of incorrectly rejecting \(H\) when it is true (Type I error), and to attempt to minimize the other probability (Type II error) subject to this condition. Thus, one selects a number \(\alpha\) between 0 and 1, called the <i>level of significance</i>, and imposes the condition that 
</p>

\begin{equation*}
\mathbb{P}_\theta \{\delta(X) = d_1\} = \mathbb{P}_\theta \{ X \in S_1 \} \leq \alpha \text{ for all } \theta \in \Omega_H.
\end{equation*}

<p>
Subject to this condition, it is desired to maximize the <i>power</i> which is
</p>

\begin{equation*}
\mathbb{P}_\theta \{\delta(X) = d_1 \} = \mathbb{P}_\theta \{X \in S_1 \} \text{ for all } \theta \in \Omega_K.
\end{equation*}

<p>
It is a function of \(\theta\), and we call this function the <i>power function</i>, denoted by \(\beta(\theta)\). 
</p>

<p>
The <i>size</i> of the test is then \(\sup_{\Omega_H} \mathbb{P}_\theta \{ X \in S_1 \}\). 
</p>

<p>
A low significance level results in the hypothesis being rejected only for a small set of values of the observations whose total probability under the hypothesis is small, so that such values would be most unlikely to occur if \(H\) were true. 
</p>

<p>
In applications, there is usually available a nested family of rejection regions, corresponding to different significance levels. It is then good practice to determine not only whether the hypothesis is accepted or rejected at the given significance level, but also to determine the smallest significance level \(\hat{\alpha} = \hat{\alpha}(x)\), the <i>critical level</i>, at which the hypothesis would be rejected for the given observation. 
</p>

<p>
Considering the structure of a randomized test, for any value \(x\), such a test chooses among the two decisions, rejection or accepance, with certain probabilities that depend on \(x\) and will be denoted by \(\phi(x)\) and \(1 - \phi(x)\), respectively. A randomized test is therefore completely characterized by a function \(\phi\), the <i>critical function</i>, with \(0 \leq \phi(x) \leq 1\) for all \(x\). If \(\phi\) takes on the values 0 and 1, one is back in the case of a nonrandomized test. the set of points \(x\) for which \(\phi(x) = 1\) is then just the rejection region, so that in a nonrandomized test \(\phi\) is simply the indicator function of the critical region. 
</p>

<p>
The probability of rejection is
</p>

\begin{equation*}
\mathbb{E}_\theta \phi(X) = \int \phi(x) d\mathbb{P}_\theta (x),
\end{equation*}

<p>
the conditional probability \(\phi(x)\) of rejection given \(x\), integrated with respect to the probability distribution \(X\). The problem is to select \(\phi\) so as to maximize the power
</p>

\begin{equation*}
\beta_\phi(\theta) = \mathbb{E}_\theta \phi(X) \text{ for all } \theta \in \Omega_K
\end{equation*}

<p>
subject to the condition
</p>

\begin{equation*}
\mathbb{E}_\theta \phi(X) \leq \alpha \text{ for all } \theta \in \Omega_H.
\end{equation*}

<p>
A <i>uniformly most powerful</i> (UMP) test maximizes the power for all alternatives in \(K\) even when there is more than one. 
</p>
</div>
</div>

<div id="outline-container-org6962660" class="outline-4">
<h4 id="org6962660"><span class="done DONE">DONE</span> Neyman-Pearson Fundamental Lemma <code>[4/4]</code></h4>
<div class="outline-text-4" id="text-org6962660">
<dl class="org-dl">
<dt class="on">&#x2611; Chapter 3 Section 2</dt><dd>Lehmann</dd>
</dl>
<p>
A class of distributions is called <i>simple</i> if it contains only a single distribution and otherwise is said to be <i>composite</i>.
</p>

<p>
Let the distribution under a simple hypothesis \(H\) and alternative \(K\) be \(\mathbb{P}_0\) and \(\mathbb{P}_1\), and suppose that these distributions are discrete with \(\mathbb{P}_i \{X = x \} = \mathbb{P}_i(x)\) for \(i = 0, 1\). If we only consider nonrandomized tests, the optimum test is defined as the critical region \(S\) satisfying
</p>

\begin{equation*}
\sum_{x \in S} \mathbb{P}_0 (x) \leq \alpha
\end{equation*}

<p>
and
</p>

\begin{equation*}
\sum_{x \in S} \mathbb{P}_1 (x) = \text{ maximum}.
\end{equation*}

<p>
So we include points in \(S\) based on the idea of a "limited budget". The most valuable points \(x\) are those with the highest value of
</p>

\begin{equation*}
r(x) = \frac{\mathbb{P}_1 (x)}{\mathbb{P}_0 (x)}. 
\end{equation*}

<p>
So points are rated according to the value of this ratio and selected for \(S\) in this order, as many as one can afford under \(\sum_{x \in S} \mathbb{P}_0 (x) \leq \alpha\).
</p>

<p>
It may happen that when a certain point is included, the value \(\alpha\) has not yet been reached but that it would be exceeded if the next point were also included. The exact value of \(\alpha\) can then either not be achieved at all, or it can be attained only by passing over the next desirable point and in its place taking one further down the list. The difficulty can be overcome by permitting randomization. This makes it possible to split the next point, including only a portion of it, and thereby to obtain the exact value \(\alpha\) without breaking the order of the preference that has been established for the various sampling points. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.1</dt><dd>Lehmann (The fundamental lemma of Neyman and Pearson)</dd>
</dl>
<p>
Let \(\mathbb{P}_0\) and \(\mathbb{P}_1\) be probability distributions possessing densities \(p_0\) and \(p_1\) respectively with respect to a measure \(\mu\).
</p>

<p>
<b>i.</b> <i>Existence</i>. For testing \(H: p_0\) against the alternative \(K: p_1\) there exists a test \(\phi\) and a constant \(k\) such that 
</p>
\begin{equation*}
\mathbb{E}_0 \phi(X) = \alpha
\end{equation*}
<p>
and 
</p>
\begin{equation*}
\phi(x) = 1 \text{ when } p_1(x) > k p_0(x) \\
\phi(x) = 0 \text{ when } p_1(x) < k p_0(x)
\end{equation*}

<p>
<b>ii.</b> <i>Sufficient condition for most powerful test</i>. If a test satisfies condition 1. for some \(k\), then it is most powerful for testing \(p_0\) against \(p_1\) at level \(\alpha\).
</p>

<p>
<b>iii.</b> <i>Necessary condition for a most powerful test</i>. If \(\phi\) is most powerful at level \(\alpha\) for testing \(p_0\) against \(p_1\), then for some \(k\) it satisfies 
</p>

\begin{equation*}
\phi(x) = 1 \text{ when } p_1(x) > k p_0(x) \\
\phi(x) = 0 \text{ when } p_1(x) < k p_0(x)
\end{equation*}

<p>
a.e. \(\mu\). It also satisfies \(\mathbb{E}_0 \phi(X) = \alpha\) unless there exists a test of size \(< \alpha\) and with power \(1\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 3.1</dt><dd>Lehmann</dd>
</dl>
<p>
Let \(\beta\) denote the power of the most powerful level- \(\alpha\) test \((0 < \alpha < 1)\) for testing \(\mathbb{P}_0\) against \(\mathbb{P}_1\). Then \(\alpha < \beta\) unless \(\mathbb{P}_0 = \mathbb{P}_1\). 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Example 12.6</dt><dd>Keener</dd>
</dl>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
<div id="outline-container-orgc1c4f7c" class="outline-4">
<h4 id="orgc1c4f7c"><span class="done DONE">DONE</span> Distributions with monotone likelihood ratio <code>[8/8]</code></h4>
<div class="outline-text-4" id="text-orgc1c4f7c">
<p>
Besides testing simple hypotheses, we often have distribtions depending on a single real-valued parameter \(\theta\) and the hypothesis is one-sided, say \(H_0: \theta \leq \theta_0\). In general, the most powerful test of \(H\) against an alternative \(\theta_1 > \theta_0\) depends on \(\theta_1\) and is then not UMP. However, a UMP test does exist if an additional assumption is satisfied. The real-parameter family of densities \(p_\theta(x)\) is said to have <i>monotone likelihood ratio</i> if there exists a real-valued function \(T(x)\) such that for any \(\theta < \theta^{\prime}\) the distributions \(\mathbb{P}_\theta\) and \(\mathbb{P}_{\theta^{\prime}}\) are distinct, and the ratio \(p_{\theta^{\prime}}(x) / p_\theta(x)\) is a nondecreasing function of \(T(x)\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.2</dt><dd>Lehmann</dd>
</dl>
<p>
Let \(\theta\) be a real parameter, and let the random variable \(X\) have probability density \(p_\theta(x)\) with monotone likelihood ratio in \(T(x)\). 
</p>

<p>
(i) For testing \(H: \theta \leq \theta_0\) against \(K: \theta > \theta_0\), there exists a UMP test, which is given by
</p>

\begin{align*}
\phi(x) &= 1 \text{ when } T(x) > C, \\
\phi(x) &= \gamma \text{ when } T(x) = C, \\
\phi(x) &= 0 \text{ when } T(x) < C,
\end{align*}

<p>
where \(C\) and \(\gamma\) are determined by
</p>

\begin{equation*}
\mathbb{E}_{\theta_0}\phi(X) = \alpha.
\end{equation*}

<p>
(ii) The power function
</p>

\begin{equation*}
\beta(\theta) = \mathbb{E}_\theta \phi(X)
\end{equation*}

<p>
of this test is strictly increasing for all points \(\theta\) for which \(0 < \beta(\theta) < 1\).
</p>

<p>
(iii) For all \(\theta^{\prime}\), the test determined in step (i) is UMP for testing \(H^{\prime}: \theta \leq \theta^{\prime}\) against \(K^{\prime}: \theta > \theta^{\prime}\) at level \(\alpha^{\prime} = \beta(\theta^{\prime})\). 
</p>

<p>
(iv) For any \(\theta < \theta_0\) the test minimizes \(\beta(\theta)\) (the probability of error of the first kind) among all tests satisfying \(\mathbb{E}_{\theta_0}\phi(X) = \alpha\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.1</dt><dd>Lehmann</dd>
</dl>
<p>
Hypergeometric satisfies the assumption of monotone likeligood ratios with \(T(x) = x\). Therefore, there exists a UMP test for testing the one-sided hypothesis testm, which rejects when \(X\) is too large or small (depending on the sides of the test). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 3.2</dt><dd>Lehmann</dd>
</dl>
<p>
One-parameter exponential families satisfy the monotone likelihood ratio assumption. 
</p>

<p>
Let \(\theta\) be a real parameter, and let \(X\) have probability density (with respect to some measure \(\mu\)) 
</p>

\begin{equation*}
p_\theta (x) = C(\theta) e^{Q(\theta)T(x)} h(x),
\end{equation*}

<p>
where \(Q\) is strictly monotone. Then there exists a UMP test \(\phi\) for testing \(H: \theta \leq \theta_0\) against \(K: \theta > \theta_0\). If \(Q\) is increasing, 
</p>

\begin{equation*}
\phi(x) = 1, \gamma, 0 \quad \text{as} \quad T(x) >, =, < C,
\end{equation*}

<p>
where \(C\) and \(\gamma\) are determined by \(\mathbb{E}_{\theta_0}\phi(X) = \alpha\). If \(Q\) is decreasing, the inequalities are reversed. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.2</dt><dd>Lehmann</dd>
</dl>
<p>
Binomial example of one-parameter exponential family.
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 3.3</dt><dd>Lehmann</dd>
</dl>
<p>
Poisson example of one-parameter exponential family.
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 12.10</dt><dd>Keener</dd>
</dl>
<p>
Monotone likelihood ratios for joint densities of uniform distributions. 
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 3.1</dt><dd>Lehmann</dd>
</dl>
<p>
Let \(F_0\) and \(F_1\) be two cumulative distribution functions on the real line. Then \(F_1(x) \leq F_0(x)\) for all \(x\) if and only if there exist two nondecreasing functions \(f_0\) and \(f_1\), and a random variable \(V\), such that 
</p>

<p>
(a) \(f_0(v) \leq f_1(v)\) for all \(v\), and
</p>

<p>
(b) the distributions of \(f_0(V)\) and \(f_1(V)\) are \(F_0\) and \(F_1\), respectively. 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 3.2</dt><dd>Lehmann</dd>
</dl>
<p>
Basic properties of families with monotone likelihood ratios. 
</p>

<p>
Let \(p_\theta(x)\) be a family of densities on the real line with monotone likelihood ratio in \(x\).
</p>

<p>
(i) If \(\psi\) is a nondecreasing function of \(x\), then \(\mathbb{E}_\theta \psi(X)\) is a nondecreasing function of \(\theta\); if \(X_1, \ldots, X_n\) are independently distributed with density \(p_\theta\) and \(\psi^{\prime}\) is a function of \(x_1, \ldots, x_n\) which is nondecreasing in each of its arguments, then \(\mathbb{E}_\theta \psi^{\prime}(X_1, \ldots, X_n)\) is a nondecreasing function of \(\theta\). 
</p>

<p>
(ii) For any \(\theta < \theta^{\prime}\), the cumulative distribution functions of \(X\) under \(\theta\) and \(\theta^{\prime}\) satisfy
</p>

\begin{equation*}
F_{\theta^{\prime}}(x) \leq F_\theta(x) \quad \text{for all } x.
\end{equation*}

<p>
(iii) Let \(\psi\) be a function with a single change of sign. More specifically, suppose there exists a value \(x_0\) such that \(\psi(x) \leq 0\) for \(x < x_0\) and \(\psi(x) \geq 0\) for \(x \geq x_0\). Then there exists \(\theta_0\) such that \(\mathbb{E}_\theta \psi(X) \leq 0\) for \(\theta < \theta_0\) and \(\mathbb{E}_\theta \psi(X) \geq 0\) for \(\theta > \theta_0\), unless \(\mathbb{E}_\theta \psi(X)\) is either positive for all \(\theta\) or negative for all \(\theta\).
</p>

<p>
(iv) Suppose that \(p_\theta(x)\) is positive for all \(\theta\) and all \(x\), that \(p_{\theta^{\prime}}(x) / p_\theta(x)\) is strictly increasing in \(x\) for \(\theta < \theta^{\prime}\), and that \(\psi(x)\) is as in (iii) and is \(\neq 0\) with positive probability. If \(\mathbb{E}_{\theta_0} \psi(X) = 0\), then \(\mathbb{E}_\theta \psi(X) < 0\) for \(\theta < \theta_0\) and \(> 0\) for \(\theta > \theta_0\).
</p>
</div>
</div>

<div id="outline-container-org2410426" class="outline-4">
<h4 id="org2410426"><span class="done DONE">DONE</span> Confidence bounds <code>[6/6]</code></h4>
<div class="outline-text-4" id="text-org2410426">
<dl class="org-dl">
<dt class="on">&#x2611; Chapter 3 Section 5</dt><dd>Lehmann</dd>
</dl>
<p>
The theory of UMP one-sided tests can be applied to the problem of obtaining a lower or upper bound for a real-valued parameter \(\theta\). The discussion of lower and upper bounds is completely parallel, and it is therefore enough to consider the case of a lower bound, say \(\underline{\theta}\). 
</p>

<p>
One selects a number \(1 - \alpha\), the <i>confidence level</i>, and restricts attention to bounds \(\underline{\theta}\) satisfying 
</p>

\begin{equation*}
\mathbb{P}_\theta(\underline{\theta}(X) \leq \theta) \geq 1-\alpha \quad \text{for all } \theta.
\end{equation*}

<p>
A function \(\underline{\theta}\) for which
</p>

\begin{equation*}
\mathbb{P}_\theta(\underline{\theta}(X) \leq \theta^{\prime}) = \text{minimum}
\end{equation*}

<p>
for all \(\theta^{\prime} < \theta\) subject to the above condition is a uniformly most accurate lower confidence bound for \(\theta\) at confidence level \(1 - \alpha\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.4</dt><dd>Lehmann</dd>
</dl>
<p>
(i) For each \(\theta_0 \in \Omega\) let \(A(\theta_0)\) be the acceptance region of a level- \(\alpha\) test for testing \(H(\theta_0): \theta = \theta_0\), and for each sample point \(x\) let \(S(x)\) denote the set of parameter values 
</p>

\begin{equation*}
S(x) = \{\theta : x \in A(\theta), \theta \in \Omega \}.
\end{equation*}

<p>
Then \(S(x)\) is a family of confidence sets for \(\theta\) at confidence level \(1 - \alpha\). 
</p>

<p>
(ii) If for all \(\theta_0, A(\theta_0)\) is UMP for testing \(H(\theta_0)\) at level \(\alpha\) against the alternatives \(K(\theta_0)\), then for each \(\theta_0\) in \(\Omega, S(X)\) minimizes the probability 
</p>

\begin{equation*}
\mathbb{P}_\theta(\theta_0 \in S(X)) \text{ for all } \theta \in K(\theta_0)
\end{equation*}

<p>
among all level- \((1-\alpha)\) families of confidence sets for \(\theta\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Corollary 3.3</dt><dd>Lehmann</dd>
</dl>
<p>
Let the family of densities \(p_\theta(x), \theta \in \Omega\), have monotone likelihood ratio in \(T(x)\), and suppose that the cumulative distribution function \(F_\theta(t)\) of \(T = T(X)\) is a continuous function in each of the variables \(t\) and \(\theta\) when the other is fixed. 
</p>

<p>
(i) There exists a uniformly most accurate confidence bound \(\underline{\theta}\) for \(\theta\) at each confidence level \(1 - \alpha\).
</p>

<p>
(ii) If \(x\) denotes the observed values of \(X\) and \(t = T(x)\), and if the equation 
</p>

\begin{equation*}
F_\theta(t) = 1 - \alpha
\end{equation*}

<p>
has a solution \(\theta = \hat{\theta}\) in \(\Omega\), then this solution is unique and \(\underline{\theta}(x) = \hat{\theta}\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.6</dt><dd>Lehmann</dd>
</dl>
<p>
Exponential waiting times
</p>

<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Discrete Distributions</dt><dd>p. 93 Lehmann</dd>
</dl>

<p>
If the variables \(X\) or \(T\) are discrete, corollary 3.3 cannot be applied directly, since the distribution functions \(F_\theta(t)\) are not continuous, and for most values \(\theta_0\) the optimum tests of \(H: \theta = \theta_0\) are randomized. However, any randomized test based on \(X\) has a representation as a nonrandomized test depending on \(X\) and an independent random variable \(U\) distribued uniformly over \((0, 1)\).
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Example 3.7</dt><dd>Lehmann</dd>
</dl>
<p>
Binomial example
</p>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
<div id="outline-container-org3f06019" class="outline-4">
<h4 id="org3f06019"><span class="done DONE">DONE</span> A generalization of the fundamental lemma <code>[3/3]</code></h4>
<div class="outline-text-4" id="text-org3f06019">
<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.5</dt><dd>Lehmann</dd>
</dl>
<p>
This is a useful extension of Theorem 3.1 to the case of more than one side condition.
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Corollary 3.4</dt><dd>Lehmann</dd>
</dl>
<p>
Let \(p_1, \ldots, p_m, p_{m+1}\) be probability densities with respect to a measure \(\mu\), and let \(0 < \alpha < 1\). Then there exists a test \(\phi\) such that \(\mathbb{E}_i \phi(X) = \alpha (i = 1, \ldots, m)\) and \(\mathbb{E}_{m + 1} \phi(X) > \alpha\), unless \(p_{m+1} = \sum_{i = 1}^m k_i p_i\) a.e. \(\mu\). 
</p>
<dl class="org-dl">
<dt class="on">&#x2611; Lemma 3.3</dt><dd>Lehmann</dd>
</dl>
<p>
This is the method of undetermined multipliers. 
</p>

<p>
Let \(F_1, \ldots, F_{m+1}\) be real-valued functions defined over a space \(U\), and consider the problem of maximizing \(F_{m+1}(u)\) subject to \(F_i(u) = c(i), (i = 1, \ldots, m)\). A sufficient condition for a point \(u^0\) satisfying the side conditions to be a solution of the given problem is that among all points of \(U\) it maximizes
</p>

\begin{equation*}
F_{m+1}(u) - \sum_{i = 1}^m k_i F_i(u)
\end{equation*}

<p>
for some \(k_1, \ldots, k_m\).
</p>
</div>
</div>

<div id="outline-container-org3d6cd9c" class="outline-4">
<h4 id="org3d6cd9c"><span class="done DONE">DONE</span> Two-sided hypotheses <code>[2/2]</code></h4>
<div class="outline-text-4" id="text-org3d6cd9c">
<p>
Two-sided hypotheses have the form
</p>

\begin{equation*}
H:\theta \leq \theta_1 \text{ or } \theta \geq \theta_2 \quad (\theta_1 < \theta_2).
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Theorem 3.6</dt><dd>Lehmann</dd>
</dl>

<p>
(i) For testing the hypothesis \(H: \theta \leq \theta_1 \text{ or } \theta \geq \theta_2\) \((\theta_1 < \theta_2)\) against the alternatives \(K: \theta_1 < \theta < \theta_2\) in the one-parameter exponential family, there exists a UMP test given by
</p>

\begin{align*}
\phi(x) &= 1 \text{ when } C_1 < T(x) < C_2 \quad (C_1 < C_2), \\
\phi(x) &= \gamma_i \text{ when } T(x) = C_i, \quad i = 1, 2, \\
\phi(x) &= 0 \text{ when } T(x) < C_1 \text{ or } > C_2.
\end{align*}

<p>
where the \(C\) 's and \(\gamma\) 's are determined by 
</p>

\begin{equation*}
\mathbb{E}_{\theta_1}\phi(X) = \mathbb{E}_{\theta_2} \phi(X) = \alpha.
\end{equation*}

<p>
(ii) This test minimizes \(\mathbb{E}_\theta(X)\) subject to \(\mathbb{E}_{\theta_1}\phi(X) = \mathbb{E}_{\theta_2} \phi(X) = \alpha\) for all \(\theta < \theta_1\) and \(> \theta_2\). 
</p>

<p>
(iii) For \(0 < \alpha < 1\) the power function of this test has a maximum at a point \(\theta_0\) between \(\theta_1\) and \(\theta_2\) and decreases strictly as \(\theta\) tends away from \(\theta_0\) in either direction, unless there exist two values \(t_1, t_2\) such that \(\mathbb{P}_\theta(T(X) = t_1) + \mathbb{P}_\theta(T(X) = t_2) = 1\) for all \(\theta\). 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemhma 3.4</dt><dd>Lehmann</dd>
</dl>

<p>
Let \(p_\theta(x)\) be postive for all \(\theta\) and all \(x\) with \(p_{\theta^{\prime}}(x) / p_\theta (x)\) being strictly increasing in \(x\) for \(\theta < \theta^{\prime}\).
</p>

<p>
(i) If \(\phi\) and \(\phi^*\) are two tests satisfying 
</p>

\begin{align*}
\phi(x) &= 1 \text{ when } C_1 < T(x) < C_2 \quad (C_1 < C_2), \\
\phi(x) &= \gamma_i \text{ when } T(x) = C_i, \quad i = 1, 2, \\
\phi(x) &= 0 \text{ when } T(x) < C_1 \text{ or } > C_2.
\end{align*}

<p>
and \(\mathbb{E}_{\theta_1} \phi(T) = \mathbb{E}_{\theta_1} \phi^*(T)\), and if \(\phi^*\) is to the right of \(\phi\), then \(\beta(\theta) <\) or \(> \beta^*(\theta)\) as \(\theta > \theta_1\) or \(< \theta_1\). 
</p>

<p>
(ii) If \(\phi\) and \(\phi^*\) satisfy
</p>

\begin{align*}
\phi(x) &= 1 \text{ when } C_1 < T(x) < C_2 \quad (C_1 < C_2), \\
\phi(x) &= \gamma_i \text{ when } T(x) = C_i, \quad i = 1, 2, \\
\phi(x) &= 0 \text{ when } T(x) < C_1 \text{ or } > C_2.
\end{align*}

<p>
and 
</p>

\begin{equation*}
\mathbb{E}_{\theta_1}\phi(X) = \mathbb{E}_{\theta_2} \phi(X) = \alpha.
\end{equation*}

<p>
then \(\phi = \phi^*\) with probability one. 
</p>
</div>
</div>
</div>

<div id="outline-container-org07d2609" class="outline-3">
<h3 id="org07d2609"><span class="section-number-3">4.7</span> <span class="done DONE">DONE</span> Unbiased tests <code>[5/5]</code></h3>
<div class="outline-text-3" id="text-4-7">
<dl class="org-dl">
<dt class="on">&#x2611; Definition 12.25</dt><dd>Keener</dd>
</dl>
<p>
A test \(\varphi\) for \(H_0: \theta \in \Omega_0\) versus \(H_1: \theta \in \Omega_1\) with level \(\alpha\) is unbiased if its power \(\beta_\varphi(\theta) = \mathbb{E}_\theta \varphi\) satisfies
</p>

\begin{equation*}
\beta_\varphi (\theta) \leq \alpha, \text{ for all } \theta \in \Omega_0 \text{ and } \beta_\varphi(\theta) \geq \alpha, \text{ for all } \theta \in \Omega_1.
\end{equation*}

<p>
If there is a uniformly most powerful test, then it is automatically unbiased. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Lemma 4.1</dt><dd>Lehmann</dd>
</dl>

<p>
If the distributions \(\mathbb{P}_\theta\) are such that the power function of every test is continuous, and if \(\phi_0\) is UMP among all tests that are similar on the boundary and is a level- \(\alpha\) test of \(H\), then \(\phi_0\) is UMP unbiased. 
</p>

<dl class="org-dl">
<dt class="on">&#x2611; Chapter 4 Section 2</dt><dd>Lehmann</dd>
</dl>
<p>
Let \(\theta\) be a real parameter, and \(X = (X_1, \ldots, X_n)\) a random vector with probability density (with respect to some measure \(\mu\))
</p>

\begin{equation*}
p_\theta(x) = C(\theta)e^{\theta T(x)}h(x).
\end{equation*}

<p>
We have shown that a UMP test exists when the hypothesis \(H\) and the class \(K\) of alternatives are given by
</p>

<p>
(i) \(H: \theta \leq \theta_0, \quad K: \theta > \theta_0\) (Corollary 3.2)
</p>

<p>
(ii) \(H: \theta \leq \theta_1\) or \(\theta \geq \theta_2, \quad (\theta_1 < \theta_2)\), \(K: \theta_1 < \theta < \theta_2\) (Theorem 3.6)
</p>

<p>
We will now show that for 
</p>

<p>
(iii) \(H: \theta_1 \leq \theta \leq \theta_2, K: \theta < \theta_1\) or \(\theta > \theta_2\),
</p>

<p>
there exists a UMP unbiased test given by
</p>

\begin{align*}
\phi(x) &= 1 \text{ when } T(x) < C_1 \text{ or } > C_2, \\
\phi(x) &= \gamma_i \text{ when } T(x) = C_i, \quad i = 1, 2, \\
\phi(x) &= 0 \text{ when } C_1 < T(x) < C_2,
\end{align*}

<p>
where the \(C\) 's and \(\gamma\) 's are determined by
</p>

\begin{equation*}
\mathbb{E}_{\theta_1} \phi(X) = \mathbb{E}_{\theta_2} \phi(X) = \alpha.
\end{equation*}

<p>
A closely related problem is that of testing
</p>

<p>
(iv) \(H: \theta = \theta_0\) against the alternatives \(\theta \neq \theta_0\).
</p>

<p>
For this there also exists a UMP unbiased test given by 
</p>

\begin{align*}
\phi(x) &= 1 \text{ when } T(x) < C_1 \text{ or } > C_2, \\
\phi(x) &= \gamma_i \text{ when } T(x) = C_i, \quad i = 1, 2, \\
\phi(x) &= 0 \text{ when } C_1 < T(x) < C_2,
\end{align*}

<p>
but the constants are now determined by
</p>

\begin{equation*}
\mathbb{E}_{\theta_0} [\phi(X)] = \alpha
\end{equation*}

<p>
and
</p>

\begin{equation*}
\mathbb{E}_{\theta_0} [T(X) \phi(X)] = \mathbb{E}_{\theta_0} [T(X)] \alpha.
\end{equation*}

<dl class="org-dl">
<dt class="on">&#x2611; Example 4.1</dt><dd>Lehmann</dd>
</dl>
<p>
Binomial example for one-parameter exponential family
</p>
<div style="margin-bottom: 150px;"></div>
<dl class="org-dl">
<dt class="on">&#x2611; Example 4.2</dt><dd>Lehmann</dd>
</dl>
<p>
Normal variance example for one-parameter exponential family
</p>
<div style="margin-bottom: 150px;"></div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Elliot Shannon</p>
<p class="date">Created: 2025-03-21 Fri 09:37</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
